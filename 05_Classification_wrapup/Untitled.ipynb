{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = \"\"\"\n",
    "# Epoch 1/50\n",
    "# 390/390 [==============================] - 104s 266ms/step - loss: 1.6366 - accuracy: 0.4322 - val_loss: 1.4235 - val_accuracy: 0.4934\n",
    "# Epoch 2/50\n",
    "# 390/390 [==============================] - 103s 265ms/step - loss: 1.1883 - accuracy: 0.5818 - val_loss: 1.1919 - val_accuracy: 0.5852\n",
    "# Epoch 3/50\n",
    "# 390/390 [==============================] - 106s 271ms/step - loss: 1.0168 - accuracy: 0.6425 - val_loss: 1.0603 - val_accuracy: 0.6283\n",
    "# Epoch 4/50\n",
    "# 390/390 [==============================] - 104s 266ms/step - loss: 0.9050 - accuracy: 0.6849 - val_loss: 0.9647 - val_accuracy: 0.6619\n",
    "# Epoch 5/50\n",
    "# 390/390 [==============================] - 104s 266ms/step - loss: 0.8236 - accuracy: 0.7127 - val_loss: 0.9540 - val_accuracy: 0.6682\n",
    "# Epoch 6/50\n",
    "# 390/390 [==============================] - 103s 264ms/step - loss: 0.7645 - accuracy: 0.7347 - val_loss: 0.8745 - val_accuracy: 0.7029\n",
    "# Epoch 7/50\n",
    "# 390/390 [==============================] - 107s 274ms/step - loss: 0.7111 - accuracy: 0.7555 - val_loss: 0.8894 - val_accuracy: 0.6918\n",
    "# Epoch 8/50\n",
    "# 390/390 [==============================] - 103s 263ms/step - loss: 0.6696 - accuracy: 0.7684 - val_loss: 0.8470 - val_accuracy: 0.7115\n",
    "# Epoch 9/50\n",
    "# 390/390 [==============================] - 102s 263ms/step - loss: 0.6316 - accuracy: 0.7840 - val_loss: 0.8082 - val_accuracy: 0.7249\n",
    "# Epoch 10/50\n",
    "# 390/390 [==============================] - 112s 286ms/step - loss: 0.5963 - accuracy: 0.7952 - val_loss: 0.7840 - val_accuracy: 0.7363\n",
    "# Epoch 11/50\n",
    "# 390/390 [==============================] - 118s 304ms/step - loss: 0.5620 - accuracy: 0.8062 - val_loss: 0.8809 - val_accuracy: 0.7051\n",
    "# Epoch 12/50\n",
    "# 390/390 [==============================] - 117s 301ms/step - loss: 0.5344 - accuracy: 0.8174 - val_loss: 0.7891 - val_accuracy: 0.7422\n",
    "# Epoch 13/50\n",
    "# 390/390 [==============================] - 117s 301ms/step - loss: 0.5099 - accuracy: 0.8250 - val_loss: 0.7883 - val_accuracy: 0.7397\n",
    "# Epoch 14/50\n",
    "# 390/390 [==============================] - 118s 301ms/step - loss: 0.4842 - accuracy: 0.8346 - val_loss: 0.7635 - val_accuracy: 0.7470\n",
    "# Epoch 15/50\n",
    "# 390/390 [==============================] - 110s 282ms/step - loss: 0.4615 - accuracy: 0.8432 - val_loss: 0.7886 - val_accuracy: 0.7439\n",
    "# Epoch 16/50\n",
    "# 390/390 [==============================] - 104s 266ms/step - loss: 0.4363 - accuracy: 0.8511 - val_loss: 0.7676 - val_accuracy: 0.7424\n",
    "# Epoch 17/50\n",
    "# 390/390 [==============================] - 102s 262ms/step - loss: 0.4193 - accuracy: 0.8575 - val_loss: 0.7766 - val_accuracy: 0.7456\n",
    "# Epoch 18/50\n",
    "# 390/390 [==============================] - 102s 263ms/step - loss: 0.3936 - accuracy: 0.8657 - val_loss: 0.7964 - val_accuracy: 0.7424\n",
    "# Epoch 19/50\n",
    "# 390/390 [==============================] - 102s 262ms/step - loss: 0.3746 - accuracy: 0.8740 - val_loss: 0.8418 - val_accuracy: 0.7319\n",
    "# Epoch 20/50\n",
    "# 390/390 [==============================] - 102s 263ms/step - loss: 0.3553 - accuracy: 0.8815 - val_loss: 0.7705 - val_accuracy: 0.7519\n",
    "# Epoch 21/50\n",
    "# 390/390 [==============================] - 103s 263ms/step - loss: 0.3402 - accuracy: 0.8874 - val_loss: 0.8254 - val_accuracy: 0.7427\n",
    "# Epoch 22/50\n",
    "# 390/390 [==============================] - 109s 279ms/step - loss: 0.3217 - accuracy: 0.8939 - val_loss: 0.7721 - val_accuracy: 0.7540\n",
    "# Epoch 23/50\n",
    "# 390/390 [==============================] - 116s 297ms/step - loss: 0.3043 - accuracy: 0.9007 - val_loss: 0.7735 - val_accuracy: 0.7609\n",
    "# Epoch 24/50\n",
    "# 390/390 [==============================] - 115s 295ms/step - loss: 0.2868 - accuracy: 0.9063 - val_loss: 0.7849 - val_accuracy: 0.7585\n",
    "# Epoch 25/50\n",
    "# 390/390 [==============================] - 115s 296ms/step - loss: 0.2670 - accuracy: 0.9148 - val_loss: 0.7967 - val_accuracy: 0.7543\n",
    "# Epoch 26/50\n",
    "# 390/390 [==============================] - 116s 297ms/step - loss: 0.2560 - accuracy: 0.9191 - val_loss: 0.8197 - val_accuracy: 0.7530\n",
    "# Epoch 27/50\n",
    "# 390/390 [==============================] - 113s 289ms/step - loss: 0.2469 - accuracy: 0.9223 - val_loss: 0.8030 - val_accuracy: 0.7563\n",
    "# Epoch 28/50\n",
    "# 390/390 [==============================] - 107s 273ms/step - loss: 0.2253 - accuracy: 0.9295 - val_loss: 0.8130 - val_accuracy: 0.7551\n",
    "# Epoch 29/50\n",
    "# 390/390 [==============================] - 105s 269ms/step - loss: 0.2140 - accuracy: 0.9333 - val_loss: 0.8328 - val_accuracy: 0.7488\n",
    "# Epoch 30/50\n",
    "# 390/390 [==============================] - 128s 328ms/step - loss: 0.2016 - accuracy: 0.9397 - val_loss: 0.8496 - val_accuracy: 0.7526\n",
    "# Epoch 31/50\n",
    "# 390/390 [==============================] - 104s 267ms/step - loss: 0.1859 - accuracy: 0.9445 - val_loss: 0.8299 - val_accuracy: 0.7601\n",
    "# Epoch 32/50\n",
    "# 390/390 [==============================] - 103s 265ms/step - loss: 0.1751 - accuracy: 0.9492 - val_loss: 0.8666 - val_accuracy: 0.7545\n",
    "# Epoch 33/50\n",
    "# 390/390 [==============================] - 146s 375ms/step - loss: 0.1634 - accuracy: 0.9530 - val_loss: 0.8543 - val_accuracy: 0.7575\n",
    "# Epoch 34/50\n",
    "# 390/390 [==============================] - 261s 670ms/step - loss: 0.1522 - accuracy: 0.9571 - val_loss: 0.8626 - val_accuracy: 0.7647\n",
    "# Epoch 35/50\n",
    "# 390/390 [==============================] - 103s 265ms/step - loss: 0.1419 - accuracy: 0.9619 - val_loss: 0.8685 - val_accuracy: 0.7585\n",
    "# Epoch 36/50\n",
    "# 390/390 [==============================] - 104s 267ms/step - loss: 0.1353 - accuracy: 0.9643 - val_loss: 0.8487 - val_accuracy: 0.7601\n",
    "# Epoch 37/50\n",
    "# 390/390 [==============================] - 106s 272ms/step - loss: 0.1224 - accuracy: 0.9690 - val_loss: 0.8789 - val_accuracy: 0.7588\n",
    "# Epoch 38/50\n",
    "# 390/390 [==============================] - 104s 267ms/step - loss: 0.1163 - accuracy: 0.9713 - val_loss: 0.8802 - val_accuracy: 0.7618\n",
    "# Epoch 39/50\n",
    "# 390/390 [==============================] - 110s 281ms/step - loss: 0.1061 - accuracy: 0.9751 - val_loss: 0.8807 - val_accuracy: 0.7637\n",
    "# Epoch 40/50\n",
    "# 390/390 [==============================] - 106s 272ms/step - loss: 0.0976 - accuracy: 0.9781 - val_loss: 0.8942 - val_accuracy: 0.7635\n",
    "# Epoch 41/50\n",
    "# 390/390 [==============================] - 111s 284ms/step - loss: 0.0892 - accuracy: 0.9816 - val_loss: 0.9146 - val_accuracy: 0.7627\n",
    "# Epoch 42/50\n",
    "# 390/390 [==============================] - 107s 273ms/step - loss: 0.0839 - accuracy: 0.9830 - val_loss: 0.9088 - val_accuracy: 0.7613\n",
    "# Epoch 43/50\n",
    "# 390/390 [==============================] - 108s 276ms/step - loss: 0.0786 - accuracy: 0.9839 - val_loss: 0.9264 - val_accuracy: 0.7613\n",
    "# Epoch 44/50\n",
    "# 390/390 [==============================] - 107s 275ms/step - loss: 0.0733 - accuracy: 0.9864 - val_loss: 0.9182 - val_accuracy: 0.7585\n",
    "# \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data = \"\"\"\n",
    "Epoch 1/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 2.0599 - accuracy: 0.4107 - val_loss: 1.8859 - val_accuracy: 0.4693\n",
    "Epoch 2/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 1.7205 - accuracy: 0.5219 - val_loss: 1.9937 - val_accuracy: 0.4844\n",
    "Epoch 3/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 1.5905 - accuracy: 0.5688 - val_loss: 1.6765 - val_accuracy: 0.5591\n",
    "Epoch 4/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 1.4974 - accuracy: 0.6016 - val_loss: 1.4793 - val_accuracy: 0.6142\n",
    "Epoch 5/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 1.4271 - accuracy: 0.6250 - val_loss: 1.5261 - val_accuracy: 0.5974\n",
    "Epoch 6/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 1.3700 - accuracy: 0.6446 - val_loss: 1.4851 - val_accuracy: 0.6282\n",
    "Epoch 7/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 1.3220 - accuracy: 0.6601 - val_loss: 1.2994 - val_accuracy: 0.6803\n",
    "Epoch 8/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 1.2739 - accuracy: 0.6759 - val_loss: 1.2912 - val_accuracy: 0.6783\n",
    "Epoch 9/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 1.2277 - accuracy: 0.6915 - val_loss: 1.2616 - val_accuracy: 0.6900\n",
    "Epoch 10/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 1.1872 - accuracy: 0.7038 - val_loss: 1.3190 - val_accuracy: 0.6726\n",
    "Epoch 11/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 1.1571 - accuracy: 0.7128 - val_loss: 1.2867 - val_accuracy: 0.6792\n",
    "Epoch 12/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 1.1277 - accuracy: 0.7219 - val_loss: 1.4620 - val_accuracy: 0.6396\n",
    "Epoch 13/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 1.1028 - accuracy: 0.7280 - val_loss: 1.1590 - val_accuracy: 0.7258\n",
    "Epoch 14/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 1.0755 - accuracy: 0.7381 - val_loss: 1.0992 - val_accuracy: 0.7424\n",
    "Epoch 15/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 1.0511 - accuracy: 0.7459 - val_loss: 1.2855 - val_accuracy: 0.6940\n",
    "Epoch 16/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 1.0278 - accuracy: 0.7506 - val_loss: 1.1468 - val_accuracy: 0.7265\n",
    "Epoch 17/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 1.0140 - accuracy: 0.7562 - val_loss: 1.1902 - val_accuracy: 0.7183\n",
    "Epoch 18/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 0.9820 - accuracy: 0.7662 - val_loss: 1.0532 - val_accuracy: 0.7541\n",
    "Epoch 19/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.9678 - accuracy: 0.7707 - val_loss: 1.0227 - val_accuracy: 0.7582\n",
    "Epoch 20/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 0.9565 - accuracy: 0.7727 - val_loss: 1.0175 - val_accuracy: 0.7660\n",
    "Epoch 21/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 0.9401 - accuracy: 0.7755 - val_loss: 1.0776 - val_accuracy: 0.7495\n",
    "Epoch 22/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.9174 - accuracy: 0.7846 - val_loss: 1.1113 - val_accuracy: 0.7345\n",
    "Epoch 23/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 0.9102 - accuracy: 0.7841 - val_loss: 1.0366 - val_accuracy: 0.7573\n",
    "Epoch 24/500\n",
    "390/390 [==============================] - 110s 282ms/step - loss: 0.8935 - accuracy: 0.7870 - val_loss: 1.1080 - val_accuracy: 0.7364\n",
    "Epoch 25/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 0.8751 - accuracy: 0.7944 - val_loss: 0.9486 - val_accuracy: 0.7782\n",
    "Epoch 26/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 0.8635 - accuracy: 0.7977 - val_loss: 0.9943 - val_accuracy: 0.7717\n",
    "Epoch 27/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 0.8496 - accuracy: 0.8022 - val_loss: 0.9457 - val_accuracy: 0.7786\n",
    "Epoch 28/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.8395 - accuracy: 0.8027 - val_loss: 0.9368 - val_accuracy: 0.7791\n",
    "Epoch 29/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.8291 - accuracy: 0.8066 - val_loss: 0.9918 - val_accuracy: 0.7723\n",
    "Epoch 30/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.8171 - accuracy: 0.8100 - val_loss: 1.0488 - val_accuracy: 0.7564\n",
    "Epoch 31/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.8074 - accuracy: 0.8119 - val_loss: 0.8897 - val_accuracy: 0.7932\n",
    "Epoch 32/500\n",
    "390/390 [==============================] - 110s 282ms/step - loss: 0.7953 - accuracy: 0.8157 - val_loss: 0.8769 - val_accuracy: 0.8045\n",
    "Epoch 33/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.7836 - accuracy: 0.8187 - val_loss: 0.8802 - val_accuracy: 0.8007\n",
    "Epoch 34/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 0.7703 - accuracy: 0.8216 - val_loss: 0.8704 - val_accuracy: 0.8038\n",
    "Epoch 35/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 0.7665 - accuracy: 0.8241 - val_loss: 0.8473 - val_accuracy: 0.8063\n",
    "Epoch 36/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.7571 - accuracy: 0.8253 - val_loss: 0.9571 - val_accuracy: 0.7805\n",
    "Epoch 37/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.7461 - accuracy: 0.8266 - val_loss: 0.8691 - val_accuracy: 0.7997\n",
    "Epoch 38/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 0.7360 - accuracy: 0.8314 - val_loss: 0.9446 - val_accuracy: 0.7772\n",
    "Epoch 39/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 0.7283 - accuracy: 0.8309 - val_loss: 0.8442 - val_accuracy: 0.8037\n",
    "Epoch 40/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 0.7202 - accuracy: 0.8347 - val_loss: 0.8885 - val_accuracy: 0.7935\n",
    "Epoch 41/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.7188 - accuracy: 0.8330 - val_loss: 0.8955 - val_accuracy: 0.7898\n",
    "Epoch 42/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.7046 - accuracy: 0.8397 - val_loss: 0.8608 - val_accuracy: 0.8028\n",
    "Epoch 43/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 0.6946 - accuracy: 0.8395 - val_loss: 0.8278 - val_accuracy: 0.8117\n",
    "Epoch 44/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.6887 - accuracy: 0.8418 - val_loss: 0.8742 - val_accuracy: 0.7925\n",
    "Epoch 45/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.6783 - accuracy: 0.8446 - val_loss: 0.8551 - val_accuracy: 0.8005\n",
    "Epoch 46/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.6786 - accuracy: 0.8439 - val_loss: 0.8351 - val_accuracy: 0.8032\n",
    "Epoch 47/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.6651 - accuracy: 0.8478 - val_loss: 0.8334 - val_accuracy: 0.8021\n",
    "Epoch 48/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 0.6626 - accuracy: 0.8482 - val_loss: 0.8033 - val_accuracy: 0.8168\n",
    "Epoch 49/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 0.6481 - accuracy: 0.8510 - val_loss: 0.8713 - val_accuracy: 0.8006\n",
    "Epoch 50/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.6409 - accuracy: 0.8544 - val_loss: 0.8011 - val_accuracy: 0.8171\n",
    "Epoch 51/500\n",
    "390/390 [==============================] - 110s 283ms/step - loss: 0.6448 - accuracy: 0.8517 - val_loss: 0.8453 - val_accuracy: 0.8102\n",
    "Epoch 52/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.6380 - accuracy: 0.8545 - val_loss: 0.7950 - val_accuracy: 0.8185\n",
    "Epoch 53/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 0.6299 - accuracy: 0.8556 - val_loss: 0.7773 - val_accuracy: 0.8177\n",
    "Epoch 54/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.6212 - accuracy: 0.8579 - val_loss: 0.7947 - val_accuracy: 0.8141\n",
    "Epoch 55/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 0.6146 - accuracy: 0.8589 - val_loss: 0.9437 - val_accuracy: 0.7802\n",
    "Epoch 56/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 0.6104 - accuracy: 0.8621 - val_loss: 0.8790 - val_accuracy: 0.7928\n",
    "Epoch 57/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.6028 - accuracy: 0.8638 - val_loss: 0.8848 - val_accuracy: 0.7962\n",
    "Epoch 58/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.6024 - accuracy: 0.8619 - val_loss: 0.7880 - val_accuracy: 0.8196\n",
    "Epoch 59/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 0.5957 - accuracy: 0.8625 - val_loss: 0.8284 - val_accuracy: 0.8092\n",
    "Epoch 60/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 0.5872 - accuracy: 0.8674 - val_loss: 0.7586 - val_accuracy: 0.8216\n",
    "Epoch 61/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.5825 - accuracy: 0.8671 - val_loss: 0.7995 - val_accuracy: 0.8161\n",
    "Epoch 62/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.5796 - accuracy: 0.8667 - val_loss: 0.8975 - val_accuracy: 0.7895\n",
    "Epoch 63/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.5733 - accuracy: 0.8684 - val_loss: 0.8706 - val_accuracy: 0.7936\n",
    "Epoch 64/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.5711 - accuracy: 0.8687 - val_loss: 0.8334 - val_accuracy: 0.8098\n",
    "Epoch 65/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.5611 - accuracy: 0.8732 - val_loss: 0.7812 - val_accuracy: 0.8222\n",
    "Epoch 66/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.5616 - accuracy: 0.8715 - val_loss: 0.7427 - val_accuracy: 0.8254\n",
    "Epoch 67/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.5570 - accuracy: 0.8726 - val_loss: 0.7551 - val_accuracy: 0.8251\n",
    "Epoch 68/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.5540 - accuracy: 0.8728 - val_loss: 0.7871 - val_accuracy: 0.8099\n",
    "Epoch 69/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.5490 - accuracy: 0.8751 - val_loss: 0.7427 - val_accuracy: 0.8269\n",
    "Epoch 70/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.5395 - accuracy: 0.8779 - val_loss: 0.8832 - val_accuracy: 0.7881\n",
    "Epoch 71/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.5393 - accuracy: 0.8781 - val_loss: 0.7371 - val_accuracy: 0.8270\n",
    "Epoch 72/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 0.5325 - accuracy: 0.8798 - val_loss: 0.7335 - val_accuracy: 0.8280\n",
    "Epoch 73/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 0.5226 - accuracy: 0.8812 - val_loss: 0.7645 - val_accuracy: 0.8163\n",
    "Epoch 74/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.5194 - accuracy: 0.8835 - val_loss: 0.7325 - val_accuracy: 0.8299\n",
    "Epoch 75/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.5207 - accuracy: 0.8827 - val_loss: 0.8524 - val_accuracy: 0.8052\n",
    "Epoch 76/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 0.5116 - accuracy: 0.8845 - val_loss: 0.7493 - val_accuracy: 0.8271\n",
    "Epoch 77/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.5109 - accuracy: 0.8835 - val_loss: 0.7522 - val_accuracy: 0.8217\n",
    "Epoch 78/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.5116 - accuracy: 0.8841 - val_loss: 0.8058 - val_accuracy: 0.8078\n",
    "Epoch 79/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 0.5080 - accuracy: 0.8839 - val_loss: 0.7211 - val_accuracy: 0.8263\n",
    "Epoch 80/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 0.5034 - accuracy: 0.8851 - val_loss: 0.7202 - val_accuracy: 0.8322\n",
    "Epoch 81/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 0.5016 - accuracy: 0.8879 - val_loss: 0.7210 - val_accuracy: 0.8264\n",
    "Epoch 82/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.4918 - accuracy: 0.8876 - val_loss: 0.7478 - val_accuracy: 0.8233\n",
    "Epoch 83/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.4968 - accuracy: 0.8874 - val_loss: 0.7869 - val_accuracy: 0.8167\n",
    "Epoch 84/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 0.4822 - accuracy: 0.8937 - val_loss: 0.7451 - val_accuracy: 0.8288\n",
    "Epoch 85/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.4860 - accuracy: 0.8910 - val_loss: 0.7508 - val_accuracy: 0.8233\n",
    "Epoch 86/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.4840 - accuracy: 0.8903 - val_loss: 0.7341 - val_accuracy: 0.8239\n",
    "Epoch 87/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 0.4801 - accuracy: 0.8912 - val_loss: 0.6927 - val_accuracy: 0.8367\n",
    "Epoch 88/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 0.4740 - accuracy: 0.8934 - val_loss: 0.8767 - val_accuracy: 0.7975\n",
    "Epoch 89/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 0.4719 - accuracy: 0.8948 - val_loss: 0.7124 - val_accuracy: 0.8346\n",
    "Epoch 90/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.4704 - accuracy: 0.8945 - val_loss: 0.7406 - val_accuracy: 0.8249\n",
    "Epoch 91/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.4657 - accuracy: 0.8954 - val_loss: 0.7814 - val_accuracy: 0.8118\n",
    "Epoch 92/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.4678 - accuracy: 0.8940 - val_loss: 0.6929 - val_accuracy: 0.8324\n",
    "Epoch 93/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 0.4588 - accuracy: 0.8968 - val_loss: 0.7917 - val_accuracy: 0.8235\n",
    "Epoch 94/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.4602 - accuracy: 0.8974 - val_loss: 0.8237 - val_accuracy: 0.8075\n",
    "Epoch 95/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 0.4539 - accuracy: 0.8973 - val_loss: 0.8110 - val_accuracy: 0.8133\n",
    "Epoch 96/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 0.4526 - accuracy: 0.8981 - val_loss: 0.7317 - val_accuracy: 0.8185\n",
    "Epoch 97/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.4570 - accuracy: 0.8967 - val_loss: 0.6710 - val_accuracy: 0.8415\n",
    "Epoch 98/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.4524 - accuracy: 0.8983 - val_loss: 0.6893 - val_accuracy: 0.8344\n",
    "Epoch 99/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.4493 - accuracy: 0.8990 - val_loss: 0.6305 - val_accuracy: 0.8499\n",
    "Epoch 100/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.4414 - accuracy: 0.9012 - val_loss: 0.7630 - val_accuracy: 0.8216\n",
    "Epoch 101/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 0.4423 - accuracy: 0.9009 - val_loss: 0.7386 - val_accuracy: 0.8312\n",
    "Epoch 102/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.4368 - accuracy: 0.9036 - val_loss: 0.7295 - val_accuracy: 0.8280\n",
    "Epoch 103/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.4348 - accuracy: 0.9043 - val_loss: 0.6502 - val_accuracy: 0.8453\n",
    "Epoch 104/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 0.4333 - accuracy: 0.9055 - val_loss: 0.6806 - val_accuracy: 0.8392\n",
    "Epoch 105/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.4319 - accuracy: 0.9046 - val_loss: 0.7490 - val_accuracy: 0.8239\n",
    "Epoch 106/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 0.4257 - accuracy: 0.9059 - val_loss: 0.9395 - val_accuracy: 0.7869\n",
    "Epoch 107/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.4251 - accuracy: 0.9052 - val_loss: 0.7368 - val_accuracy: 0.8312\n",
    "Epoch 108/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.4276 - accuracy: 0.9051 - val_loss: 0.6543 - val_accuracy: 0.8467\n",
    "Epoch 109/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 0.4259 - accuracy: 0.9058 - val_loss: 0.7818 - val_accuracy: 0.8148\n",
    "Epoch 110/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.4130 - accuracy: 0.9092 - val_loss: 0.7225 - val_accuracy: 0.8326\n",
    "Epoch 111/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.4205 - accuracy: 0.9060 - val_loss: 0.7117 - val_accuracy: 0.8322\n",
    "Epoch 112/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 0.4246 - accuracy: 0.9067 - val_loss: 0.6748 - val_accuracy: 0.8395\n",
    "Epoch 113/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.4124 - accuracy: 0.9097 - val_loss: 0.6957 - val_accuracy: 0.8390\n",
    "Epoch 114/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.4117 - accuracy: 0.9093 - val_loss: 0.7909 - val_accuracy: 0.8077\n",
    "Epoch 115/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 0.4105 - accuracy: 0.9108 - val_loss: 0.6461 - val_accuracy: 0.8505\n",
    "Epoch 116/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 0.4098 - accuracy: 0.9098 - val_loss: 0.6621 - val_accuracy: 0.8461\n",
    "Epoch 117/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.4041 - accuracy: 0.9119 - val_loss: 0.6754 - val_accuracy: 0.8404\n",
    "Epoch 118/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.4013 - accuracy: 0.9117 - val_loss: 0.6281 - val_accuracy: 0.8512\n",
    "Epoch 119/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.4081 - accuracy: 0.9091 - val_loss: 0.7457 - val_accuracy: 0.8332\n",
    "Epoch 120/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.4034 - accuracy: 0.9101 - val_loss: 0.6785 - val_accuracy: 0.8379\n",
    "Epoch 121/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.4027 - accuracy: 0.9112 - val_loss: 0.6523 - val_accuracy: 0.8470\n",
    "Epoch 122/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.3946 - accuracy: 0.9141 - val_loss: 0.7062 - val_accuracy: 0.8365\n",
    "Epoch 123/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.3935 - accuracy: 0.9137 - val_loss: 0.6977 - val_accuracy: 0.8402\n",
    "Epoch 124/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.3941 - accuracy: 0.9137 - val_loss: 0.7185 - val_accuracy: 0.8353\n",
    "Epoch 125/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.3899 - accuracy: 0.9143 - val_loss: 0.6906 - val_accuracy: 0.8425\n",
    "Epoch 126/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 0.3896 - accuracy: 0.9152 - val_loss: 0.6042 - val_accuracy: 0.8622\n",
    "Epoch 127/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.3888 - accuracy: 0.9163 - val_loss: 0.7511 - val_accuracy: 0.8306\n",
    "Epoch 128/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 0.3904 - accuracy: 0.9142 - val_loss: 0.7261 - val_accuracy: 0.8339\n",
    "Epoch 129/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 0.3933 - accuracy: 0.9150 - val_loss: 0.6887 - val_accuracy: 0.8487\n",
    "Epoch 130/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.3860 - accuracy: 0.9166 - val_loss: 0.7198 - val_accuracy: 0.8274\n",
    "Epoch 131/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.3850 - accuracy: 0.9156 - val_loss: 0.7012 - val_accuracy: 0.8405\n",
    "Epoch 132/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.3825 - accuracy: 0.9178 - val_loss: 0.7076 - val_accuracy: 0.8367\n",
    "Epoch 133/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.3788 - accuracy: 0.9196 - val_loss: 0.7418 - val_accuracy: 0.8290\n",
    "Epoch 134/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.3798 - accuracy: 0.9185 - val_loss: 0.7080 - val_accuracy: 0.8364\n",
    "Epoch 135/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.3791 - accuracy: 0.9178 - val_loss: 0.7835 - val_accuracy: 0.8224\n",
    "Epoch 136/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.3745 - accuracy: 0.9192 - val_loss: 0.7252 - val_accuracy: 0.8296\n",
    "Epoch 137/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 0.3781 - accuracy: 0.9176 - val_loss: 0.6736 - val_accuracy: 0.8435\n",
    "Epoch 138/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.3738 - accuracy: 0.9198 - val_loss: 0.6460 - val_accuracy: 0.8524\n",
    "Epoch 139/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.3719 - accuracy: 0.9196 - val_loss: 0.6453 - val_accuracy: 0.8457\n",
    "Epoch 140/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.3690 - accuracy: 0.9213 - val_loss: 0.7210 - val_accuracy: 0.8305\n",
    "Epoch 141/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.3767 - accuracy: 0.9187 - val_loss: 0.7102 - val_accuracy: 0.8349\n",
    "Epoch 142/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.3657 - accuracy: 0.9209 - val_loss: 0.7309 - val_accuracy: 0.8375\n",
    "Epoch 143/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.3657 - accuracy: 0.9228 - val_loss: 0.6755 - val_accuracy: 0.8485\n",
    "Epoch 144/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 0.3686 - accuracy: 0.9208 - val_loss: 0.7396 - val_accuracy: 0.8297\n",
    "Epoch 145/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.3676 - accuracy: 0.9205 - val_loss: 0.6342 - val_accuracy: 0.8523\n",
    "Epoch 146/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.3641 - accuracy: 0.9215 - val_loss: 0.6575 - val_accuracy: 0.8448\n",
    "Epoch 147/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.3655 - accuracy: 0.9216 - val_loss: 0.7022 - val_accuracy: 0.8398\n",
    "Epoch 148/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.3623 - accuracy: 0.9226 - val_loss: 0.6499 - val_accuracy: 0.8494\n",
    "Epoch 149/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.3616 - accuracy: 0.9224 - val_loss: 0.6991 - val_accuracy: 0.8424\n",
    "Epoch 150/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.3611 - accuracy: 0.9227 - val_loss: 0.6561 - val_accuracy: 0.8502\n",
    "Epoch 151/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.3562 - accuracy: 0.9257 - val_loss: 0.6600 - val_accuracy: 0.8482\n",
    "Epoch 152/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.3582 - accuracy: 0.9235 - val_loss: 0.7339 - val_accuracy: 0.8293\n",
    "Epoch 153/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.3555 - accuracy: 0.9254 - val_loss: 0.7092 - val_accuracy: 0.8417\n",
    "Epoch 154/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.3557 - accuracy: 0.9238 - val_loss: 0.6888 - val_accuracy: 0.8460\n",
    "Epoch 155/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.3568 - accuracy: 0.9242 - val_loss: 0.6725 - val_accuracy: 0.8451\n",
    "Epoch 156/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.3535 - accuracy: 0.9251 - val_loss: 0.7240 - val_accuracy: 0.8294\n",
    "Epoch 157/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.3492 - accuracy: 0.9276 - val_loss: 0.6655 - val_accuracy: 0.8537\n",
    "Epoch 158/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.3497 - accuracy: 0.9259 - val_loss: 0.6961 - val_accuracy: 0.8421\n",
    "Epoch 159/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.3507 - accuracy: 0.9258 - val_loss: 0.7412 - val_accuracy: 0.8317\n",
    "Epoch 160/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 0.3456 - accuracy: 0.9278 - val_loss: 0.7584 - val_accuracy: 0.8320\n",
    "Epoch 161/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.3515 - accuracy: 0.9255 - val_loss: 0.7653 - val_accuracy: 0.8323\n",
    "Epoch 162/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.3485 - accuracy: 0.9273 - val_loss: 0.8621 - val_accuracy: 0.8102\n",
    "Epoch 163/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.3431 - accuracy: 0.9284 - val_loss: 0.6966 - val_accuracy: 0.8400\n",
    "Epoch 164/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.3473 - accuracy: 0.9263 - val_loss: 0.6647 - val_accuracy: 0.8458\n",
    "Epoch 165/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.3493 - accuracy: 0.9256 - val_loss: 0.7269 - val_accuracy: 0.8378\n",
    "Epoch 166/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.3417 - accuracy: 0.9282 - val_loss: 0.6705 - val_accuracy: 0.8467\n",
    "Epoch 167/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.3437 - accuracy: 0.9283 - val_loss: 0.6731 - val_accuracy: 0.8454\n",
    "Epoch 168/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 0.3427 - accuracy: 0.9290 - val_loss: 0.6205 - val_accuracy: 0.8632\n",
    "Epoch 169/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.3345 - accuracy: 0.9321 - val_loss: 0.6706 - val_accuracy: 0.8445\n",
    "Epoch 170/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.3428 - accuracy: 0.9280 - val_loss: 0.6996 - val_accuracy: 0.8395\n",
    "Epoch 171/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.3418 - accuracy: 0.9286 - val_loss: 0.7535 - val_accuracy: 0.8222\n",
    "Epoch 172/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.3368 - accuracy: 0.9298 - val_loss: 0.6665 - val_accuracy: 0.8473\n",
    "Epoch 173/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.3376 - accuracy: 0.9288 - val_loss: 0.7368 - val_accuracy: 0.8275\n",
    "Epoch 174/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.3312 - accuracy: 0.9310 - val_loss: 0.6454 - val_accuracy: 0.8510\n",
    "Epoch 175/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.3346 - accuracy: 0.9298 - val_loss: 0.7085 - val_accuracy: 0.8391\n",
    "Epoch 176/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.3343 - accuracy: 0.9304 - val_loss: 0.7461 - val_accuracy: 0.8379\n",
    "Epoch 177/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.3363 - accuracy: 0.9302 - val_loss: 0.8247 - val_accuracy: 0.8162\n",
    "Epoch 178/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.3359 - accuracy: 0.9303 - val_loss: 0.6700 - val_accuracy: 0.8463\n",
    "Epoch 179/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.3332 - accuracy: 0.9315 - val_loss: 0.7507 - val_accuracy: 0.8346\n",
    "Epoch 180/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 0.3345 - accuracy: 0.9317 - val_loss: 0.6369 - val_accuracy: 0.8548\n",
    "Epoch 181/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 0.3288 - accuracy: 0.9323 - val_loss: 0.6668 - val_accuracy: 0.8444\n",
    "Epoch 182/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.3256 - accuracy: 0.9342 - val_loss: 0.7236 - val_accuracy: 0.8449\n",
    "Epoch 183/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.3316 - accuracy: 0.9312 - val_loss: 0.7541 - val_accuracy: 0.8382\n",
    "Epoch 184/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.3286 - accuracy: 0.9326 - val_loss: 0.6289 - val_accuracy: 0.8535\n",
    "Epoch 185/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.3266 - accuracy: 0.9327 - val_loss: 0.6611 - val_accuracy: 0.8476\n",
    "Epoch 186/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.3289 - accuracy: 0.9318 - val_loss: 0.7026 - val_accuracy: 0.8415\n",
    "Epoch 187/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.3318 - accuracy: 0.9321 - val_loss: 0.7372 - val_accuracy: 0.8318\n",
    "Epoch 188/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.3292 - accuracy: 0.9323 - val_loss: 0.6257 - val_accuracy: 0.8538\n",
    "Epoch 189/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.3286 - accuracy: 0.9333 - val_loss: 0.6941 - val_accuracy: 0.8452\n",
    "Epoch 190/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.3272 - accuracy: 0.9327 - val_loss: 0.7283 - val_accuracy: 0.8353\n",
    "Epoch 191/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.3183 - accuracy: 0.9364 - val_loss: 0.7015 - val_accuracy: 0.8436\n",
    "Epoch 192/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.3251 - accuracy: 0.9340 - val_loss: 0.7640 - val_accuracy: 0.8329\n",
    "Epoch 193/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.3232 - accuracy: 0.9339 - val_loss: 0.6122 - val_accuracy: 0.8564\n",
    "Epoch 194/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.3223 - accuracy: 0.9345 - val_loss: 0.6764 - val_accuracy: 0.8485\n",
    "Epoch 195/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.3215 - accuracy: 0.9354 - val_loss: 0.6869 - val_accuracy: 0.8418\n",
    "Epoch 196/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.3213 - accuracy: 0.9353 - val_loss: 0.6983 - val_accuracy: 0.8443\n",
    "Epoch 197/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.3198 - accuracy: 0.9345 - val_loss: 0.7679 - val_accuracy: 0.8276\n",
    "Epoch 198/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.3177 - accuracy: 0.9353 - val_loss: 0.6658 - val_accuracy: 0.8462\n",
    "Epoch 199/500\n",
    "390/390 [==============================] - 110s 283ms/step - loss: 0.3215 - accuracy: 0.9344 - val_loss: 0.8749 - val_accuracy: 0.8120\n",
    "Epoch 200/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 0.3194 - accuracy: 0.9358 - val_loss: 0.7133 - val_accuracy: 0.8388\n",
    "Epoch 201/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.3197 - accuracy: 0.9349 - val_loss: 0.7902 - val_accuracy: 0.8310\n",
    "Epoch 202/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.3195 - accuracy: 0.9365 - val_loss: 0.7068 - val_accuracy: 0.8398\n",
    "Epoch 203/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 0.3141 - accuracy: 0.9374 - val_loss: 0.7026 - val_accuracy: 0.8394\n",
    "Epoch 204/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.3202 - accuracy: 0.9355 - val_loss: 0.6624 - val_accuracy: 0.8476\n",
    "Epoch 205/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.3191 - accuracy: 0.9349 - val_loss: 0.7917 - val_accuracy: 0.8253\n",
    "Epoch 206/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.3161 - accuracy: 0.9364 - val_loss: 0.8080 - val_accuracy: 0.8276\n",
    "Epoch 207/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.3089 - accuracy: 0.9391 - val_loss: 0.6986 - val_accuracy: 0.8434\n",
    "Epoch 208/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.3109 - accuracy: 0.9383 - val_loss: 0.6794 - val_accuracy: 0.8427\n",
    "Epoch 209/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 0.3116 - accuracy: 0.9369 - val_loss: 0.6797 - val_accuracy: 0.8463\n",
    "Epoch 210/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.3161 - accuracy: 0.9360 - val_loss: 0.7264 - val_accuracy: 0.8365\n",
    "Epoch 211/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 0.3099 - accuracy: 0.9386 - val_loss: 0.6726 - val_accuracy: 0.8505\n",
    "Epoch 212/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.3094 - accuracy: 0.9391 - val_loss: 0.7146 - val_accuracy: 0.8398\n",
    "Epoch 213/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.3088 - accuracy: 0.9388 - val_loss: 0.7955 - val_accuracy: 0.8320\n",
    "Epoch 214/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.3119 - accuracy: 0.9386 - val_loss: 0.7168 - val_accuracy: 0.8363\n",
    "Epoch 215/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.3089 - accuracy: 0.9389 - val_loss: 0.6878 - val_accuracy: 0.8492\n",
    "Epoch 216/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.3151 - accuracy: 0.9362 - val_loss: 0.7203 - val_accuracy: 0.8379\n",
    "Epoch 217/500\n",
    "390/390 [==============================] - 110s 283ms/step - loss: 0.3067 - accuracy: 0.9397 - val_loss: 0.7213 - val_accuracy: 0.8420\n",
    "Epoch 218/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.3131 - accuracy: 0.9376 - val_loss: 0.6650 - val_accuracy: 0.8522\n",
    "Epoch 219/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 0.3060 - accuracy: 0.9396 - val_loss: 0.7011 - val_accuracy: 0.8440\n",
    "Epoch 220/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.3075 - accuracy: 0.9400 - val_loss: 0.6790 - val_accuracy: 0.8543\n",
    "Epoch 221/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.3046 - accuracy: 0.9413 - val_loss: 0.6216 - val_accuracy: 0.8585\n",
    "Epoch 222/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.3099 - accuracy: 0.9373 - val_loss: 0.6922 - val_accuracy: 0.8502\n",
    "Epoch 223/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.3038 - accuracy: 0.9404 - val_loss: 0.6552 - val_accuracy: 0.8478\n",
    "Epoch 224/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.3005 - accuracy: 0.9418 - val_loss: 0.6608 - val_accuracy: 0.8510\n",
    "Epoch 225/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.3073 - accuracy: 0.9390 - val_loss: 0.6958 - val_accuracy: 0.8508\n",
    "Epoch 226/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.3046 - accuracy: 0.9410 - val_loss: 0.6881 - val_accuracy: 0.8473\n",
    "Epoch 227/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.3084 - accuracy: 0.9383 - val_loss: 0.8249 - val_accuracy: 0.8274\n",
    "Epoch 228/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.3040 - accuracy: 0.9410 - val_loss: 0.6705 - val_accuracy: 0.8480\n",
    "Epoch 229/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.3043 - accuracy: 0.9394 - val_loss: 0.6781 - val_accuracy: 0.8474\n",
    "Epoch 230/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.3042 - accuracy: 0.9412 - val_loss: 0.7273 - val_accuracy: 0.8329\n",
    "Epoch 231/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 0.3017 - accuracy: 0.9417 - val_loss: 0.6684 - val_accuracy: 0.8465\n",
    "Epoch 232/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 0.3011 - accuracy: 0.9410 - val_loss: 0.6391 - val_accuracy: 0.8602\n",
    "Epoch 233/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.2978 - accuracy: 0.9421 - val_loss: 0.6991 - val_accuracy: 0.8495\n",
    "Epoch 234/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.3034 - accuracy: 0.9408 - val_loss: 0.6925 - val_accuracy: 0.8489\n",
    "Epoch 235/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.2976 - accuracy: 0.9433 - val_loss: 0.6635 - val_accuracy: 0.8527\n",
    "Epoch 236/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 0.3014 - accuracy: 0.9418 - val_loss: 0.7973 - val_accuracy: 0.8294\n",
    "Epoch 237/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.2985 - accuracy: 0.9419 - val_loss: 0.6742 - val_accuracy: 0.8506\n",
    "Epoch 238/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.3011 - accuracy: 0.9413 - val_loss: 0.7191 - val_accuracy: 0.8471\n",
    "Epoch 239/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.3012 - accuracy: 0.9401 - val_loss: 0.6431 - val_accuracy: 0.8521\n",
    "Epoch 240/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.2997 - accuracy: 0.9419 - val_loss: 0.7556 - val_accuracy: 0.8458\n",
    "Epoch 241/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.3001 - accuracy: 0.9402 - val_loss: 0.6356 - val_accuracy: 0.8536\n",
    "Epoch 242/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.2992 - accuracy: 0.9418 - val_loss: 0.6312 - val_accuracy: 0.8588\n",
    "Epoch 243/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.3016 - accuracy: 0.9401 - val_loss: 0.7272 - val_accuracy: 0.8391\n",
    "Epoch 244/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 0.2998 - accuracy: 0.9414 - val_loss: 0.7180 - val_accuracy: 0.8344\n",
    "Epoch 245/500\n",
    "390/390 [==============================] - 110s 282ms/step - loss: 0.2952 - accuracy: 0.9445 - val_loss: 0.7679 - val_accuracy: 0.8362\n",
    "Epoch 246/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.3008 - accuracy: 0.9416 - val_loss: 0.6788 - val_accuracy: 0.8516\n",
    "Epoch 247/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 0.2944 - accuracy: 0.9441 - val_loss: 0.6949 - val_accuracy: 0.8504\n",
    "Epoch 248/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.2988 - accuracy: 0.9417 - val_loss: 0.6695 - val_accuracy: 0.8514\n",
    "Epoch 249/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.2939 - accuracy: 0.9447 - val_loss: 0.8013 - val_accuracy: 0.8193\n",
    "Epoch 250/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.2916 - accuracy: 0.9452 - val_loss: 0.6845 - val_accuracy: 0.8430\n",
    "Epoch 251/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 0.2937 - accuracy: 0.9430 - val_loss: 0.7472 - val_accuracy: 0.8389\n",
    "Epoch 252/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.2934 - accuracy: 0.9437 - val_loss: 0.6337 - val_accuracy: 0.8567\n",
    "Epoch 253/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.2920 - accuracy: 0.9455 - val_loss: 0.6658 - val_accuracy: 0.8507\n",
    "Epoch 254/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.2876 - accuracy: 0.9450 - val_loss: 0.6713 - val_accuracy: 0.8532\n",
    "Epoch 255/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.2917 - accuracy: 0.9438 - val_loss: 0.7080 - val_accuracy: 0.8413\n",
    "Epoch 256/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 0.2980 - accuracy: 0.9416 - val_loss: 0.7020 - val_accuracy: 0.8435\n",
    "Epoch 257/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 0.2899 - accuracy: 0.9449 - val_loss: 0.6924 - val_accuracy: 0.8512\n",
    "Epoch 258/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.2943 - accuracy: 0.9447 - val_loss: 0.6810 - val_accuracy: 0.8489\n",
    "Epoch 259/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 0.2940 - accuracy: 0.9434 - val_loss: 0.8251 - val_accuracy: 0.8239\n",
    "Epoch 260/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.2934 - accuracy: 0.9432 - val_loss: 0.7448 - val_accuracy: 0.8392\n",
    "Epoch 261/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 0.2884 - accuracy: 0.9458 - val_loss: 0.6474 - val_accuracy: 0.8575\n",
    "Epoch 262/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.2962 - accuracy: 0.9420 - val_loss: 0.7087 - val_accuracy: 0.8501\n",
    "Epoch 263/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.2887 - accuracy: 0.9453 - val_loss: 0.6648 - val_accuracy: 0.8578\n",
    "Epoch 264/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.2879 - accuracy: 0.9457 - val_loss: 0.8294 - val_accuracy: 0.8290\n",
    "Epoch 265/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 0.2920 - accuracy: 0.9450 - val_loss: 0.6918 - val_accuracy: 0.8468\n",
    "Epoch 266/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.2938 - accuracy: 0.9432 - val_loss: 0.6478 - val_accuracy: 0.8582\n",
    "Epoch 267/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.2898 - accuracy: 0.9453 - val_loss: 0.6158 - val_accuracy: 0.8626\n",
    "Epoch 268/500\n",
    "390/390 [==============================] - 110s 283ms/step - loss: 0.2877 - accuracy: 0.9446 - val_loss: 0.8230 - val_accuracy: 0.8223\n",
    "Epoch 269/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.2908 - accuracy: 0.9447 - val_loss: 0.6714 - val_accuracy: 0.8470\n",
    "Epoch 270/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.2868 - accuracy: 0.9467 - val_loss: 0.6512 - val_accuracy: 0.8538\n",
    "Epoch 271/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.2885 - accuracy: 0.9455 - val_loss: 0.6484 - val_accuracy: 0.8568\n",
    "Epoch 272/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.2928 - accuracy: 0.9437 - val_loss: 0.6663 - val_accuracy: 0.8477\n",
    "Epoch 273/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 0.2873 - accuracy: 0.9464 - val_loss: 0.7923 - val_accuracy: 0.8270\n",
    "Epoch 274/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 0.2907 - accuracy: 0.9440 - val_loss: 0.7000 - val_accuracy: 0.8391\n",
    "Epoch 275/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.2882 - accuracy: 0.9450 - val_loss: 0.6631 - val_accuracy: 0.8568\n",
    "Epoch 276/500\n",
    "390/390 [==============================] - 110s 282ms/step - loss: 0.2861 - accuracy: 0.9453 - val_loss: 0.5883 - val_accuracy: 0.8659\n",
    "Epoch 277/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.2842 - accuracy: 0.9467 - val_loss: 0.7048 - val_accuracy: 0.8468\n",
    "Epoch 278/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.2877 - accuracy: 0.9462 - val_loss: 0.6291 - val_accuracy: 0.8538\n",
    "Epoch 279/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.2888 - accuracy: 0.9445 - val_loss: 0.7404 - val_accuracy: 0.8354\n",
    "Epoch 280/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.2836 - accuracy: 0.9466 - val_loss: 0.7674 - val_accuracy: 0.8370\n",
    "Epoch 281/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.2892 - accuracy: 0.9446 - val_loss: 0.7080 - val_accuracy: 0.8475\n",
    "Epoch 282/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.2880 - accuracy: 0.9452 - val_loss: 0.7282 - val_accuracy: 0.8448\n",
    "Epoch 283/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.2869 - accuracy: 0.9450 - val_loss: 0.6440 - val_accuracy: 0.8607\n",
    "Epoch 284/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.2859 - accuracy: 0.9458 - val_loss: 0.6764 - val_accuracy: 0.8526\n",
    "Epoch 285/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 0.2879 - accuracy: 0.9450 - val_loss: 0.7023 - val_accuracy: 0.8520\n",
    "Epoch 286/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.2799 - accuracy: 0.9495 - val_loss: 0.6175 - val_accuracy: 0.8683\n",
    "Epoch 287/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.2827 - accuracy: 0.9475 - val_loss: 0.8263 - val_accuracy: 0.8273\n",
    "Epoch 288/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.2795 - accuracy: 0.9479 - val_loss: 0.6924 - val_accuracy: 0.8450\n",
    "Epoch 289/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.2856 - accuracy: 0.9450 - val_loss: 0.7191 - val_accuracy: 0.8407\n",
    "Epoch 290/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.2855 - accuracy: 0.9466 - val_loss: 0.6592 - val_accuracy: 0.8526\n",
    "Epoch 291/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.2824 - accuracy: 0.9471 - val_loss: 0.7608 - val_accuracy: 0.8409\n",
    "Epoch 292/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.2832 - accuracy: 0.9471 - val_loss: 0.6451 - val_accuracy: 0.8550\n",
    "Epoch 293/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.2814 - accuracy: 0.9486 - val_loss: 0.6678 - val_accuracy: 0.8492\n",
    "Epoch 294/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.2799 - accuracy: 0.9482 - val_loss: 0.6797 - val_accuracy: 0.8521\n",
    "Epoch 295/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.2859 - accuracy: 0.9457 - val_loss: 0.6798 - val_accuracy: 0.8507\n",
    "Epoch 296/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.2834 - accuracy: 0.9474 - val_loss: 0.6828 - val_accuracy: 0.8566\n",
    "Epoch 297/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.2803 - accuracy: 0.9488 - val_loss: 0.6909 - val_accuracy: 0.8460\n",
    "Epoch 298/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.2798 - accuracy: 0.9485 - val_loss: 0.6899 - val_accuracy: 0.8437\n",
    "Epoch 299/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.2770 - accuracy: 0.9484 - val_loss: 0.6863 - val_accuracy: 0.8503\n",
    "Epoch 300/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.2809 - accuracy: 0.9467 - val_loss: 0.6927 - val_accuracy: 0.8499\n",
    "Epoch 301/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.2792 - accuracy: 0.9484 - val_loss: 0.6560 - val_accuracy: 0.8580\n",
    "Epoch 302/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.2802 - accuracy: 0.9472 - val_loss: 0.6405 - val_accuracy: 0.8626\n",
    "Epoch 303/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.2779 - accuracy: 0.9488 - val_loss: 0.6713 - val_accuracy: 0.8536\n",
    "Epoch 304/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.2779 - accuracy: 0.9496 - val_loss: 0.6530 - val_accuracy: 0.8614\n",
    "Epoch 305/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.2770 - accuracy: 0.9488 - val_loss: 0.7120 - val_accuracy: 0.8528\n",
    "Epoch 306/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.2791 - accuracy: 0.9481 - val_loss: 0.6720 - val_accuracy: 0.8495\n",
    "Epoch 307/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.2819 - accuracy: 0.9472 - val_loss: 0.7144 - val_accuracy: 0.8472\n",
    "Epoch 308/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.2753 - accuracy: 0.9498 - val_loss: 0.7666 - val_accuracy: 0.8306\n",
    "Epoch 309/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.2816 - accuracy: 0.9475 - val_loss: 0.6860 - val_accuracy: 0.8523\n",
    "Epoch 310/500\n",
    "390/390 [==============================] - 110s 282ms/step - loss: 0.2776 - accuracy: 0.9483 - val_loss: 0.6804 - val_accuracy: 0.8555\n",
    "Epoch 311/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.2786 - accuracy: 0.9486 - val_loss: 0.7367 - val_accuracy: 0.8473\n",
    "Epoch 312/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.2726 - accuracy: 0.9506 - val_loss: 0.7451 - val_accuracy: 0.8436\n",
    "Epoch 313/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 0.2743 - accuracy: 0.9501 - val_loss: 0.6761 - val_accuracy: 0.8491\n",
    "Epoch 314/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.2786 - accuracy: 0.9481 - val_loss: 0.7307 - val_accuracy: 0.8401\n",
    "Epoch 315/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.2759 - accuracy: 0.9497 - val_loss: 0.6713 - val_accuracy: 0.8542\n",
    "Epoch 316/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 0.2738 - accuracy: 0.9512 - val_loss: 0.6667 - val_accuracy: 0.8529\n",
    "Epoch 317/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.2760 - accuracy: 0.9498 - val_loss: 0.7754 - val_accuracy: 0.8369\n",
    "Epoch 318/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 0.2765 - accuracy: 0.9477 - val_loss: 0.6874 - val_accuracy: 0.8531\n",
    "Epoch 319/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.2715 - accuracy: 0.9517 - val_loss: 0.6533 - val_accuracy: 0.8537\n",
    "Epoch 320/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.2762 - accuracy: 0.9483 - val_loss: 0.7438 - val_accuracy: 0.8434\n",
    "Epoch 321/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 0.2733 - accuracy: 0.9509 - val_loss: 0.7636 - val_accuracy: 0.8368\n",
    "Epoch 322/500\n",
    "390/390 [==============================] - 110s 282ms/step - loss: 0.2731 - accuracy: 0.9500 - val_loss: 0.7383 - val_accuracy: 0.8384\n",
    "Epoch 323/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 0.2705 - accuracy: 0.9519 - val_loss: 0.6764 - val_accuracy: 0.8581\n",
    "Epoch 324/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.2768 - accuracy: 0.9494 - val_loss: 0.6772 - val_accuracy: 0.8575\n",
    "Epoch 325/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 0.2719 - accuracy: 0.9510 - val_loss: 0.6400 - val_accuracy: 0.8595\n",
    "Epoch 326/500\n",
    "390/390 [==============================] - 114s 293ms/step - loss: 0.2663 - accuracy: 0.9526 - val_loss: 0.6620 - val_accuracy: 0.8509\n",
    "Epoch 327/500\n",
    "390/390 [==============================] - 112s 286ms/step - loss: 0.2744 - accuracy: 0.9492 - val_loss: 0.6701 - val_accuracy: 0.8544\n",
    "Epoch 328/500\n",
    "390/390 [==============================] - 114s 291ms/step - loss: 0.2695 - accuracy: 0.9514 - val_loss: 0.6916 - val_accuracy: 0.8550\n",
    "Epoch 329/500\n",
    "390/390 [==============================] - 115s 294ms/step - loss: 0.2722 - accuracy: 0.9512 - val_loss: 0.7454 - val_accuracy: 0.8447\n",
    "Epoch 330/500\n",
    "390/390 [==============================] - 116s 297ms/step - loss: 0.2795 - accuracy: 0.9474 - val_loss: 0.7416 - val_accuracy: 0.8388\n",
    "Epoch 331/500\n",
    "390/390 [==============================] - 112s 287ms/step - loss: 0.2745 - accuracy: 0.9499 - val_loss: 0.7185 - val_accuracy: 0.8433\n",
    "Epoch 332/500\n",
    "390/390 [==============================] - 113s 291ms/step - loss: 0.2728 - accuracy: 0.9506 - val_loss: 0.6861 - val_accuracy: 0.8568\n",
    "Epoch 333/500\n",
    "390/390 [==============================] - 114s 292ms/step - loss: 0.2720 - accuracy: 0.9499 - val_loss: 0.7373 - val_accuracy: 0.8420\n",
    "Epoch 334/500\n",
    "390/390 [==============================] - 113s 291ms/step - loss: 0.2694 - accuracy: 0.9522 - val_loss: 0.6462 - val_accuracy: 0.8587\n",
    "Epoch 335/500\n",
    "390/390 [==============================] - 113s 289ms/step - loss: 0.2732 - accuracy: 0.9501 - val_loss: 0.7015 - val_accuracy: 0.8469\n",
    "Epoch 336/500\n",
    "390/390 [==============================] - 111s 286ms/step - loss: 0.2731 - accuracy: 0.9498 - val_loss: 0.6470 - val_accuracy: 0.8630\n",
    "Epoch 337/500\n",
    "390/390 [==============================] - 111s 285ms/step - loss: 0.2729 - accuracy: 0.9503 - val_loss: 0.8527 - val_accuracy: 0.8240\n",
    "Epoch 338/500\n",
    "390/390 [==============================] - 111s 285ms/step - loss: 0.2708 - accuracy: 0.9513 - val_loss: 0.6755 - val_accuracy: 0.8525\n",
    "Epoch 339/500\n",
    "390/390 [==============================] - 112s 286ms/step - loss: 0.2735 - accuracy: 0.9506 - val_loss: 0.7327 - val_accuracy: 0.8424\n",
    "Epoch 340/500\n",
    "390/390 [==============================] - 111s 285ms/step - loss: 0.2710 - accuracy: 0.9513 - val_loss: 0.6720 - val_accuracy: 0.8564\n",
    "Epoch 341/500\n",
    "390/390 [==============================] - 111s 286ms/step - loss: 0.2726 - accuracy: 0.9515 - val_loss: 0.6834 - val_accuracy: 0.8543\n",
    "Epoch 342/500\n",
    "390/390 [==============================] - 111s 285ms/step - loss: 0.2674 - accuracy: 0.9522 - val_loss: 0.6595 - val_accuracy: 0.8561\n",
    "Epoch 343/500\n",
    "390/390 [==============================] - 115s 294ms/step - loss: 0.2674 - accuracy: 0.9519 - val_loss: 0.6965 - val_accuracy: 0.8480\n",
    "Epoch 344/500\n",
    "390/390 [==============================] - 128s 327ms/step - loss: 0.2742 - accuracy: 0.9498 - val_loss: 0.8320 - val_accuracy: 0.8341\n",
    "Epoch 345/500\n",
    "390/390 [==============================] - 127s 327ms/step - loss: 0.2688 - accuracy: 0.9515 - val_loss: 0.7245 - val_accuracy: 0.8485\n",
    "Epoch 346/500\n",
    "390/390 [==============================] - 122s 313ms/step - loss: 0.2741 - accuracy: 0.9487 - val_loss: 0.8742 - val_accuracy: 0.8256\n",
    "Epoch 347/500\n",
    "390/390 [==============================] - 111s 284ms/step - loss: 0.2724 - accuracy: 0.9503 - val_loss: 0.7522 - val_accuracy: 0.8332\n",
    "Epoch 348/500\n",
    "390/390 [==============================] - 111s 285ms/step - loss: 0.2677 - accuracy: 0.9521 - val_loss: 0.6746 - val_accuracy: 0.8563\n",
    "Epoch 349/500\n",
    "390/390 [==============================] - 111s 285ms/step - loss: 0.2681 - accuracy: 0.9515 - val_loss: 0.7856 - val_accuracy: 0.8296\n",
    "Epoch 350/500\n",
    "390/390 [==============================] - 111s 285ms/step - loss: 0.2669 - accuracy: 0.9532 - val_loss: 0.6581 - val_accuracy: 0.8571\n",
    "Epoch 351/500\n",
    "390/390 [==============================] - 111s 285ms/step - loss: 0.2676 - accuracy: 0.9518 - val_loss: 0.6211 - val_accuracy: 0.8610\n",
    "Epoch 352/500\n",
    "390/390 [==============================] - 111s 286ms/step - loss: 0.2686 - accuracy: 0.9524 - val_loss: 0.6593 - val_accuracy: 0.8573\n",
    "Epoch 353/500\n",
    "390/390 [==============================] - 111s 285ms/step - loss: 0.2682 - accuracy: 0.9525 - val_loss: 0.7021 - val_accuracy: 0.8523\n",
    "Epoch 354/500\n",
    "390/390 [==============================] - 124s 317ms/step - loss: 0.2672 - accuracy: 0.9532 - val_loss: 0.6965 - val_accuracy: 0.8492\n",
    "Epoch 355/500\n",
    "390/390 [==============================] - 116s 297ms/step - loss: 0.2666 - accuracy: 0.9525 - val_loss: 0.7969 - val_accuracy: 0.8292\n",
    "Epoch 356/500\n",
    "390/390 [==============================] - 110s 282ms/step - loss: 0.2659 - accuracy: 0.9533 - val_loss: 0.7062 - val_accuracy: 0.8461\n",
    "Epoch 357/500\n",
    "390/390 [==============================] - 111s 286ms/step - loss: 0.2701 - accuracy: 0.9506 - val_loss: 0.7249 - val_accuracy: 0.8499\n",
    "Epoch 358/500\n",
    "390/390 [==============================] - 110s 282ms/step - loss: 0.2630 - accuracy: 0.9538 - val_loss: 0.7024 - val_accuracy: 0.8479\n",
    "Epoch 359/500\n",
    "390/390 [==============================] - 110s 282ms/step - loss: 0.2685 - accuracy: 0.9502 - val_loss: 0.6537 - val_accuracy: 0.8627\n",
    "Epoch 360/500\n",
    "390/390 [==============================] - 110s 282ms/step - loss: 0.2691 - accuracy: 0.9515 - val_loss: 0.6930 - val_accuracy: 0.8517\n",
    "Epoch 361/500\n",
    "390/390 [==============================] - 110s 282ms/step - loss: 0.2640 - accuracy: 0.9536 - val_loss: 0.6640 - val_accuracy: 0.8533\n",
    "Epoch 362/500\n",
    "390/390 [==============================] - 110s 282ms/step - loss: 0.2663 - accuracy: 0.9527 - val_loss: 0.6400 - val_accuracy: 0.8611\n",
    "Epoch 363/500\n",
    "390/390 [==============================] - 120s 309ms/step - loss: 0.2690 - accuracy: 0.9512 - val_loss: 0.7377 - val_accuracy: 0.8530\n",
    "Epoch 364/500\n",
    "390/390 [==============================] - 127s 325ms/step - loss: 0.2642 - accuracy: 0.9536 - val_loss: 0.6716 - val_accuracy: 0.8618\n",
    "Epoch 365/500\n",
    "390/390 [==============================] - 128s 327ms/step - loss: 0.2653 - accuracy: 0.9526 - val_loss: 0.7125 - val_accuracy: 0.8529\n",
    "Epoch 366/500\n",
    "390/390 [==============================] - 128s 328ms/step - loss: 0.2677 - accuracy: 0.9509 - val_loss: 0.6676 - val_accuracy: 0.8515\n",
    "Epoch 367/500\n",
    "390/390 [==============================] - 127s 325ms/step - loss: 0.2668 - accuracy: 0.9531 - val_loss: 0.7023 - val_accuracy: 0.8529\n",
    "Epoch 368/500\n",
    "390/390 [==============================] - 111s 285ms/step - loss: 0.2694 - accuracy: 0.9504 - val_loss: 0.7458 - val_accuracy: 0.8407\n",
    "Epoch 369/500\n",
    "390/390 [==============================] - 110s 282ms/step - loss: 0.2675 - accuracy: 0.9522 - val_loss: 0.6850 - val_accuracy: 0.8518\n",
    "Epoch 370/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.2644 - accuracy: 0.9527 - val_loss: 0.7056 - val_accuracy: 0.8494\n",
    "Epoch 371/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.2637 - accuracy: 0.9522 - val_loss: 0.6489 - val_accuracy: 0.8566\n",
    "Epoch 372/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.2659 - accuracy: 0.9526 - val_loss: 0.6922 - val_accuracy: 0.8555\n",
    "Epoch 373/500\n",
    "390/390 [==============================] - 110s 282ms/step - loss: 0.2608 - accuracy: 0.9551 - val_loss: 0.6417 - val_accuracy: 0.8606\n",
    "Epoch 374/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.2644 - accuracy: 0.9535 - val_loss: 0.6931 - val_accuracy: 0.8561\n",
    "Epoch 375/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 0.2617 - accuracy: 0.9531 - val_loss: 0.7804 - val_accuracy: 0.8321\n",
    "Epoch 376/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.2647 - accuracy: 0.9525 - val_loss: 0.7794 - val_accuracy: 0.8333\n",
    "Epoch 377/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 0.2641 - accuracy: 0.9532 - val_loss: 0.7805 - val_accuracy: 0.8368\n",
    "Epoch 378/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.2666 - accuracy: 0.9517 - val_loss: 0.6105 - val_accuracy: 0.8671\n",
    "Epoch 379/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.2642 - accuracy: 0.9526 - val_loss: 0.6633 - val_accuracy: 0.8573\n",
    "Epoch 380/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.2619 - accuracy: 0.9539 - val_loss: 0.6349 - val_accuracy: 0.8556\n",
    "Epoch 381/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 0.2654 - accuracy: 0.9533 - val_loss: 0.6601 - val_accuracy: 0.8625\n",
    "Epoch 382/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.2633 - accuracy: 0.9530 - val_loss: 0.6633 - val_accuracy: 0.8596\n",
    "Epoch 383/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.2595 - accuracy: 0.9548 - val_loss: 0.7185 - val_accuracy: 0.8444\n",
    "Epoch 384/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 0.2650 - accuracy: 0.9528 - val_loss: 0.6608 - val_accuracy: 0.8551\n",
    "Epoch 385/500\n",
    "390/390 [==============================] - 110s 282ms/step - loss: 0.2602 - accuracy: 0.9544 - val_loss: 0.6564 - val_accuracy: 0.8623\n",
    "Epoch 386/500\n",
    "390/390 [==============================] - 111s 285ms/step - loss: 0.2605 - accuracy: 0.9536 - val_loss: 0.7244 - val_accuracy: 0.8448\n",
    "Epoch 387/500\n",
    "390/390 [==============================] - 113s 289ms/step - loss: 0.2627 - accuracy: 0.9525 - val_loss: 0.7320 - val_accuracy: 0.8400\n",
    "Epoch 388/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 0.2590 - accuracy: 0.9551 - val_loss: 0.7197 - val_accuracy: 0.8470\n",
    "Epoch 389/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.2637 - accuracy: 0.9530 - val_loss: 0.6643 - val_accuracy: 0.8647\n",
    "Epoch 390/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.2636 - accuracy: 0.9516 - val_loss: 0.7211 - val_accuracy: 0.8525\n",
    "Epoch 391/500\n",
    "390/390 [==============================] - 109s 281ms/step - loss: 0.2630 - accuracy: 0.9542 - val_loss: 0.7936 - val_accuracy: 0.8417\n",
    "Epoch 392/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.2643 - accuracy: 0.9529 - val_loss: 0.6415 - val_accuracy: 0.8582\n",
    "Epoch 393/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.2624 - accuracy: 0.9523 - val_loss: 0.6906 - val_accuracy: 0.8505\n",
    "Epoch 394/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.2641 - accuracy: 0.9533 - val_loss: 0.7900 - val_accuracy: 0.8337\n",
    "Epoch 395/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.2596 - accuracy: 0.9550 - val_loss: 0.7332 - val_accuracy: 0.8525\n",
    "Epoch 396/500\n",
    "390/390 [==============================] - 110s 281ms/step - loss: 0.2592 - accuracy: 0.9551 - val_loss: 0.7620 - val_accuracy: 0.8421\n",
    "Epoch 397/500\n",
    "390/390 [==============================] - 109s 280ms/step - loss: 0.2639 - accuracy: 0.9529 - val_loss: 0.7878 - val_accuracy: 0.8388\n",
    "Epoch 398/500\n",
    "390/390 [==============================] - 110s 282ms/step - loss: 0.2582 - accuracy: 0.9538 - val_loss: 0.7343 - val_accuracy: 0.8463\n",
    "Epoch 399/500\n",
    "390/390 [==============================] - 112s 288ms/step - loss: 0.2623 - accuracy: 0.9541 - val_loss: 0.6424 - val_accuracy: 0.8570\n",
    "Epoch 400/500\n",
    "390/390 [==============================] - 111s 285ms/step - loss: 0.2579 - accuracy: 0.9536 - val_loss: 0.7216 - val_accuracy: 0.8420\n",
    "Epoch 401/500\n",
    "390/390 [==============================] - 111s 285ms/step - loss: 0.2621 - accuracy: 0.9533 - val_loss: 0.6775 - val_accuracy: 0.8556\n",
    "Epoch 402/500\n",
    "390/390 [==============================] - 111s 285ms/step - loss: 0.2603 - accuracy: 0.9547 - val_loss: 0.7284 - val_accuracy: 0.8466\n",
    "Epoch 403/500\n",
    "390/390 [==============================] - 114s 293ms/step - loss: 0.2548 - accuracy: 0.9544 - val_loss: 0.7301 - val_accuracy: 0.8443\n",
    "Epoch 404/500\n",
    "390/390 [==============================] - 116s 297ms/step - loss: 0.2612 - accuracy: 0.9543 - val_loss: 0.7883 - val_accuracy: 0.8323\n",
    "Epoch 405/500\n",
    "390/390 [==============================] - 132s 339ms/step - loss: 0.2622 - accuracy: 0.9542 - val_loss: 0.7217 - val_accuracy: 0.8503\n",
    "Epoch 406/500\n",
    "390/390 [==============================] - 139s 357ms/step - loss: 0.2604 - accuracy: 0.9539 - val_loss: 0.6567 - val_accuracy: 0.8566\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitted = data.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'Epoch 1/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 2.0599 - accuracy: 0.4107 - val_loss: 1.8859 - val_accuracy: 0.4693',\n",
       " 'Epoch 2/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 1.7205 - accuracy: 0.5219 - val_loss: 1.9937 - val_accuracy: 0.4844',\n",
       " 'Epoch 3/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 1.5905 - accuracy: 0.5688 - val_loss: 1.6765 - val_accuracy: 0.5591',\n",
       " 'Epoch 4/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 1.4974 - accuracy: 0.6016 - val_loss: 1.4793 - val_accuracy: 0.6142',\n",
       " 'Epoch 5/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 1.4271 - accuracy: 0.6250 - val_loss: 1.5261 - val_accuracy: 0.5974',\n",
       " 'Epoch 6/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 1.3700 - accuracy: 0.6446 - val_loss: 1.4851 - val_accuracy: 0.6282',\n",
       " 'Epoch 7/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 1.3220 - accuracy: 0.6601 - val_loss: 1.2994 - val_accuracy: 0.6803',\n",
       " 'Epoch 8/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 1.2739 - accuracy: 0.6759 - val_loss: 1.2912 - val_accuracy: 0.6783',\n",
       " 'Epoch 9/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 1.2277 - accuracy: 0.6915 - val_loss: 1.2616 - val_accuracy: 0.6900',\n",
       " 'Epoch 10/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 1.1872 - accuracy: 0.7038 - val_loss: 1.3190 - val_accuracy: 0.6726',\n",
       " 'Epoch 11/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 1.1571 - accuracy: 0.7128 - val_loss: 1.2867 - val_accuracy: 0.6792',\n",
       " 'Epoch 12/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 1.1277 - accuracy: 0.7219 - val_loss: 1.4620 - val_accuracy: 0.6396',\n",
       " 'Epoch 13/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 1.1028 - accuracy: 0.7280 - val_loss: 1.1590 - val_accuracy: 0.7258',\n",
       " 'Epoch 14/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 1.0755 - accuracy: 0.7381 - val_loss: 1.0992 - val_accuracy: 0.7424',\n",
       " 'Epoch 15/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 1.0511 - accuracy: 0.7459 - val_loss: 1.2855 - val_accuracy: 0.6940',\n",
       " 'Epoch 16/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 1.0278 - accuracy: 0.7506 - val_loss: 1.1468 - val_accuracy: 0.7265',\n",
       " 'Epoch 17/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 1.0140 - accuracy: 0.7562 - val_loss: 1.1902 - val_accuracy: 0.7183',\n",
       " 'Epoch 18/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 0.9820 - accuracy: 0.7662 - val_loss: 1.0532 - val_accuracy: 0.7541',\n",
       " 'Epoch 19/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.9678 - accuracy: 0.7707 - val_loss: 1.0227 - val_accuracy: 0.7582',\n",
       " 'Epoch 20/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 0.9565 - accuracy: 0.7727 - val_loss: 1.0175 - val_accuracy: 0.7660',\n",
       " 'Epoch 21/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 0.9401 - accuracy: 0.7755 - val_loss: 1.0776 - val_accuracy: 0.7495',\n",
       " 'Epoch 22/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.9174 - accuracy: 0.7846 - val_loss: 1.1113 - val_accuracy: 0.7345',\n",
       " 'Epoch 23/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 0.9102 - accuracy: 0.7841 - val_loss: 1.0366 - val_accuracy: 0.7573',\n",
       " 'Epoch 24/500',\n",
       " '390/390 [==============================] - 110s 282ms/step - loss: 0.8935 - accuracy: 0.7870 - val_loss: 1.1080 - val_accuracy: 0.7364',\n",
       " 'Epoch 25/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 0.8751 - accuracy: 0.7944 - val_loss: 0.9486 - val_accuracy: 0.7782',\n",
       " 'Epoch 26/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 0.8635 - accuracy: 0.7977 - val_loss: 0.9943 - val_accuracy: 0.7717',\n",
       " 'Epoch 27/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 0.8496 - accuracy: 0.8022 - val_loss: 0.9457 - val_accuracy: 0.7786',\n",
       " 'Epoch 28/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.8395 - accuracy: 0.8027 - val_loss: 0.9368 - val_accuracy: 0.7791',\n",
       " 'Epoch 29/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.8291 - accuracy: 0.8066 - val_loss: 0.9918 - val_accuracy: 0.7723',\n",
       " 'Epoch 30/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.8171 - accuracy: 0.8100 - val_loss: 1.0488 - val_accuracy: 0.7564',\n",
       " 'Epoch 31/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.8074 - accuracy: 0.8119 - val_loss: 0.8897 - val_accuracy: 0.7932',\n",
       " 'Epoch 32/500',\n",
       " '390/390 [==============================] - 110s 282ms/step - loss: 0.7953 - accuracy: 0.8157 - val_loss: 0.8769 - val_accuracy: 0.8045',\n",
       " 'Epoch 33/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.7836 - accuracy: 0.8187 - val_loss: 0.8802 - val_accuracy: 0.8007',\n",
       " 'Epoch 34/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 0.7703 - accuracy: 0.8216 - val_loss: 0.8704 - val_accuracy: 0.8038',\n",
       " 'Epoch 35/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 0.7665 - accuracy: 0.8241 - val_loss: 0.8473 - val_accuracy: 0.8063',\n",
       " 'Epoch 36/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.7571 - accuracy: 0.8253 - val_loss: 0.9571 - val_accuracy: 0.7805',\n",
       " 'Epoch 37/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.7461 - accuracy: 0.8266 - val_loss: 0.8691 - val_accuracy: 0.7997',\n",
       " 'Epoch 38/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 0.7360 - accuracy: 0.8314 - val_loss: 0.9446 - val_accuracy: 0.7772',\n",
       " 'Epoch 39/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 0.7283 - accuracy: 0.8309 - val_loss: 0.8442 - val_accuracy: 0.8037',\n",
       " 'Epoch 40/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 0.7202 - accuracy: 0.8347 - val_loss: 0.8885 - val_accuracy: 0.7935',\n",
       " 'Epoch 41/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.7188 - accuracy: 0.8330 - val_loss: 0.8955 - val_accuracy: 0.7898',\n",
       " 'Epoch 42/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.7046 - accuracy: 0.8397 - val_loss: 0.8608 - val_accuracy: 0.8028',\n",
       " 'Epoch 43/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 0.6946 - accuracy: 0.8395 - val_loss: 0.8278 - val_accuracy: 0.8117',\n",
       " 'Epoch 44/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.6887 - accuracy: 0.8418 - val_loss: 0.8742 - val_accuracy: 0.7925',\n",
       " 'Epoch 45/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.6783 - accuracy: 0.8446 - val_loss: 0.8551 - val_accuracy: 0.8005',\n",
       " 'Epoch 46/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.6786 - accuracy: 0.8439 - val_loss: 0.8351 - val_accuracy: 0.8032',\n",
       " 'Epoch 47/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.6651 - accuracy: 0.8478 - val_loss: 0.8334 - val_accuracy: 0.8021',\n",
       " 'Epoch 48/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 0.6626 - accuracy: 0.8482 - val_loss: 0.8033 - val_accuracy: 0.8168',\n",
       " 'Epoch 49/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 0.6481 - accuracy: 0.8510 - val_loss: 0.8713 - val_accuracy: 0.8006',\n",
       " 'Epoch 50/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.6409 - accuracy: 0.8544 - val_loss: 0.8011 - val_accuracy: 0.8171',\n",
       " 'Epoch 51/500',\n",
       " '390/390 [==============================] - 110s 283ms/step - loss: 0.6448 - accuracy: 0.8517 - val_loss: 0.8453 - val_accuracy: 0.8102',\n",
       " 'Epoch 52/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.6380 - accuracy: 0.8545 - val_loss: 0.7950 - val_accuracy: 0.8185',\n",
       " 'Epoch 53/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 0.6299 - accuracy: 0.8556 - val_loss: 0.7773 - val_accuracy: 0.8177',\n",
       " 'Epoch 54/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.6212 - accuracy: 0.8579 - val_loss: 0.7947 - val_accuracy: 0.8141',\n",
       " 'Epoch 55/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 0.6146 - accuracy: 0.8589 - val_loss: 0.9437 - val_accuracy: 0.7802',\n",
       " 'Epoch 56/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 0.6104 - accuracy: 0.8621 - val_loss: 0.8790 - val_accuracy: 0.7928',\n",
       " 'Epoch 57/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.6028 - accuracy: 0.8638 - val_loss: 0.8848 - val_accuracy: 0.7962',\n",
       " 'Epoch 58/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.6024 - accuracy: 0.8619 - val_loss: 0.7880 - val_accuracy: 0.8196',\n",
       " 'Epoch 59/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 0.5957 - accuracy: 0.8625 - val_loss: 0.8284 - val_accuracy: 0.8092',\n",
       " 'Epoch 60/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 0.5872 - accuracy: 0.8674 - val_loss: 0.7586 - val_accuracy: 0.8216',\n",
       " 'Epoch 61/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.5825 - accuracy: 0.8671 - val_loss: 0.7995 - val_accuracy: 0.8161',\n",
       " 'Epoch 62/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.5796 - accuracy: 0.8667 - val_loss: 0.8975 - val_accuracy: 0.7895',\n",
       " 'Epoch 63/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.5733 - accuracy: 0.8684 - val_loss: 0.8706 - val_accuracy: 0.7936',\n",
       " 'Epoch 64/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.5711 - accuracy: 0.8687 - val_loss: 0.8334 - val_accuracy: 0.8098',\n",
       " 'Epoch 65/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.5611 - accuracy: 0.8732 - val_loss: 0.7812 - val_accuracy: 0.8222',\n",
       " 'Epoch 66/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.5616 - accuracy: 0.8715 - val_loss: 0.7427 - val_accuracy: 0.8254',\n",
       " 'Epoch 67/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.5570 - accuracy: 0.8726 - val_loss: 0.7551 - val_accuracy: 0.8251',\n",
       " 'Epoch 68/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.5540 - accuracy: 0.8728 - val_loss: 0.7871 - val_accuracy: 0.8099',\n",
       " 'Epoch 69/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.5490 - accuracy: 0.8751 - val_loss: 0.7427 - val_accuracy: 0.8269',\n",
       " 'Epoch 70/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.5395 - accuracy: 0.8779 - val_loss: 0.8832 - val_accuracy: 0.7881',\n",
       " 'Epoch 71/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.5393 - accuracy: 0.8781 - val_loss: 0.7371 - val_accuracy: 0.8270',\n",
       " 'Epoch 72/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 0.5325 - accuracy: 0.8798 - val_loss: 0.7335 - val_accuracy: 0.8280',\n",
       " 'Epoch 73/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 0.5226 - accuracy: 0.8812 - val_loss: 0.7645 - val_accuracy: 0.8163',\n",
       " 'Epoch 74/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.5194 - accuracy: 0.8835 - val_loss: 0.7325 - val_accuracy: 0.8299',\n",
       " 'Epoch 75/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.5207 - accuracy: 0.8827 - val_loss: 0.8524 - val_accuracy: 0.8052',\n",
       " 'Epoch 76/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 0.5116 - accuracy: 0.8845 - val_loss: 0.7493 - val_accuracy: 0.8271',\n",
       " 'Epoch 77/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.5109 - accuracy: 0.8835 - val_loss: 0.7522 - val_accuracy: 0.8217',\n",
       " 'Epoch 78/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.5116 - accuracy: 0.8841 - val_loss: 0.8058 - val_accuracy: 0.8078',\n",
       " 'Epoch 79/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 0.5080 - accuracy: 0.8839 - val_loss: 0.7211 - val_accuracy: 0.8263',\n",
       " 'Epoch 80/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 0.5034 - accuracy: 0.8851 - val_loss: 0.7202 - val_accuracy: 0.8322',\n",
       " 'Epoch 81/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 0.5016 - accuracy: 0.8879 - val_loss: 0.7210 - val_accuracy: 0.8264',\n",
       " 'Epoch 82/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.4918 - accuracy: 0.8876 - val_loss: 0.7478 - val_accuracy: 0.8233',\n",
       " 'Epoch 83/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.4968 - accuracy: 0.8874 - val_loss: 0.7869 - val_accuracy: 0.8167',\n",
       " 'Epoch 84/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 0.4822 - accuracy: 0.8937 - val_loss: 0.7451 - val_accuracy: 0.8288',\n",
       " 'Epoch 85/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.4860 - accuracy: 0.8910 - val_loss: 0.7508 - val_accuracy: 0.8233',\n",
       " 'Epoch 86/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.4840 - accuracy: 0.8903 - val_loss: 0.7341 - val_accuracy: 0.8239',\n",
       " 'Epoch 87/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 0.4801 - accuracy: 0.8912 - val_loss: 0.6927 - val_accuracy: 0.8367',\n",
       " 'Epoch 88/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 0.4740 - accuracy: 0.8934 - val_loss: 0.8767 - val_accuracy: 0.7975',\n",
       " 'Epoch 89/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 0.4719 - accuracy: 0.8948 - val_loss: 0.7124 - val_accuracy: 0.8346',\n",
       " 'Epoch 90/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.4704 - accuracy: 0.8945 - val_loss: 0.7406 - val_accuracy: 0.8249',\n",
       " 'Epoch 91/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.4657 - accuracy: 0.8954 - val_loss: 0.7814 - val_accuracy: 0.8118',\n",
       " 'Epoch 92/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.4678 - accuracy: 0.8940 - val_loss: 0.6929 - val_accuracy: 0.8324',\n",
       " 'Epoch 93/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 0.4588 - accuracy: 0.8968 - val_loss: 0.7917 - val_accuracy: 0.8235',\n",
       " 'Epoch 94/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.4602 - accuracy: 0.8974 - val_loss: 0.8237 - val_accuracy: 0.8075',\n",
       " 'Epoch 95/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 0.4539 - accuracy: 0.8973 - val_loss: 0.8110 - val_accuracy: 0.8133',\n",
       " 'Epoch 96/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 0.4526 - accuracy: 0.8981 - val_loss: 0.7317 - val_accuracy: 0.8185',\n",
       " 'Epoch 97/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.4570 - accuracy: 0.8967 - val_loss: 0.6710 - val_accuracy: 0.8415',\n",
       " 'Epoch 98/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.4524 - accuracy: 0.8983 - val_loss: 0.6893 - val_accuracy: 0.8344',\n",
       " 'Epoch 99/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.4493 - accuracy: 0.8990 - val_loss: 0.6305 - val_accuracy: 0.8499',\n",
       " 'Epoch 100/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.4414 - accuracy: 0.9012 - val_loss: 0.7630 - val_accuracy: 0.8216',\n",
       " 'Epoch 101/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 0.4423 - accuracy: 0.9009 - val_loss: 0.7386 - val_accuracy: 0.8312',\n",
       " 'Epoch 102/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.4368 - accuracy: 0.9036 - val_loss: 0.7295 - val_accuracy: 0.8280',\n",
       " 'Epoch 103/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.4348 - accuracy: 0.9043 - val_loss: 0.6502 - val_accuracy: 0.8453',\n",
       " 'Epoch 104/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 0.4333 - accuracy: 0.9055 - val_loss: 0.6806 - val_accuracy: 0.8392',\n",
       " 'Epoch 105/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.4319 - accuracy: 0.9046 - val_loss: 0.7490 - val_accuracy: 0.8239',\n",
       " 'Epoch 106/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 0.4257 - accuracy: 0.9059 - val_loss: 0.9395 - val_accuracy: 0.7869',\n",
       " 'Epoch 107/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.4251 - accuracy: 0.9052 - val_loss: 0.7368 - val_accuracy: 0.8312',\n",
       " 'Epoch 108/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.4276 - accuracy: 0.9051 - val_loss: 0.6543 - val_accuracy: 0.8467',\n",
       " 'Epoch 109/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 0.4259 - accuracy: 0.9058 - val_loss: 0.7818 - val_accuracy: 0.8148',\n",
       " 'Epoch 110/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.4130 - accuracy: 0.9092 - val_loss: 0.7225 - val_accuracy: 0.8326',\n",
       " 'Epoch 111/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.4205 - accuracy: 0.9060 - val_loss: 0.7117 - val_accuracy: 0.8322',\n",
       " 'Epoch 112/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 0.4246 - accuracy: 0.9067 - val_loss: 0.6748 - val_accuracy: 0.8395',\n",
       " 'Epoch 113/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.4124 - accuracy: 0.9097 - val_loss: 0.6957 - val_accuracy: 0.8390',\n",
       " 'Epoch 114/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.4117 - accuracy: 0.9093 - val_loss: 0.7909 - val_accuracy: 0.8077',\n",
       " 'Epoch 115/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 0.4105 - accuracy: 0.9108 - val_loss: 0.6461 - val_accuracy: 0.8505',\n",
       " 'Epoch 116/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 0.4098 - accuracy: 0.9098 - val_loss: 0.6621 - val_accuracy: 0.8461',\n",
       " 'Epoch 117/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.4041 - accuracy: 0.9119 - val_loss: 0.6754 - val_accuracy: 0.8404',\n",
       " 'Epoch 118/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.4013 - accuracy: 0.9117 - val_loss: 0.6281 - val_accuracy: 0.8512',\n",
       " 'Epoch 119/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.4081 - accuracy: 0.9091 - val_loss: 0.7457 - val_accuracy: 0.8332',\n",
       " 'Epoch 120/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.4034 - accuracy: 0.9101 - val_loss: 0.6785 - val_accuracy: 0.8379',\n",
       " 'Epoch 121/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.4027 - accuracy: 0.9112 - val_loss: 0.6523 - val_accuracy: 0.8470',\n",
       " 'Epoch 122/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.3946 - accuracy: 0.9141 - val_loss: 0.7062 - val_accuracy: 0.8365',\n",
       " 'Epoch 123/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.3935 - accuracy: 0.9137 - val_loss: 0.6977 - val_accuracy: 0.8402',\n",
       " 'Epoch 124/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.3941 - accuracy: 0.9137 - val_loss: 0.7185 - val_accuracy: 0.8353',\n",
       " 'Epoch 125/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.3899 - accuracy: 0.9143 - val_loss: 0.6906 - val_accuracy: 0.8425',\n",
       " 'Epoch 126/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 0.3896 - accuracy: 0.9152 - val_loss: 0.6042 - val_accuracy: 0.8622',\n",
       " 'Epoch 127/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.3888 - accuracy: 0.9163 - val_loss: 0.7511 - val_accuracy: 0.8306',\n",
       " 'Epoch 128/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 0.3904 - accuracy: 0.9142 - val_loss: 0.7261 - val_accuracy: 0.8339',\n",
       " 'Epoch 129/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 0.3933 - accuracy: 0.9150 - val_loss: 0.6887 - val_accuracy: 0.8487',\n",
       " 'Epoch 130/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.3860 - accuracy: 0.9166 - val_loss: 0.7198 - val_accuracy: 0.8274',\n",
       " 'Epoch 131/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.3850 - accuracy: 0.9156 - val_loss: 0.7012 - val_accuracy: 0.8405',\n",
       " 'Epoch 132/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.3825 - accuracy: 0.9178 - val_loss: 0.7076 - val_accuracy: 0.8367',\n",
       " 'Epoch 133/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.3788 - accuracy: 0.9196 - val_loss: 0.7418 - val_accuracy: 0.8290',\n",
       " 'Epoch 134/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.3798 - accuracy: 0.9185 - val_loss: 0.7080 - val_accuracy: 0.8364',\n",
       " 'Epoch 135/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.3791 - accuracy: 0.9178 - val_loss: 0.7835 - val_accuracy: 0.8224',\n",
       " 'Epoch 136/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.3745 - accuracy: 0.9192 - val_loss: 0.7252 - val_accuracy: 0.8296',\n",
       " 'Epoch 137/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 0.3781 - accuracy: 0.9176 - val_loss: 0.6736 - val_accuracy: 0.8435',\n",
       " 'Epoch 138/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.3738 - accuracy: 0.9198 - val_loss: 0.6460 - val_accuracy: 0.8524',\n",
       " 'Epoch 139/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.3719 - accuracy: 0.9196 - val_loss: 0.6453 - val_accuracy: 0.8457',\n",
       " 'Epoch 140/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.3690 - accuracy: 0.9213 - val_loss: 0.7210 - val_accuracy: 0.8305',\n",
       " 'Epoch 141/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.3767 - accuracy: 0.9187 - val_loss: 0.7102 - val_accuracy: 0.8349',\n",
       " 'Epoch 142/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.3657 - accuracy: 0.9209 - val_loss: 0.7309 - val_accuracy: 0.8375',\n",
       " 'Epoch 143/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.3657 - accuracy: 0.9228 - val_loss: 0.6755 - val_accuracy: 0.8485',\n",
       " 'Epoch 144/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 0.3686 - accuracy: 0.9208 - val_loss: 0.7396 - val_accuracy: 0.8297',\n",
       " 'Epoch 145/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.3676 - accuracy: 0.9205 - val_loss: 0.6342 - val_accuracy: 0.8523',\n",
       " 'Epoch 146/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.3641 - accuracy: 0.9215 - val_loss: 0.6575 - val_accuracy: 0.8448',\n",
       " 'Epoch 147/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.3655 - accuracy: 0.9216 - val_loss: 0.7022 - val_accuracy: 0.8398',\n",
       " 'Epoch 148/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.3623 - accuracy: 0.9226 - val_loss: 0.6499 - val_accuracy: 0.8494',\n",
       " 'Epoch 149/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.3616 - accuracy: 0.9224 - val_loss: 0.6991 - val_accuracy: 0.8424',\n",
       " 'Epoch 150/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.3611 - accuracy: 0.9227 - val_loss: 0.6561 - val_accuracy: 0.8502',\n",
       " 'Epoch 151/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.3562 - accuracy: 0.9257 - val_loss: 0.6600 - val_accuracy: 0.8482',\n",
       " 'Epoch 152/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.3582 - accuracy: 0.9235 - val_loss: 0.7339 - val_accuracy: 0.8293',\n",
       " 'Epoch 153/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.3555 - accuracy: 0.9254 - val_loss: 0.7092 - val_accuracy: 0.8417',\n",
       " 'Epoch 154/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.3557 - accuracy: 0.9238 - val_loss: 0.6888 - val_accuracy: 0.8460',\n",
       " 'Epoch 155/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.3568 - accuracy: 0.9242 - val_loss: 0.6725 - val_accuracy: 0.8451',\n",
       " 'Epoch 156/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.3535 - accuracy: 0.9251 - val_loss: 0.7240 - val_accuracy: 0.8294',\n",
       " 'Epoch 157/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.3492 - accuracy: 0.9276 - val_loss: 0.6655 - val_accuracy: 0.8537',\n",
       " 'Epoch 158/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.3497 - accuracy: 0.9259 - val_loss: 0.6961 - val_accuracy: 0.8421',\n",
       " 'Epoch 159/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.3507 - accuracy: 0.9258 - val_loss: 0.7412 - val_accuracy: 0.8317',\n",
       " 'Epoch 160/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 0.3456 - accuracy: 0.9278 - val_loss: 0.7584 - val_accuracy: 0.8320',\n",
       " 'Epoch 161/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.3515 - accuracy: 0.9255 - val_loss: 0.7653 - val_accuracy: 0.8323',\n",
       " 'Epoch 162/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.3485 - accuracy: 0.9273 - val_loss: 0.8621 - val_accuracy: 0.8102',\n",
       " 'Epoch 163/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.3431 - accuracy: 0.9284 - val_loss: 0.6966 - val_accuracy: 0.8400',\n",
       " 'Epoch 164/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.3473 - accuracy: 0.9263 - val_loss: 0.6647 - val_accuracy: 0.8458',\n",
       " 'Epoch 165/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.3493 - accuracy: 0.9256 - val_loss: 0.7269 - val_accuracy: 0.8378',\n",
       " 'Epoch 166/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.3417 - accuracy: 0.9282 - val_loss: 0.6705 - val_accuracy: 0.8467',\n",
       " 'Epoch 167/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.3437 - accuracy: 0.9283 - val_loss: 0.6731 - val_accuracy: 0.8454',\n",
       " 'Epoch 168/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 0.3427 - accuracy: 0.9290 - val_loss: 0.6205 - val_accuracy: 0.8632',\n",
       " 'Epoch 169/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.3345 - accuracy: 0.9321 - val_loss: 0.6706 - val_accuracy: 0.8445',\n",
       " 'Epoch 170/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.3428 - accuracy: 0.9280 - val_loss: 0.6996 - val_accuracy: 0.8395',\n",
       " 'Epoch 171/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.3418 - accuracy: 0.9286 - val_loss: 0.7535 - val_accuracy: 0.8222',\n",
       " 'Epoch 172/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.3368 - accuracy: 0.9298 - val_loss: 0.6665 - val_accuracy: 0.8473',\n",
       " 'Epoch 173/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.3376 - accuracy: 0.9288 - val_loss: 0.7368 - val_accuracy: 0.8275',\n",
       " 'Epoch 174/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.3312 - accuracy: 0.9310 - val_loss: 0.6454 - val_accuracy: 0.8510',\n",
       " 'Epoch 175/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.3346 - accuracy: 0.9298 - val_loss: 0.7085 - val_accuracy: 0.8391',\n",
       " 'Epoch 176/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.3343 - accuracy: 0.9304 - val_loss: 0.7461 - val_accuracy: 0.8379',\n",
       " 'Epoch 177/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.3363 - accuracy: 0.9302 - val_loss: 0.8247 - val_accuracy: 0.8162',\n",
       " 'Epoch 178/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.3359 - accuracy: 0.9303 - val_loss: 0.6700 - val_accuracy: 0.8463',\n",
       " 'Epoch 179/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.3332 - accuracy: 0.9315 - val_loss: 0.7507 - val_accuracy: 0.8346',\n",
       " 'Epoch 180/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 0.3345 - accuracy: 0.9317 - val_loss: 0.6369 - val_accuracy: 0.8548',\n",
       " 'Epoch 181/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 0.3288 - accuracy: 0.9323 - val_loss: 0.6668 - val_accuracy: 0.8444',\n",
       " 'Epoch 182/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.3256 - accuracy: 0.9342 - val_loss: 0.7236 - val_accuracy: 0.8449',\n",
       " 'Epoch 183/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.3316 - accuracy: 0.9312 - val_loss: 0.7541 - val_accuracy: 0.8382',\n",
       " 'Epoch 184/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.3286 - accuracy: 0.9326 - val_loss: 0.6289 - val_accuracy: 0.8535',\n",
       " 'Epoch 185/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.3266 - accuracy: 0.9327 - val_loss: 0.6611 - val_accuracy: 0.8476',\n",
       " 'Epoch 186/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.3289 - accuracy: 0.9318 - val_loss: 0.7026 - val_accuracy: 0.8415',\n",
       " 'Epoch 187/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.3318 - accuracy: 0.9321 - val_loss: 0.7372 - val_accuracy: 0.8318',\n",
       " 'Epoch 188/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.3292 - accuracy: 0.9323 - val_loss: 0.6257 - val_accuracy: 0.8538',\n",
       " 'Epoch 189/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.3286 - accuracy: 0.9333 - val_loss: 0.6941 - val_accuracy: 0.8452',\n",
       " 'Epoch 190/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.3272 - accuracy: 0.9327 - val_loss: 0.7283 - val_accuracy: 0.8353',\n",
       " 'Epoch 191/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.3183 - accuracy: 0.9364 - val_loss: 0.7015 - val_accuracy: 0.8436',\n",
       " 'Epoch 192/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.3251 - accuracy: 0.9340 - val_loss: 0.7640 - val_accuracy: 0.8329',\n",
       " 'Epoch 193/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.3232 - accuracy: 0.9339 - val_loss: 0.6122 - val_accuracy: 0.8564',\n",
       " 'Epoch 194/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.3223 - accuracy: 0.9345 - val_loss: 0.6764 - val_accuracy: 0.8485',\n",
       " 'Epoch 195/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.3215 - accuracy: 0.9354 - val_loss: 0.6869 - val_accuracy: 0.8418',\n",
       " 'Epoch 196/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.3213 - accuracy: 0.9353 - val_loss: 0.6983 - val_accuracy: 0.8443',\n",
       " 'Epoch 197/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.3198 - accuracy: 0.9345 - val_loss: 0.7679 - val_accuracy: 0.8276',\n",
       " 'Epoch 198/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.3177 - accuracy: 0.9353 - val_loss: 0.6658 - val_accuracy: 0.8462',\n",
       " 'Epoch 199/500',\n",
       " '390/390 [==============================] - 110s 283ms/step - loss: 0.3215 - accuracy: 0.9344 - val_loss: 0.8749 - val_accuracy: 0.8120',\n",
       " 'Epoch 200/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 0.3194 - accuracy: 0.9358 - val_loss: 0.7133 - val_accuracy: 0.8388',\n",
       " 'Epoch 201/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.3197 - accuracy: 0.9349 - val_loss: 0.7902 - val_accuracy: 0.8310',\n",
       " 'Epoch 202/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.3195 - accuracy: 0.9365 - val_loss: 0.7068 - val_accuracy: 0.8398',\n",
       " 'Epoch 203/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 0.3141 - accuracy: 0.9374 - val_loss: 0.7026 - val_accuracy: 0.8394',\n",
       " 'Epoch 204/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.3202 - accuracy: 0.9355 - val_loss: 0.6624 - val_accuracy: 0.8476',\n",
       " 'Epoch 205/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.3191 - accuracy: 0.9349 - val_loss: 0.7917 - val_accuracy: 0.8253',\n",
       " 'Epoch 206/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.3161 - accuracy: 0.9364 - val_loss: 0.8080 - val_accuracy: 0.8276',\n",
       " 'Epoch 207/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.3089 - accuracy: 0.9391 - val_loss: 0.6986 - val_accuracy: 0.8434',\n",
       " 'Epoch 208/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.3109 - accuracy: 0.9383 - val_loss: 0.6794 - val_accuracy: 0.8427',\n",
       " 'Epoch 209/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 0.3116 - accuracy: 0.9369 - val_loss: 0.6797 - val_accuracy: 0.8463',\n",
       " 'Epoch 210/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.3161 - accuracy: 0.9360 - val_loss: 0.7264 - val_accuracy: 0.8365',\n",
       " 'Epoch 211/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 0.3099 - accuracy: 0.9386 - val_loss: 0.6726 - val_accuracy: 0.8505',\n",
       " 'Epoch 212/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.3094 - accuracy: 0.9391 - val_loss: 0.7146 - val_accuracy: 0.8398',\n",
       " 'Epoch 213/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.3088 - accuracy: 0.9388 - val_loss: 0.7955 - val_accuracy: 0.8320',\n",
       " 'Epoch 214/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.3119 - accuracy: 0.9386 - val_loss: 0.7168 - val_accuracy: 0.8363',\n",
       " 'Epoch 215/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.3089 - accuracy: 0.9389 - val_loss: 0.6878 - val_accuracy: 0.8492',\n",
       " 'Epoch 216/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.3151 - accuracy: 0.9362 - val_loss: 0.7203 - val_accuracy: 0.8379',\n",
       " 'Epoch 217/500',\n",
       " '390/390 [==============================] - 110s 283ms/step - loss: 0.3067 - accuracy: 0.9397 - val_loss: 0.7213 - val_accuracy: 0.8420',\n",
       " 'Epoch 218/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.3131 - accuracy: 0.9376 - val_loss: 0.6650 - val_accuracy: 0.8522',\n",
       " 'Epoch 219/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 0.3060 - accuracy: 0.9396 - val_loss: 0.7011 - val_accuracy: 0.8440',\n",
       " 'Epoch 220/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.3075 - accuracy: 0.9400 - val_loss: 0.6790 - val_accuracy: 0.8543',\n",
       " 'Epoch 221/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.3046 - accuracy: 0.9413 - val_loss: 0.6216 - val_accuracy: 0.8585',\n",
       " 'Epoch 222/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.3099 - accuracy: 0.9373 - val_loss: 0.6922 - val_accuracy: 0.8502',\n",
       " 'Epoch 223/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.3038 - accuracy: 0.9404 - val_loss: 0.6552 - val_accuracy: 0.8478',\n",
       " 'Epoch 224/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.3005 - accuracy: 0.9418 - val_loss: 0.6608 - val_accuracy: 0.8510',\n",
       " 'Epoch 225/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.3073 - accuracy: 0.9390 - val_loss: 0.6958 - val_accuracy: 0.8508',\n",
       " 'Epoch 226/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.3046 - accuracy: 0.9410 - val_loss: 0.6881 - val_accuracy: 0.8473',\n",
       " 'Epoch 227/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.3084 - accuracy: 0.9383 - val_loss: 0.8249 - val_accuracy: 0.8274',\n",
       " 'Epoch 228/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.3040 - accuracy: 0.9410 - val_loss: 0.6705 - val_accuracy: 0.8480',\n",
       " 'Epoch 229/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.3043 - accuracy: 0.9394 - val_loss: 0.6781 - val_accuracy: 0.8474',\n",
       " 'Epoch 230/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.3042 - accuracy: 0.9412 - val_loss: 0.7273 - val_accuracy: 0.8329',\n",
       " 'Epoch 231/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 0.3017 - accuracy: 0.9417 - val_loss: 0.6684 - val_accuracy: 0.8465',\n",
       " 'Epoch 232/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 0.3011 - accuracy: 0.9410 - val_loss: 0.6391 - val_accuracy: 0.8602',\n",
       " 'Epoch 233/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.2978 - accuracy: 0.9421 - val_loss: 0.6991 - val_accuracy: 0.8495',\n",
       " 'Epoch 234/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.3034 - accuracy: 0.9408 - val_loss: 0.6925 - val_accuracy: 0.8489',\n",
       " 'Epoch 235/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.2976 - accuracy: 0.9433 - val_loss: 0.6635 - val_accuracy: 0.8527',\n",
       " 'Epoch 236/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 0.3014 - accuracy: 0.9418 - val_loss: 0.7973 - val_accuracy: 0.8294',\n",
       " 'Epoch 237/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.2985 - accuracy: 0.9419 - val_loss: 0.6742 - val_accuracy: 0.8506',\n",
       " 'Epoch 238/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.3011 - accuracy: 0.9413 - val_loss: 0.7191 - val_accuracy: 0.8471',\n",
       " 'Epoch 239/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.3012 - accuracy: 0.9401 - val_loss: 0.6431 - val_accuracy: 0.8521',\n",
       " 'Epoch 240/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.2997 - accuracy: 0.9419 - val_loss: 0.7556 - val_accuracy: 0.8458',\n",
       " 'Epoch 241/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.3001 - accuracy: 0.9402 - val_loss: 0.6356 - val_accuracy: 0.8536',\n",
       " 'Epoch 242/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.2992 - accuracy: 0.9418 - val_loss: 0.6312 - val_accuracy: 0.8588',\n",
       " 'Epoch 243/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.3016 - accuracy: 0.9401 - val_loss: 0.7272 - val_accuracy: 0.8391',\n",
       " 'Epoch 244/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 0.2998 - accuracy: 0.9414 - val_loss: 0.7180 - val_accuracy: 0.8344',\n",
       " 'Epoch 245/500',\n",
       " '390/390 [==============================] - 110s 282ms/step - loss: 0.2952 - accuracy: 0.9445 - val_loss: 0.7679 - val_accuracy: 0.8362',\n",
       " 'Epoch 246/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.3008 - accuracy: 0.9416 - val_loss: 0.6788 - val_accuracy: 0.8516',\n",
       " 'Epoch 247/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 0.2944 - accuracy: 0.9441 - val_loss: 0.6949 - val_accuracy: 0.8504',\n",
       " 'Epoch 248/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.2988 - accuracy: 0.9417 - val_loss: 0.6695 - val_accuracy: 0.8514',\n",
       " 'Epoch 249/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.2939 - accuracy: 0.9447 - val_loss: 0.8013 - val_accuracy: 0.8193',\n",
       " 'Epoch 250/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.2916 - accuracy: 0.9452 - val_loss: 0.6845 - val_accuracy: 0.8430',\n",
       " 'Epoch 251/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 0.2937 - accuracy: 0.9430 - val_loss: 0.7472 - val_accuracy: 0.8389',\n",
       " 'Epoch 252/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.2934 - accuracy: 0.9437 - val_loss: 0.6337 - val_accuracy: 0.8567',\n",
       " 'Epoch 253/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.2920 - accuracy: 0.9455 - val_loss: 0.6658 - val_accuracy: 0.8507',\n",
       " 'Epoch 254/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.2876 - accuracy: 0.9450 - val_loss: 0.6713 - val_accuracy: 0.8532',\n",
       " 'Epoch 255/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.2917 - accuracy: 0.9438 - val_loss: 0.7080 - val_accuracy: 0.8413',\n",
       " 'Epoch 256/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 0.2980 - accuracy: 0.9416 - val_loss: 0.7020 - val_accuracy: 0.8435',\n",
       " 'Epoch 257/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 0.2899 - accuracy: 0.9449 - val_loss: 0.6924 - val_accuracy: 0.8512',\n",
       " 'Epoch 258/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.2943 - accuracy: 0.9447 - val_loss: 0.6810 - val_accuracy: 0.8489',\n",
       " 'Epoch 259/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 0.2940 - accuracy: 0.9434 - val_loss: 0.8251 - val_accuracy: 0.8239',\n",
       " 'Epoch 260/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.2934 - accuracy: 0.9432 - val_loss: 0.7448 - val_accuracy: 0.8392',\n",
       " 'Epoch 261/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 0.2884 - accuracy: 0.9458 - val_loss: 0.6474 - val_accuracy: 0.8575',\n",
       " 'Epoch 262/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.2962 - accuracy: 0.9420 - val_loss: 0.7087 - val_accuracy: 0.8501',\n",
       " 'Epoch 263/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.2887 - accuracy: 0.9453 - val_loss: 0.6648 - val_accuracy: 0.8578',\n",
       " 'Epoch 264/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.2879 - accuracy: 0.9457 - val_loss: 0.8294 - val_accuracy: 0.8290',\n",
       " 'Epoch 265/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 0.2920 - accuracy: 0.9450 - val_loss: 0.6918 - val_accuracy: 0.8468',\n",
       " 'Epoch 266/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.2938 - accuracy: 0.9432 - val_loss: 0.6478 - val_accuracy: 0.8582',\n",
       " 'Epoch 267/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.2898 - accuracy: 0.9453 - val_loss: 0.6158 - val_accuracy: 0.8626',\n",
       " 'Epoch 268/500',\n",
       " '390/390 [==============================] - 110s 283ms/step - loss: 0.2877 - accuracy: 0.9446 - val_loss: 0.8230 - val_accuracy: 0.8223',\n",
       " 'Epoch 269/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.2908 - accuracy: 0.9447 - val_loss: 0.6714 - val_accuracy: 0.8470',\n",
       " 'Epoch 270/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.2868 - accuracy: 0.9467 - val_loss: 0.6512 - val_accuracy: 0.8538',\n",
       " 'Epoch 271/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.2885 - accuracy: 0.9455 - val_loss: 0.6484 - val_accuracy: 0.8568',\n",
       " 'Epoch 272/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.2928 - accuracy: 0.9437 - val_loss: 0.6663 - val_accuracy: 0.8477',\n",
       " 'Epoch 273/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 0.2873 - accuracy: 0.9464 - val_loss: 0.7923 - val_accuracy: 0.8270',\n",
       " 'Epoch 274/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 0.2907 - accuracy: 0.9440 - val_loss: 0.7000 - val_accuracy: 0.8391',\n",
       " 'Epoch 275/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.2882 - accuracy: 0.9450 - val_loss: 0.6631 - val_accuracy: 0.8568',\n",
       " 'Epoch 276/500',\n",
       " '390/390 [==============================] - 110s 282ms/step - loss: 0.2861 - accuracy: 0.9453 - val_loss: 0.5883 - val_accuracy: 0.8659',\n",
       " 'Epoch 277/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.2842 - accuracy: 0.9467 - val_loss: 0.7048 - val_accuracy: 0.8468',\n",
       " 'Epoch 278/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.2877 - accuracy: 0.9462 - val_loss: 0.6291 - val_accuracy: 0.8538',\n",
       " 'Epoch 279/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.2888 - accuracy: 0.9445 - val_loss: 0.7404 - val_accuracy: 0.8354',\n",
       " 'Epoch 280/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.2836 - accuracy: 0.9466 - val_loss: 0.7674 - val_accuracy: 0.8370',\n",
       " 'Epoch 281/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.2892 - accuracy: 0.9446 - val_loss: 0.7080 - val_accuracy: 0.8475',\n",
       " 'Epoch 282/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.2880 - accuracy: 0.9452 - val_loss: 0.7282 - val_accuracy: 0.8448',\n",
       " 'Epoch 283/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.2869 - accuracy: 0.9450 - val_loss: 0.6440 - val_accuracy: 0.8607',\n",
       " 'Epoch 284/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.2859 - accuracy: 0.9458 - val_loss: 0.6764 - val_accuracy: 0.8526',\n",
       " 'Epoch 285/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 0.2879 - accuracy: 0.9450 - val_loss: 0.7023 - val_accuracy: 0.8520',\n",
       " 'Epoch 286/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.2799 - accuracy: 0.9495 - val_loss: 0.6175 - val_accuracy: 0.8683',\n",
       " 'Epoch 287/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.2827 - accuracy: 0.9475 - val_loss: 0.8263 - val_accuracy: 0.8273',\n",
       " 'Epoch 288/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.2795 - accuracy: 0.9479 - val_loss: 0.6924 - val_accuracy: 0.8450',\n",
       " 'Epoch 289/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.2856 - accuracy: 0.9450 - val_loss: 0.7191 - val_accuracy: 0.8407',\n",
       " 'Epoch 290/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.2855 - accuracy: 0.9466 - val_loss: 0.6592 - val_accuracy: 0.8526',\n",
       " 'Epoch 291/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.2824 - accuracy: 0.9471 - val_loss: 0.7608 - val_accuracy: 0.8409',\n",
       " 'Epoch 292/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.2832 - accuracy: 0.9471 - val_loss: 0.6451 - val_accuracy: 0.8550',\n",
       " 'Epoch 293/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.2814 - accuracy: 0.9486 - val_loss: 0.6678 - val_accuracy: 0.8492',\n",
       " 'Epoch 294/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.2799 - accuracy: 0.9482 - val_loss: 0.6797 - val_accuracy: 0.8521',\n",
       " 'Epoch 295/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.2859 - accuracy: 0.9457 - val_loss: 0.6798 - val_accuracy: 0.8507',\n",
       " 'Epoch 296/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.2834 - accuracy: 0.9474 - val_loss: 0.6828 - val_accuracy: 0.8566',\n",
       " 'Epoch 297/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.2803 - accuracy: 0.9488 - val_loss: 0.6909 - val_accuracy: 0.8460',\n",
       " 'Epoch 298/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.2798 - accuracy: 0.9485 - val_loss: 0.6899 - val_accuracy: 0.8437',\n",
       " 'Epoch 299/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.2770 - accuracy: 0.9484 - val_loss: 0.6863 - val_accuracy: 0.8503',\n",
       " 'Epoch 300/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.2809 - accuracy: 0.9467 - val_loss: 0.6927 - val_accuracy: 0.8499',\n",
       " 'Epoch 301/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.2792 - accuracy: 0.9484 - val_loss: 0.6560 - val_accuracy: 0.8580',\n",
       " 'Epoch 302/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.2802 - accuracy: 0.9472 - val_loss: 0.6405 - val_accuracy: 0.8626',\n",
       " 'Epoch 303/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.2779 - accuracy: 0.9488 - val_loss: 0.6713 - val_accuracy: 0.8536',\n",
       " 'Epoch 304/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.2779 - accuracy: 0.9496 - val_loss: 0.6530 - val_accuracy: 0.8614',\n",
       " 'Epoch 305/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.2770 - accuracy: 0.9488 - val_loss: 0.7120 - val_accuracy: 0.8528',\n",
       " 'Epoch 306/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.2791 - accuracy: 0.9481 - val_loss: 0.6720 - val_accuracy: 0.8495',\n",
       " 'Epoch 307/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.2819 - accuracy: 0.9472 - val_loss: 0.7144 - val_accuracy: 0.8472',\n",
       " 'Epoch 308/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.2753 - accuracy: 0.9498 - val_loss: 0.7666 - val_accuracy: 0.8306',\n",
       " 'Epoch 309/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.2816 - accuracy: 0.9475 - val_loss: 0.6860 - val_accuracy: 0.8523',\n",
       " 'Epoch 310/500',\n",
       " '390/390 [==============================] - 110s 282ms/step - loss: 0.2776 - accuracy: 0.9483 - val_loss: 0.6804 - val_accuracy: 0.8555',\n",
       " 'Epoch 311/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.2786 - accuracy: 0.9486 - val_loss: 0.7367 - val_accuracy: 0.8473',\n",
       " 'Epoch 312/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.2726 - accuracy: 0.9506 - val_loss: 0.7451 - val_accuracy: 0.8436',\n",
       " 'Epoch 313/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 0.2743 - accuracy: 0.9501 - val_loss: 0.6761 - val_accuracy: 0.8491',\n",
       " 'Epoch 314/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.2786 - accuracy: 0.9481 - val_loss: 0.7307 - val_accuracy: 0.8401',\n",
       " 'Epoch 315/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.2759 - accuracy: 0.9497 - val_loss: 0.6713 - val_accuracy: 0.8542',\n",
       " 'Epoch 316/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 0.2738 - accuracy: 0.9512 - val_loss: 0.6667 - val_accuracy: 0.8529',\n",
       " 'Epoch 317/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.2760 - accuracy: 0.9498 - val_loss: 0.7754 - val_accuracy: 0.8369',\n",
       " 'Epoch 318/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 0.2765 - accuracy: 0.9477 - val_loss: 0.6874 - val_accuracy: 0.8531',\n",
       " 'Epoch 319/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.2715 - accuracy: 0.9517 - val_loss: 0.6533 - val_accuracy: 0.8537',\n",
       " 'Epoch 320/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.2762 - accuracy: 0.9483 - val_loss: 0.7438 - val_accuracy: 0.8434',\n",
       " 'Epoch 321/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 0.2733 - accuracy: 0.9509 - val_loss: 0.7636 - val_accuracy: 0.8368',\n",
       " 'Epoch 322/500',\n",
       " '390/390 [==============================] - 110s 282ms/step - loss: 0.2731 - accuracy: 0.9500 - val_loss: 0.7383 - val_accuracy: 0.8384',\n",
       " 'Epoch 323/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 0.2705 - accuracy: 0.9519 - val_loss: 0.6764 - val_accuracy: 0.8581',\n",
       " 'Epoch 324/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.2768 - accuracy: 0.9494 - val_loss: 0.6772 - val_accuracy: 0.8575',\n",
       " 'Epoch 325/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 0.2719 - accuracy: 0.9510 - val_loss: 0.6400 - val_accuracy: 0.8595',\n",
       " 'Epoch 326/500',\n",
       " '390/390 [==============================] - 114s 293ms/step - loss: 0.2663 - accuracy: 0.9526 - val_loss: 0.6620 - val_accuracy: 0.8509',\n",
       " 'Epoch 327/500',\n",
       " '390/390 [==============================] - 112s 286ms/step - loss: 0.2744 - accuracy: 0.9492 - val_loss: 0.6701 - val_accuracy: 0.8544',\n",
       " 'Epoch 328/500',\n",
       " '390/390 [==============================] - 114s 291ms/step - loss: 0.2695 - accuracy: 0.9514 - val_loss: 0.6916 - val_accuracy: 0.8550',\n",
       " 'Epoch 329/500',\n",
       " '390/390 [==============================] - 115s 294ms/step - loss: 0.2722 - accuracy: 0.9512 - val_loss: 0.7454 - val_accuracy: 0.8447',\n",
       " 'Epoch 330/500',\n",
       " '390/390 [==============================] - 116s 297ms/step - loss: 0.2795 - accuracy: 0.9474 - val_loss: 0.7416 - val_accuracy: 0.8388',\n",
       " 'Epoch 331/500',\n",
       " '390/390 [==============================] - 112s 287ms/step - loss: 0.2745 - accuracy: 0.9499 - val_loss: 0.7185 - val_accuracy: 0.8433',\n",
       " 'Epoch 332/500',\n",
       " '390/390 [==============================] - 113s 291ms/step - loss: 0.2728 - accuracy: 0.9506 - val_loss: 0.6861 - val_accuracy: 0.8568',\n",
       " 'Epoch 333/500',\n",
       " '390/390 [==============================] - 114s 292ms/step - loss: 0.2720 - accuracy: 0.9499 - val_loss: 0.7373 - val_accuracy: 0.8420',\n",
       " 'Epoch 334/500',\n",
       " '390/390 [==============================] - 113s 291ms/step - loss: 0.2694 - accuracy: 0.9522 - val_loss: 0.6462 - val_accuracy: 0.8587',\n",
       " 'Epoch 335/500',\n",
       " '390/390 [==============================] - 113s 289ms/step - loss: 0.2732 - accuracy: 0.9501 - val_loss: 0.7015 - val_accuracy: 0.8469',\n",
       " 'Epoch 336/500',\n",
       " '390/390 [==============================] - 111s 286ms/step - loss: 0.2731 - accuracy: 0.9498 - val_loss: 0.6470 - val_accuracy: 0.8630',\n",
       " 'Epoch 337/500',\n",
       " '390/390 [==============================] - 111s 285ms/step - loss: 0.2729 - accuracy: 0.9503 - val_loss: 0.8527 - val_accuracy: 0.8240',\n",
       " 'Epoch 338/500',\n",
       " '390/390 [==============================] - 111s 285ms/step - loss: 0.2708 - accuracy: 0.9513 - val_loss: 0.6755 - val_accuracy: 0.8525',\n",
       " 'Epoch 339/500',\n",
       " '390/390 [==============================] - 112s 286ms/step - loss: 0.2735 - accuracy: 0.9506 - val_loss: 0.7327 - val_accuracy: 0.8424',\n",
       " 'Epoch 340/500',\n",
       " '390/390 [==============================] - 111s 285ms/step - loss: 0.2710 - accuracy: 0.9513 - val_loss: 0.6720 - val_accuracy: 0.8564',\n",
       " 'Epoch 341/500',\n",
       " '390/390 [==============================] - 111s 286ms/step - loss: 0.2726 - accuracy: 0.9515 - val_loss: 0.6834 - val_accuracy: 0.8543',\n",
       " 'Epoch 342/500',\n",
       " '390/390 [==============================] - 111s 285ms/step - loss: 0.2674 - accuracy: 0.9522 - val_loss: 0.6595 - val_accuracy: 0.8561',\n",
       " 'Epoch 343/500',\n",
       " '390/390 [==============================] - 115s 294ms/step - loss: 0.2674 - accuracy: 0.9519 - val_loss: 0.6965 - val_accuracy: 0.8480',\n",
       " 'Epoch 344/500',\n",
       " '390/390 [==============================] - 128s 327ms/step - loss: 0.2742 - accuracy: 0.9498 - val_loss: 0.8320 - val_accuracy: 0.8341',\n",
       " 'Epoch 345/500',\n",
       " '390/390 [==============================] - 127s 327ms/step - loss: 0.2688 - accuracy: 0.9515 - val_loss: 0.7245 - val_accuracy: 0.8485',\n",
       " 'Epoch 346/500',\n",
       " '390/390 [==============================] - 122s 313ms/step - loss: 0.2741 - accuracy: 0.9487 - val_loss: 0.8742 - val_accuracy: 0.8256',\n",
       " 'Epoch 347/500',\n",
       " '390/390 [==============================] - 111s 284ms/step - loss: 0.2724 - accuracy: 0.9503 - val_loss: 0.7522 - val_accuracy: 0.8332',\n",
       " 'Epoch 348/500',\n",
       " '390/390 [==============================] - 111s 285ms/step - loss: 0.2677 - accuracy: 0.9521 - val_loss: 0.6746 - val_accuracy: 0.8563',\n",
       " 'Epoch 349/500',\n",
       " '390/390 [==============================] - 111s 285ms/step - loss: 0.2681 - accuracy: 0.9515 - val_loss: 0.7856 - val_accuracy: 0.8296',\n",
       " 'Epoch 350/500',\n",
       " '390/390 [==============================] - 111s 285ms/step - loss: 0.2669 - accuracy: 0.9532 - val_loss: 0.6581 - val_accuracy: 0.8571',\n",
       " 'Epoch 351/500',\n",
       " '390/390 [==============================] - 111s 285ms/step - loss: 0.2676 - accuracy: 0.9518 - val_loss: 0.6211 - val_accuracy: 0.8610',\n",
       " 'Epoch 352/500',\n",
       " '390/390 [==============================] - 111s 286ms/step - loss: 0.2686 - accuracy: 0.9524 - val_loss: 0.6593 - val_accuracy: 0.8573',\n",
       " 'Epoch 353/500',\n",
       " '390/390 [==============================] - 111s 285ms/step - loss: 0.2682 - accuracy: 0.9525 - val_loss: 0.7021 - val_accuracy: 0.8523',\n",
       " 'Epoch 354/500',\n",
       " '390/390 [==============================] - 124s 317ms/step - loss: 0.2672 - accuracy: 0.9532 - val_loss: 0.6965 - val_accuracy: 0.8492',\n",
       " 'Epoch 355/500',\n",
       " '390/390 [==============================] - 116s 297ms/step - loss: 0.2666 - accuracy: 0.9525 - val_loss: 0.7969 - val_accuracy: 0.8292',\n",
       " 'Epoch 356/500',\n",
       " '390/390 [==============================] - 110s 282ms/step - loss: 0.2659 - accuracy: 0.9533 - val_loss: 0.7062 - val_accuracy: 0.8461',\n",
       " 'Epoch 357/500',\n",
       " '390/390 [==============================] - 111s 286ms/step - loss: 0.2701 - accuracy: 0.9506 - val_loss: 0.7249 - val_accuracy: 0.8499',\n",
       " 'Epoch 358/500',\n",
       " '390/390 [==============================] - 110s 282ms/step - loss: 0.2630 - accuracy: 0.9538 - val_loss: 0.7024 - val_accuracy: 0.8479',\n",
       " 'Epoch 359/500',\n",
       " '390/390 [==============================] - 110s 282ms/step - loss: 0.2685 - accuracy: 0.9502 - val_loss: 0.6537 - val_accuracy: 0.8627',\n",
       " 'Epoch 360/500',\n",
       " '390/390 [==============================] - 110s 282ms/step - loss: 0.2691 - accuracy: 0.9515 - val_loss: 0.6930 - val_accuracy: 0.8517',\n",
       " 'Epoch 361/500',\n",
       " '390/390 [==============================] - 110s 282ms/step - loss: 0.2640 - accuracy: 0.9536 - val_loss: 0.6640 - val_accuracy: 0.8533',\n",
       " 'Epoch 362/500',\n",
       " '390/390 [==============================] - 110s 282ms/step - loss: 0.2663 - accuracy: 0.9527 - val_loss: 0.6400 - val_accuracy: 0.8611',\n",
       " 'Epoch 363/500',\n",
       " '390/390 [==============================] - 120s 309ms/step - loss: 0.2690 - accuracy: 0.9512 - val_loss: 0.7377 - val_accuracy: 0.8530',\n",
       " 'Epoch 364/500',\n",
       " '390/390 [==============================] - 127s 325ms/step - loss: 0.2642 - accuracy: 0.9536 - val_loss: 0.6716 - val_accuracy: 0.8618',\n",
       " 'Epoch 365/500',\n",
       " '390/390 [==============================] - 128s 327ms/step - loss: 0.2653 - accuracy: 0.9526 - val_loss: 0.7125 - val_accuracy: 0.8529',\n",
       " 'Epoch 366/500',\n",
       " '390/390 [==============================] - 128s 328ms/step - loss: 0.2677 - accuracy: 0.9509 - val_loss: 0.6676 - val_accuracy: 0.8515',\n",
       " 'Epoch 367/500',\n",
       " '390/390 [==============================] - 127s 325ms/step - loss: 0.2668 - accuracy: 0.9531 - val_loss: 0.7023 - val_accuracy: 0.8529',\n",
       " 'Epoch 368/500',\n",
       " '390/390 [==============================] - 111s 285ms/step - loss: 0.2694 - accuracy: 0.9504 - val_loss: 0.7458 - val_accuracy: 0.8407',\n",
       " 'Epoch 369/500',\n",
       " '390/390 [==============================] - 110s 282ms/step - loss: 0.2675 - accuracy: 0.9522 - val_loss: 0.6850 - val_accuracy: 0.8518',\n",
       " 'Epoch 370/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.2644 - accuracy: 0.9527 - val_loss: 0.7056 - val_accuracy: 0.8494',\n",
       " 'Epoch 371/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.2637 - accuracy: 0.9522 - val_loss: 0.6489 - val_accuracy: 0.8566',\n",
       " 'Epoch 372/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.2659 - accuracy: 0.9526 - val_loss: 0.6922 - val_accuracy: 0.8555',\n",
       " 'Epoch 373/500',\n",
       " '390/390 [==============================] - 110s 282ms/step - loss: 0.2608 - accuracy: 0.9551 - val_loss: 0.6417 - val_accuracy: 0.8606',\n",
       " 'Epoch 374/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.2644 - accuracy: 0.9535 - val_loss: 0.6931 - val_accuracy: 0.8561',\n",
       " 'Epoch 375/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 0.2617 - accuracy: 0.9531 - val_loss: 0.7804 - val_accuracy: 0.8321',\n",
       " 'Epoch 376/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.2647 - accuracy: 0.9525 - val_loss: 0.7794 - val_accuracy: 0.8333',\n",
       " 'Epoch 377/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 0.2641 - accuracy: 0.9532 - val_loss: 0.7805 - val_accuracy: 0.8368',\n",
       " 'Epoch 378/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.2666 - accuracy: 0.9517 - val_loss: 0.6105 - val_accuracy: 0.8671',\n",
       " 'Epoch 379/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.2642 - accuracy: 0.9526 - val_loss: 0.6633 - val_accuracy: 0.8573',\n",
       " 'Epoch 380/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.2619 - accuracy: 0.9539 - val_loss: 0.6349 - val_accuracy: 0.8556',\n",
       " 'Epoch 381/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 0.2654 - accuracy: 0.9533 - val_loss: 0.6601 - val_accuracy: 0.8625',\n",
       " 'Epoch 382/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.2633 - accuracy: 0.9530 - val_loss: 0.6633 - val_accuracy: 0.8596',\n",
       " 'Epoch 383/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.2595 - accuracy: 0.9548 - val_loss: 0.7185 - val_accuracy: 0.8444',\n",
       " 'Epoch 384/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 0.2650 - accuracy: 0.9528 - val_loss: 0.6608 - val_accuracy: 0.8551',\n",
       " 'Epoch 385/500',\n",
       " '390/390 [==============================] - 110s 282ms/step - loss: 0.2602 - accuracy: 0.9544 - val_loss: 0.6564 - val_accuracy: 0.8623',\n",
       " 'Epoch 386/500',\n",
       " '390/390 [==============================] - 111s 285ms/step - loss: 0.2605 - accuracy: 0.9536 - val_loss: 0.7244 - val_accuracy: 0.8448',\n",
       " 'Epoch 387/500',\n",
       " '390/390 [==============================] - 113s 289ms/step - loss: 0.2627 - accuracy: 0.9525 - val_loss: 0.7320 - val_accuracy: 0.8400',\n",
       " 'Epoch 388/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 0.2590 - accuracy: 0.9551 - val_loss: 0.7197 - val_accuracy: 0.8470',\n",
       " 'Epoch 389/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.2637 - accuracy: 0.9530 - val_loss: 0.6643 - val_accuracy: 0.8647',\n",
       " 'Epoch 390/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.2636 - accuracy: 0.9516 - val_loss: 0.7211 - val_accuracy: 0.8525',\n",
       " 'Epoch 391/500',\n",
       " '390/390 [==============================] - 109s 281ms/step - loss: 0.2630 - accuracy: 0.9542 - val_loss: 0.7936 - val_accuracy: 0.8417',\n",
       " 'Epoch 392/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.2643 - accuracy: 0.9529 - val_loss: 0.6415 - val_accuracy: 0.8582',\n",
       " 'Epoch 393/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.2624 - accuracy: 0.9523 - val_loss: 0.6906 - val_accuracy: 0.8505',\n",
       " 'Epoch 394/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.2641 - accuracy: 0.9533 - val_loss: 0.7900 - val_accuracy: 0.8337',\n",
       " 'Epoch 395/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.2596 - accuracy: 0.9550 - val_loss: 0.7332 - val_accuracy: 0.8525',\n",
       " 'Epoch 396/500',\n",
       " '390/390 [==============================] - 110s 281ms/step - loss: 0.2592 - accuracy: 0.9551 - val_loss: 0.7620 - val_accuracy: 0.8421',\n",
       " 'Epoch 397/500',\n",
       " '390/390 [==============================] - 109s 280ms/step - loss: 0.2639 - accuracy: 0.9529 - val_loss: 0.7878 - val_accuracy: 0.8388',\n",
       " 'Epoch 398/500',\n",
       " '390/390 [==============================] - 110s 282ms/step - loss: 0.2582 - accuracy: 0.9538 - val_loss: 0.7343 - val_accuracy: 0.8463',\n",
       " 'Epoch 399/500',\n",
       " '390/390 [==============================] - 112s 288ms/step - loss: 0.2623 - accuracy: 0.9541 - val_loss: 0.6424 - val_accuracy: 0.8570',\n",
       " 'Epoch 400/500',\n",
       " '390/390 [==============================] - 111s 285ms/step - loss: 0.2579 - accuracy: 0.9536 - val_loss: 0.7216 - val_accuracy: 0.8420',\n",
       " 'Epoch 401/500',\n",
       " '390/390 [==============================] - 111s 285ms/step - loss: 0.2621 - accuracy: 0.9533 - val_loss: 0.6775 - val_accuracy: 0.8556',\n",
       " 'Epoch 402/500',\n",
       " '390/390 [==============================] - 111s 285ms/step - loss: 0.2603 - accuracy: 0.9547 - val_loss: 0.7284 - val_accuracy: 0.8466',\n",
       " 'Epoch 403/500',\n",
       " '390/390 [==============================] - 114s 293ms/step - loss: 0.2548 - accuracy: 0.9544 - val_loss: 0.7301 - val_accuracy: 0.8443',\n",
       " 'Epoch 404/500',\n",
       " '390/390 [==============================] - 116s 297ms/step - loss: 0.2612 - accuracy: 0.9543 - val_loss: 0.7883 - val_accuracy: 0.8323',\n",
       " 'Epoch 405/500',\n",
       " '390/390 [==============================] - 132s 339ms/step - loss: 0.2622 - accuracy: 0.9542 - val_loss: 0.7217 - val_accuracy: 0.8503',\n",
       " 'Epoch 406/500',\n",
       " '390/390 [==============================] - 139s 357ms/step - loss: 0.2604 - accuracy: 0.9539 - val_loss: 0.6567 - val_accuracy: 0.8566',\n",
       " '']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'390/390 [==============================] - 109s 281ms/step - loss: 2.0599 - accuracy: 0.4107 - val_loss: 1.8859 - val_accuracy: 0.4693'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitted[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== i 0\n",
      "===== i 1\n",
      "1\n",
      "['loss', '2.0599']\n",
      "['accuracy', '0.4107']\n",
      "['val_loss', '1.8859']\n",
      "['val_accuracy', '0.4693']\n",
      "===== i 2\n",
      "2\n",
      "['loss', '1.7205']\n",
      "['accuracy', '0.5219']\n",
      "['val_loss', '1.9937']\n",
      "['val_accuracy', '0.4844']\n",
      "===== i 3\n",
      "3\n",
      "['loss', '1.5905']\n",
      "['accuracy', '0.5688']\n",
      "['val_loss', '1.6765']\n",
      "['val_accuracy', '0.5591']\n",
      "===== i 4\n",
      "4\n",
      "['loss', '1.4974']\n",
      "['accuracy', '0.6016']\n",
      "['val_loss', '1.4793']\n",
      "['val_accuracy', '0.6142']\n",
      "===== i 5\n",
      "5\n",
      "['loss', '1.4271']\n",
      "['accuracy', '0.6250']\n",
      "['val_loss', '1.5261']\n",
      "['val_accuracy', '0.5974']\n",
      "===== i 6\n",
      "6\n",
      "['loss', '1.3700']\n",
      "['accuracy', '0.6446']\n",
      "['val_loss', '1.4851']\n",
      "['val_accuracy', '0.6282']\n",
      "===== i 7\n",
      "7\n",
      "['loss', '1.3220']\n",
      "['accuracy', '0.6601']\n",
      "['val_loss', '1.2994']\n",
      "['val_accuracy', '0.6803']\n",
      "===== i 8\n",
      "8\n",
      "['loss', '1.2739']\n",
      "['accuracy', '0.6759']\n",
      "['val_loss', '1.2912']\n",
      "['val_accuracy', '0.6783']\n",
      "===== i 9\n",
      "9\n",
      "['loss', '1.2277']\n",
      "['accuracy', '0.6915']\n",
      "['val_loss', '1.2616']\n",
      "['val_accuracy', '0.6900']\n",
      "===== i 10\n",
      "10\n",
      "['loss', '1.1872']\n",
      "['accuracy', '0.7038']\n",
      "['val_loss', '1.3190']\n",
      "['val_accuracy', '0.6726']\n",
      "===== i 11\n",
      "11\n",
      "['loss', '1.1571']\n",
      "['accuracy', '0.7128']\n",
      "['val_loss', '1.2867']\n",
      "['val_accuracy', '0.6792']\n",
      "===== i 12\n",
      "12\n",
      "['loss', '1.1277']\n",
      "['accuracy', '0.7219']\n",
      "['val_loss', '1.4620']\n",
      "['val_accuracy', '0.6396']\n",
      "===== i 13\n",
      "13\n",
      "['loss', '1.1028']\n",
      "['accuracy', '0.7280']\n",
      "['val_loss', '1.1590']\n",
      "['val_accuracy', '0.7258']\n",
      "===== i 14\n",
      "14\n",
      "['loss', '1.0755']\n",
      "['accuracy', '0.7381']\n",
      "['val_loss', '1.0992']\n",
      "['val_accuracy', '0.7424']\n",
      "===== i 15\n",
      "15\n",
      "['loss', '1.0511']\n",
      "['accuracy', '0.7459']\n",
      "['val_loss', '1.2855']\n",
      "['val_accuracy', '0.6940']\n",
      "===== i 16\n",
      "16\n",
      "['loss', '1.0278']\n",
      "['accuracy', '0.7506']\n",
      "['val_loss', '1.1468']\n",
      "['val_accuracy', '0.7265']\n",
      "===== i 17\n",
      "17\n",
      "['loss', '1.0140']\n",
      "['accuracy', '0.7562']\n",
      "['val_loss', '1.1902']\n",
      "['val_accuracy', '0.7183']\n",
      "===== i 18\n",
      "18\n",
      "['loss', '0.9820']\n",
      "['accuracy', '0.7662']\n",
      "['val_loss', '1.0532']\n",
      "['val_accuracy', '0.7541']\n",
      "===== i 19\n",
      "19\n",
      "['loss', '0.9678']\n",
      "['accuracy', '0.7707']\n",
      "['val_loss', '1.0227']\n",
      "['val_accuracy', '0.7582']\n",
      "===== i 20\n",
      "20\n",
      "['loss', '0.9565']\n",
      "['accuracy', '0.7727']\n",
      "['val_loss', '1.0175']\n",
      "['val_accuracy', '0.7660']\n",
      "===== i 21\n",
      "21\n",
      "['loss', '0.9401']\n",
      "['accuracy', '0.7755']\n",
      "['val_loss', '1.0776']\n",
      "['val_accuracy', '0.7495']\n",
      "===== i 22\n",
      "22\n",
      "['loss', '0.9174']\n",
      "['accuracy', '0.7846']\n",
      "['val_loss', '1.1113']\n",
      "['val_accuracy', '0.7345']\n",
      "===== i 23\n",
      "23\n",
      "['loss', '0.9102']\n",
      "['accuracy', '0.7841']\n",
      "['val_loss', '1.0366']\n",
      "['val_accuracy', '0.7573']\n",
      "===== i 24\n",
      "24\n",
      "['loss', '0.8935']\n",
      "['accuracy', '0.7870']\n",
      "['val_loss', '1.1080']\n",
      "['val_accuracy', '0.7364']\n",
      "===== i 25\n",
      "25\n",
      "['loss', '0.8751']\n",
      "['accuracy', '0.7944']\n",
      "['val_loss', '0.9486']\n",
      "['val_accuracy', '0.7782']\n",
      "===== i 26\n",
      "26\n",
      "['loss', '0.8635']\n",
      "['accuracy', '0.7977']\n",
      "['val_loss', '0.9943']\n",
      "['val_accuracy', '0.7717']\n",
      "===== i 27\n",
      "27\n",
      "['loss', '0.8496']\n",
      "['accuracy', '0.8022']\n",
      "['val_loss', '0.9457']\n",
      "['val_accuracy', '0.7786']\n",
      "===== i 28\n",
      "28\n",
      "['loss', '0.8395']\n",
      "['accuracy', '0.8027']\n",
      "['val_loss', '0.9368']\n",
      "['val_accuracy', '0.7791']\n",
      "===== i 29\n",
      "29\n",
      "['loss', '0.8291']\n",
      "['accuracy', '0.8066']\n",
      "['val_loss', '0.9918']\n",
      "['val_accuracy', '0.7723']\n",
      "===== i 30\n",
      "30\n",
      "['loss', '0.8171']\n",
      "['accuracy', '0.8100']\n",
      "['val_loss', '1.0488']\n",
      "['val_accuracy', '0.7564']\n",
      "===== i 31\n",
      "31\n",
      "['loss', '0.8074']\n",
      "['accuracy', '0.8119']\n",
      "['val_loss', '0.8897']\n",
      "['val_accuracy', '0.7932']\n",
      "===== i 32\n",
      "32\n",
      "['loss', '0.7953']\n",
      "['accuracy', '0.8157']\n",
      "['val_loss', '0.8769']\n",
      "['val_accuracy', '0.8045']\n",
      "===== i 33\n",
      "33\n",
      "['loss', '0.7836']\n",
      "['accuracy', '0.8187']\n",
      "['val_loss', '0.8802']\n",
      "['val_accuracy', '0.8007']\n",
      "===== i 34\n",
      "34\n",
      "['loss', '0.7703']\n",
      "['accuracy', '0.8216']\n",
      "['val_loss', '0.8704']\n",
      "['val_accuracy', '0.8038']\n",
      "===== i 35\n",
      "35\n",
      "['loss', '0.7665']\n",
      "['accuracy', '0.8241']\n",
      "['val_loss', '0.8473']\n",
      "['val_accuracy', '0.8063']\n",
      "===== i 36\n",
      "36\n",
      "['loss', '0.7571']\n",
      "['accuracy', '0.8253']\n",
      "['val_loss', '0.9571']\n",
      "['val_accuracy', '0.7805']\n",
      "===== i 37\n",
      "37\n",
      "['loss', '0.7461']\n",
      "['accuracy', '0.8266']\n",
      "['val_loss', '0.8691']\n",
      "['val_accuracy', '0.7997']\n",
      "===== i 38\n",
      "38\n",
      "['loss', '0.7360']\n",
      "['accuracy', '0.8314']\n",
      "['val_loss', '0.9446']\n",
      "['val_accuracy', '0.7772']\n",
      "===== i 39\n",
      "39\n",
      "['loss', '0.7283']\n",
      "['accuracy', '0.8309']\n",
      "['val_loss', '0.8442']\n",
      "['val_accuracy', '0.8037']\n",
      "===== i 40\n",
      "40\n",
      "['loss', '0.7202']\n",
      "['accuracy', '0.8347']\n",
      "['val_loss', '0.8885']\n",
      "['val_accuracy', '0.7935']\n",
      "===== i 41\n",
      "41\n",
      "['loss', '0.7188']\n",
      "['accuracy', '0.8330']\n",
      "['val_loss', '0.8955']\n",
      "['val_accuracy', '0.7898']\n",
      "===== i 42\n",
      "42\n",
      "['loss', '0.7046']\n",
      "['accuracy', '0.8397']\n",
      "['val_loss', '0.8608']\n",
      "['val_accuracy', '0.8028']\n",
      "===== i 43\n",
      "43\n",
      "['loss', '0.6946']\n",
      "['accuracy', '0.8395']\n",
      "['val_loss', '0.8278']\n",
      "['val_accuracy', '0.8117']\n",
      "===== i 44\n",
      "44\n",
      "['loss', '0.6887']\n",
      "['accuracy', '0.8418']\n",
      "['val_loss', '0.8742']\n",
      "['val_accuracy', '0.7925']\n",
      "===== i 45\n",
      "45\n",
      "['loss', '0.6783']\n",
      "['accuracy', '0.8446']\n",
      "['val_loss', '0.8551']\n",
      "['val_accuracy', '0.8005']\n",
      "===== i 46\n",
      "46\n",
      "['loss', '0.6786']\n",
      "['accuracy', '0.8439']\n",
      "['val_loss', '0.8351']\n",
      "['val_accuracy', '0.8032']\n",
      "===== i 47\n",
      "47\n",
      "['loss', '0.6651']\n",
      "['accuracy', '0.8478']\n",
      "['val_loss', '0.8334']\n",
      "['val_accuracy', '0.8021']\n",
      "===== i 48\n",
      "48\n",
      "['loss', '0.6626']\n",
      "['accuracy', '0.8482']\n",
      "['val_loss', '0.8033']\n",
      "['val_accuracy', '0.8168']\n",
      "===== i 49\n",
      "49\n",
      "['loss', '0.6481']\n",
      "['accuracy', '0.8510']\n",
      "['val_loss', '0.8713']\n",
      "['val_accuracy', '0.8006']\n",
      "===== i 50\n",
      "50\n",
      "['loss', '0.6409']\n",
      "['accuracy', '0.8544']\n",
      "['val_loss', '0.8011']\n",
      "['val_accuracy', '0.8171']\n",
      "===== i 51\n",
      "51\n",
      "['loss', '0.6448']\n",
      "['accuracy', '0.8517']\n",
      "['val_loss', '0.8453']\n",
      "['val_accuracy', '0.8102']\n",
      "===== i 52\n",
      "52\n",
      "['loss', '0.6380']\n",
      "['accuracy', '0.8545']\n",
      "['val_loss', '0.7950']\n",
      "['val_accuracy', '0.8185']\n",
      "===== i 53\n",
      "53\n",
      "['loss', '0.6299']\n",
      "['accuracy', '0.8556']\n",
      "['val_loss', '0.7773']\n",
      "['val_accuracy', '0.8177']\n",
      "===== i 54\n",
      "54\n",
      "['loss', '0.6212']\n",
      "['accuracy', '0.8579']\n",
      "['val_loss', '0.7947']\n",
      "['val_accuracy', '0.8141']\n",
      "===== i 55\n",
      "55\n",
      "['loss', '0.6146']\n",
      "['accuracy', '0.8589']\n",
      "['val_loss', '0.9437']\n",
      "['val_accuracy', '0.7802']\n",
      "===== i 56\n",
      "56\n",
      "['loss', '0.6104']\n",
      "['accuracy', '0.8621']\n",
      "['val_loss', '0.8790']\n",
      "['val_accuracy', '0.7928']\n",
      "===== i 57\n",
      "57\n",
      "['loss', '0.6028']\n",
      "['accuracy', '0.8638']\n",
      "['val_loss', '0.8848']\n",
      "['val_accuracy', '0.7962']\n",
      "===== i 58\n",
      "58\n",
      "['loss', '0.6024']\n",
      "['accuracy', '0.8619']\n",
      "['val_loss', '0.7880']\n",
      "['val_accuracy', '0.8196']\n",
      "===== i 59\n",
      "59\n",
      "['loss', '0.5957']\n",
      "['accuracy', '0.8625']\n",
      "['val_loss', '0.8284']\n",
      "['val_accuracy', '0.8092']\n",
      "===== i 60\n",
      "60\n",
      "['loss', '0.5872']\n",
      "['accuracy', '0.8674']\n",
      "['val_loss', '0.7586']\n",
      "['val_accuracy', '0.8216']\n",
      "===== i 61\n",
      "61\n",
      "['loss', '0.5825']\n",
      "['accuracy', '0.8671']\n",
      "['val_loss', '0.7995']\n",
      "['val_accuracy', '0.8161']\n",
      "===== i 62\n",
      "62\n",
      "['loss', '0.5796']\n",
      "['accuracy', '0.8667']\n",
      "['val_loss', '0.8975']\n",
      "['val_accuracy', '0.7895']\n",
      "===== i 63\n",
      "63\n",
      "['loss', '0.5733']\n",
      "['accuracy', '0.8684']\n",
      "['val_loss', '0.8706']\n",
      "['val_accuracy', '0.7936']\n",
      "===== i 64\n",
      "64\n",
      "['loss', '0.5711']\n",
      "['accuracy', '0.8687']\n",
      "['val_loss', '0.8334']\n",
      "['val_accuracy', '0.8098']\n",
      "===== i 65\n",
      "65\n",
      "['loss', '0.5611']\n",
      "['accuracy', '0.8732']\n",
      "['val_loss', '0.7812']\n",
      "['val_accuracy', '0.8222']\n",
      "===== i 66\n",
      "66\n",
      "['loss', '0.5616']\n",
      "['accuracy', '0.8715']\n",
      "['val_loss', '0.7427']\n",
      "['val_accuracy', '0.8254']\n",
      "===== i 67\n",
      "67\n",
      "['loss', '0.5570']\n",
      "['accuracy', '0.8726']\n",
      "['val_loss', '0.7551']\n",
      "['val_accuracy', '0.8251']\n",
      "===== i 68\n",
      "68\n",
      "['loss', '0.5540']\n",
      "['accuracy', '0.8728']\n",
      "['val_loss', '0.7871']\n",
      "['val_accuracy', '0.8099']\n",
      "===== i 69\n",
      "69\n",
      "['loss', '0.5490']\n",
      "['accuracy', '0.8751']\n",
      "['val_loss', '0.7427']\n",
      "['val_accuracy', '0.8269']\n",
      "===== i 70\n",
      "70\n",
      "['loss', '0.5395']\n",
      "['accuracy', '0.8779']\n",
      "['val_loss', '0.8832']\n",
      "['val_accuracy', '0.7881']\n",
      "===== i 71\n",
      "71\n",
      "['loss', '0.5393']\n",
      "['accuracy', '0.8781']\n",
      "['val_loss', '0.7371']\n",
      "['val_accuracy', '0.8270']\n",
      "===== i 72\n",
      "72\n",
      "['loss', '0.5325']\n",
      "['accuracy', '0.8798']\n",
      "['val_loss', '0.7335']\n",
      "['val_accuracy', '0.8280']\n",
      "===== i 73\n",
      "73\n",
      "['loss', '0.5226']\n",
      "['accuracy', '0.8812']\n",
      "['val_loss', '0.7645']\n",
      "['val_accuracy', '0.8163']\n",
      "===== i 74\n",
      "74\n",
      "['loss', '0.5194']\n",
      "['accuracy', '0.8835']\n",
      "['val_loss', '0.7325']\n",
      "['val_accuracy', '0.8299']\n",
      "===== i 75\n",
      "75\n",
      "['loss', '0.5207']\n",
      "['accuracy', '0.8827']\n",
      "['val_loss', '0.8524']\n",
      "['val_accuracy', '0.8052']\n",
      "===== i 76\n",
      "76\n",
      "['loss', '0.5116']\n",
      "['accuracy', '0.8845']\n",
      "['val_loss', '0.7493']\n",
      "['val_accuracy', '0.8271']\n",
      "===== i 77\n",
      "77\n",
      "['loss', '0.5109']\n",
      "['accuracy', '0.8835']\n",
      "['val_loss', '0.7522']\n",
      "['val_accuracy', '0.8217']\n",
      "===== i 78\n",
      "78\n",
      "['loss', '0.5116']\n",
      "['accuracy', '0.8841']\n",
      "['val_loss', '0.8058']\n",
      "['val_accuracy', '0.8078']\n",
      "===== i 79\n",
      "79\n",
      "['loss', '0.5080']\n",
      "['accuracy', '0.8839']\n",
      "['val_loss', '0.7211']\n",
      "['val_accuracy', '0.8263']\n",
      "===== i 80\n",
      "80\n",
      "['loss', '0.5034']\n",
      "['accuracy', '0.8851']\n",
      "['val_loss', '0.7202']\n",
      "['val_accuracy', '0.8322']\n",
      "===== i 81\n",
      "81\n",
      "['loss', '0.5016']\n",
      "['accuracy', '0.8879']\n",
      "['val_loss', '0.7210']\n",
      "['val_accuracy', '0.8264']\n",
      "===== i 82\n",
      "82\n",
      "['loss', '0.4918']\n",
      "['accuracy', '0.8876']\n",
      "['val_loss', '0.7478']\n",
      "['val_accuracy', '0.8233']\n",
      "===== i 83\n",
      "83\n",
      "['loss', '0.4968']\n",
      "['accuracy', '0.8874']\n",
      "['val_loss', '0.7869']\n",
      "['val_accuracy', '0.8167']\n",
      "===== i 84\n",
      "84\n",
      "['loss', '0.4822']\n",
      "['accuracy', '0.8937']\n",
      "['val_loss', '0.7451']\n",
      "['val_accuracy', '0.8288']\n",
      "===== i 85\n",
      "85\n",
      "['loss', '0.4860']\n",
      "['accuracy', '0.8910']\n",
      "['val_loss', '0.7508']\n",
      "['val_accuracy', '0.8233']\n",
      "===== i 86\n",
      "86\n",
      "['loss', '0.4840']\n",
      "['accuracy', '0.8903']\n",
      "['val_loss', '0.7341']\n",
      "['val_accuracy', '0.8239']\n",
      "===== i 87\n",
      "87\n",
      "['loss', '0.4801']\n",
      "['accuracy', '0.8912']\n",
      "['val_loss', '0.6927']\n",
      "['val_accuracy', '0.8367']\n",
      "===== i 88\n",
      "88\n",
      "['loss', '0.4740']\n",
      "['accuracy', '0.8934']\n",
      "['val_loss', '0.8767']\n",
      "['val_accuracy', '0.7975']\n",
      "===== i 89\n",
      "89\n",
      "['loss', '0.4719']\n",
      "['accuracy', '0.8948']\n",
      "['val_loss', '0.7124']\n",
      "['val_accuracy', '0.8346']\n",
      "===== i 90\n",
      "90\n",
      "['loss', '0.4704']\n",
      "['accuracy', '0.8945']\n",
      "['val_loss', '0.7406']\n",
      "['val_accuracy', '0.8249']\n",
      "===== i 91\n",
      "91\n",
      "['loss', '0.4657']\n",
      "['accuracy', '0.8954']\n",
      "['val_loss', '0.7814']\n",
      "['val_accuracy', '0.8118']\n",
      "===== i 92\n",
      "92\n",
      "['loss', '0.4678']\n",
      "['accuracy', '0.8940']\n",
      "['val_loss', '0.6929']\n",
      "['val_accuracy', '0.8324']\n",
      "===== i 93\n",
      "93\n",
      "['loss', '0.4588']\n",
      "['accuracy', '0.8968']\n",
      "['val_loss', '0.7917']\n",
      "['val_accuracy', '0.8235']\n",
      "===== i 94\n",
      "94\n",
      "['loss', '0.4602']\n",
      "['accuracy', '0.8974']\n",
      "['val_loss', '0.8237']\n",
      "['val_accuracy', '0.8075']\n",
      "===== i 95\n",
      "95\n",
      "['loss', '0.4539']\n",
      "['accuracy', '0.8973']\n",
      "['val_loss', '0.8110']\n",
      "['val_accuracy', '0.8133']\n",
      "===== i 96\n",
      "96\n",
      "['loss', '0.4526']\n",
      "['accuracy', '0.8981']\n",
      "['val_loss', '0.7317']\n",
      "['val_accuracy', '0.8185']\n",
      "===== i 97\n",
      "97\n",
      "['loss', '0.4570']\n",
      "['accuracy', '0.8967']\n",
      "['val_loss', '0.6710']\n",
      "['val_accuracy', '0.8415']\n",
      "===== i 98\n",
      "98\n",
      "['loss', '0.4524']\n",
      "['accuracy', '0.8983']\n",
      "['val_loss', '0.6893']\n",
      "['val_accuracy', '0.8344']\n",
      "===== i 99\n",
      "99\n",
      "['loss', '0.4493']\n",
      "['accuracy', '0.8990']\n",
      "['val_loss', '0.6305']\n",
      "['val_accuracy', '0.8499']\n",
      "===== i 100\n",
      "100\n",
      "['loss', '0.4414']\n",
      "['accuracy', '0.9012']\n",
      "['val_loss', '0.7630']\n",
      "['val_accuracy', '0.8216']\n",
      "===== i 101\n",
      "101\n",
      "['loss', '0.4423']\n",
      "['accuracy', '0.9009']\n",
      "['val_loss', '0.7386']\n",
      "['val_accuracy', '0.8312']\n",
      "===== i 102\n",
      "102\n",
      "['loss', '0.4368']\n",
      "['accuracy', '0.9036']\n",
      "['val_loss', '0.7295']\n",
      "['val_accuracy', '0.8280']\n",
      "===== i 103\n",
      "103\n",
      "['loss', '0.4348']\n",
      "['accuracy', '0.9043']\n",
      "['val_loss', '0.6502']\n",
      "['val_accuracy', '0.8453']\n",
      "===== i 104\n",
      "104\n",
      "['loss', '0.4333']\n",
      "['accuracy', '0.9055']\n",
      "['val_loss', '0.6806']\n",
      "['val_accuracy', '0.8392']\n",
      "===== i 105\n",
      "105\n",
      "['loss', '0.4319']\n",
      "['accuracy', '0.9046']\n",
      "['val_loss', '0.7490']\n",
      "['val_accuracy', '0.8239']\n",
      "===== i 106\n",
      "106\n",
      "['loss', '0.4257']\n",
      "['accuracy', '0.9059']\n",
      "['val_loss', '0.9395']\n",
      "['val_accuracy', '0.7869']\n",
      "===== i 107\n",
      "107\n",
      "['loss', '0.4251']\n",
      "['accuracy', '0.9052']\n",
      "['val_loss', '0.7368']\n",
      "['val_accuracy', '0.8312']\n",
      "===== i 108\n",
      "108\n",
      "['loss', '0.4276']\n",
      "['accuracy', '0.9051']\n",
      "['val_loss', '0.6543']\n",
      "['val_accuracy', '0.8467']\n",
      "===== i 109\n",
      "109\n",
      "['loss', '0.4259']\n",
      "['accuracy', '0.9058']\n",
      "['val_loss', '0.7818']\n",
      "['val_accuracy', '0.8148']\n",
      "===== i 110\n",
      "110\n",
      "['loss', '0.4130']\n",
      "['accuracy', '0.9092']\n",
      "['val_loss', '0.7225']\n",
      "['val_accuracy', '0.8326']\n",
      "===== i 111\n",
      "111\n",
      "['loss', '0.4205']\n",
      "['accuracy', '0.9060']\n",
      "['val_loss', '0.7117']\n",
      "['val_accuracy', '0.8322']\n",
      "===== i 112\n",
      "112\n",
      "['loss', '0.4246']\n",
      "['accuracy', '0.9067']\n",
      "['val_loss', '0.6748']\n",
      "['val_accuracy', '0.8395']\n",
      "===== i 113\n",
      "113\n",
      "['loss', '0.4124']\n",
      "['accuracy', '0.9097']\n",
      "['val_loss', '0.6957']\n",
      "['val_accuracy', '0.8390']\n",
      "===== i 114\n",
      "114\n",
      "['loss', '0.4117']\n",
      "['accuracy', '0.9093']\n",
      "['val_loss', '0.7909']\n",
      "['val_accuracy', '0.8077']\n",
      "===== i 115\n",
      "115\n",
      "['loss', '0.4105']\n",
      "['accuracy', '0.9108']\n",
      "['val_loss', '0.6461']\n",
      "['val_accuracy', '0.8505']\n",
      "===== i 116\n",
      "116\n",
      "['loss', '0.4098']\n",
      "['accuracy', '0.9098']\n",
      "['val_loss', '0.6621']\n",
      "['val_accuracy', '0.8461']\n",
      "===== i 117\n",
      "117\n",
      "['loss', '0.4041']\n",
      "['accuracy', '0.9119']\n",
      "['val_loss', '0.6754']\n",
      "['val_accuracy', '0.8404']\n",
      "===== i 118\n",
      "118\n",
      "['loss', '0.4013']\n",
      "['accuracy', '0.9117']\n",
      "['val_loss', '0.6281']\n",
      "['val_accuracy', '0.8512']\n",
      "===== i 119\n",
      "119\n",
      "['loss', '0.4081']\n",
      "['accuracy', '0.9091']\n",
      "['val_loss', '0.7457']\n",
      "['val_accuracy', '0.8332']\n",
      "===== i 120\n",
      "120\n",
      "['loss', '0.4034']\n",
      "['accuracy', '0.9101']\n",
      "['val_loss', '0.6785']\n",
      "['val_accuracy', '0.8379']\n",
      "===== i 121\n",
      "121\n",
      "['loss', '0.4027']\n",
      "['accuracy', '0.9112']\n",
      "['val_loss', '0.6523']\n",
      "['val_accuracy', '0.8470']\n",
      "===== i 122\n",
      "122\n",
      "['loss', '0.3946']\n",
      "['accuracy', '0.9141']\n",
      "['val_loss', '0.7062']\n",
      "['val_accuracy', '0.8365']\n",
      "===== i 123\n",
      "123\n",
      "['loss', '0.3935']\n",
      "['accuracy', '0.9137']\n",
      "['val_loss', '0.6977']\n",
      "['val_accuracy', '0.8402']\n",
      "===== i 124\n",
      "124\n",
      "['loss', '0.3941']\n",
      "['accuracy', '0.9137']\n",
      "['val_loss', '0.7185']\n",
      "['val_accuracy', '0.8353']\n",
      "===== i 125\n",
      "125\n",
      "['loss', '0.3899']\n",
      "['accuracy', '0.9143']\n",
      "['val_loss', '0.6906']\n",
      "['val_accuracy', '0.8425']\n",
      "===== i 126\n",
      "126\n",
      "['loss', '0.3896']\n",
      "['accuracy', '0.9152']\n",
      "['val_loss', '0.6042']\n",
      "['val_accuracy', '0.8622']\n",
      "===== i 127\n",
      "127\n",
      "['loss', '0.3888']\n",
      "['accuracy', '0.9163']\n",
      "['val_loss', '0.7511']\n",
      "['val_accuracy', '0.8306']\n",
      "===== i 128\n",
      "128\n",
      "['loss', '0.3904']\n",
      "['accuracy', '0.9142']\n",
      "['val_loss', '0.7261']\n",
      "['val_accuracy', '0.8339']\n",
      "===== i 129\n",
      "129\n",
      "['loss', '0.3933']\n",
      "['accuracy', '0.9150']\n",
      "['val_loss', '0.6887']\n",
      "['val_accuracy', '0.8487']\n",
      "===== i 130\n",
      "130\n",
      "['loss', '0.3860']\n",
      "['accuracy', '0.9166']\n",
      "['val_loss', '0.7198']\n",
      "['val_accuracy', '0.8274']\n",
      "===== i 131\n",
      "131\n",
      "['loss', '0.3850']\n",
      "['accuracy', '0.9156']\n",
      "['val_loss', '0.7012']\n",
      "['val_accuracy', '0.8405']\n",
      "===== i 132\n",
      "132\n",
      "['loss', '0.3825']\n",
      "['accuracy', '0.9178']\n",
      "['val_loss', '0.7076']\n",
      "['val_accuracy', '0.8367']\n",
      "===== i 133\n",
      "133\n",
      "['loss', '0.3788']\n",
      "['accuracy', '0.9196']\n",
      "['val_loss', '0.7418']\n",
      "['val_accuracy', '0.8290']\n",
      "===== i 134\n",
      "134\n",
      "['loss', '0.3798']\n",
      "['accuracy', '0.9185']\n",
      "['val_loss', '0.7080']\n",
      "['val_accuracy', '0.8364']\n",
      "===== i 135\n",
      "135\n",
      "['loss', '0.3791']\n",
      "['accuracy', '0.9178']\n",
      "['val_loss', '0.7835']\n",
      "['val_accuracy', '0.8224']\n",
      "===== i 136\n",
      "136\n",
      "['loss', '0.3745']\n",
      "['accuracy', '0.9192']\n",
      "['val_loss', '0.7252']\n",
      "['val_accuracy', '0.8296']\n",
      "===== i 137\n",
      "137\n",
      "['loss', '0.3781']\n",
      "['accuracy', '0.9176']\n",
      "['val_loss', '0.6736']\n",
      "['val_accuracy', '0.8435']\n",
      "===== i 138\n",
      "138\n",
      "['loss', '0.3738']\n",
      "['accuracy', '0.9198']\n",
      "['val_loss', '0.6460']\n",
      "['val_accuracy', '0.8524']\n",
      "===== i 139\n",
      "139\n",
      "['loss', '0.3719']\n",
      "['accuracy', '0.9196']\n",
      "['val_loss', '0.6453']\n",
      "['val_accuracy', '0.8457']\n",
      "===== i 140\n",
      "140\n",
      "['loss', '0.3690']\n",
      "['accuracy', '0.9213']\n",
      "['val_loss', '0.7210']\n",
      "['val_accuracy', '0.8305']\n",
      "===== i 141\n",
      "141\n",
      "['loss', '0.3767']\n",
      "['accuracy', '0.9187']\n",
      "['val_loss', '0.7102']\n",
      "['val_accuracy', '0.8349']\n",
      "===== i 142\n",
      "142\n",
      "['loss', '0.3657']\n",
      "['accuracy', '0.9209']\n",
      "['val_loss', '0.7309']\n",
      "['val_accuracy', '0.8375']\n",
      "===== i 143\n",
      "143\n",
      "['loss', '0.3657']\n",
      "['accuracy', '0.9228']\n",
      "['val_loss', '0.6755']\n",
      "['val_accuracy', '0.8485']\n",
      "===== i 144\n",
      "144\n",
      "['loss', '0.3686']\n",
      "['accuracy', '0.9208']\n",
      "['val_loss', '0.7396']\n",
      "['val_accuracy', '0.8297']\n",
      "===== i 145\n",
      "145\n",
      "['loss', '0.3676']\n",
      "['accuracy', '0.9205']\n",
      "['val_loss', '0.6342']\n",
      "['val_accuracy', '0.8523']\n",
      "===== i 146\n",
      "146\n",
      "['loss', '0.3641']\n",
      "['accuracy', '0.9215']\n",
      "['val_loss', '0.6575']\n",
      "['val_accuracy', '0.8448']\n",
      "===== i 147\n",
      "147\n",
      "['loss', '0.3655']\n",
      "['accuracy', '0.9216']\n",
      "['val_loss', '0.7022']\n",
      "['val_accuracy', '0.8398']\n",
      "===== i 148\n",
      "148\n",
      "['loss', '0.3623']\n",
      "['accuracy', '0.9226']\n",
      "['val_loss', '0.6499']\n",
      "['val_accuracy', '0.8494']\n",
      "===== i 149\n",
      "149\n",
      "['loss', '0.3616']\n",
      "['accuracy', '0.9224']\n",
      "['val_loss', '0.6991']\n",
      "['val_accuracy', '0.8424']\n",
      "===== i 150\n",
      "150\n",
      "['loss', '0.3611']\n",
      "['accuracy', '0.9227']\n",
      "['val_loss', '0.6561']\n",
      "['val_accuracy', '0.8502']\n",
      "===== i 151\n",
      "151\n",
      "['loss', '0.3562']\n",
      "['accuracy', '0.9257']\n",
      "['val_loss', '0.6600']\n",
      "['val_accuracy', '0.8482']\n",
      "===== i 152\n",
      "152\n",
      "['loss', '0.3582']\n",
      "['accuracy', '0.9235']\n",
      "['val_loss', '0.7339']\n",
      "['val_accuracy', '0.8293']\n",
      "===== i 153\n",
      "153\n",
      "['loss', '0.3555']\n",
      "['accuracy', '0.9254']\n",
      "['val_loss', '0.7092']\n",
      "['val_accuracy', '0.8417']\n",
      "===== i 154\n",
      "154\n",
      "['loss', '0.3557']\n",
      "['accuracy', '0.9238']\n",
      "['val_loss', '0.6888']\n",
      "['val_accuracy', '0.8460']\n",
      "===== i 155\n",
      "155\n",
      "['loss', '0.3568']\n",
      "['accuracy', '0.9242']\n",
      "['val_loss', '0.6725']\n",
      "['val_accuracy', '0.8451']\n",
      "===== i 156\n",
      "156\n",
      "['loss', '0.3535']\n",
      "['accuracy', '0.9251']\n",
      "['val_loss', '0.7240']\n",
      "['val_accuracy', '0.8294']\n",
      "===== i 157\n",
      "157\n",
      "['loss', '0.3492']\n",
      "['accuracy', '0.9276']\n",
      "['val_loss', '0.6655']\n",
      "['val_accuracy', '0.8537']\n",
      "===== i 158\n",
      "158\n",
      "['loss', '0.3497']\n",
      "['accuracy', '0.9259']\n",
      "['val_loss', '0.6961']\n",
      "['val_accuracy', '0.8421']\n",
      "===== i 159\n",
      "159\n",
      "['loss', '0.3507']\n",
      "['accuracy', '0.9258']\n",
      "['val_loss', '0.7412']\n",
      "['val_accuracy', '0.8317']\n",
      "===== i 160\n",
      "160\n",
      "['loss', '0.3456']\n",
      "['accuracy', '0.9278']\n",
      "['val_loss', '0.7584']\n",
      "['val_accuracy', '0.8320']\n",
      "===== i 161\n",
      "161\n",
      "['loss', '0.3515']\n",
      "['accuracy', '0.9255']\n",
      "['val_loss', '0.7653']\n",
      "['val_accuracy', '0.8323']\n",
      "===== i 162\n",
      "162\n",
      "['loss', '0.3485']\n",
      "['accuracy', '0.9273']\n",
      "['val_loss', '0.8621']\n",
      "['val_accuracy', '0.8102']\n",
      "===== i 163\n",
      "163\n",
      "['loss', '0.3431']\n",
      "['accuracy', '0.9284']\n",
      "['val_loss', '0.6966']\n",
      "['val_accuracy', '0.8400']\n",
      "===== i 164\n",
      "164\n",
      "['loss', '0.3473']\n",
      "['accuracy', '0.9263']\n",
      "['val_loss', '0.6647']\n",
      "['val_accuracy', '0.8458']\n",
      "===== i 165\n",
      "165\n",
      "['loss', '0.3493']\n",
      "['accuracy', '0.9256']\n",
      "['val_loss', '0.7269']\n",
      "['val_accuracy', '0.8378']\n",
      "===== i 166\n",
      "166\n",
      "['loss', '0.3417']\n",
      "['accuracy', '0.9282']\n",
      "['val_loss', '0.6705']\n",
      "['val_accuracy', '0.8467']\n",
      "===== i 167\n",
      "167\n",
      "['loss', '0.3437']\n",
      "['accuracy', '0.9283']\n",
      "['val_loss', '0.6731']\n",
      "['val_accuracy', '0.8454']\n",
      "===== i 168\n",
      "168\n",
      "['loss', '0.3427']\n",
      "['accuracy', '0.9290']\n",
      "['val_loss', '0.6205']\n",
      "['val_accuracy', '0.8632']\n",
      "===== i 169\n",
      "169\n",
      "['loss', '0.3345']\n",
      "['accuracy', '0.9321']\n",
      "['val_loss', '0.6706']\n",
      "['val_accuracy', '0.8445']\n",
      "===== i 170\n",
      "170\n",
      "['loss', '0.3428']\n",
      "['accuracy', '0.9280']\n",
      "['val_loss', '0.6996']\n",
      "['val_accuracy', '0.8395']\n",
      "===== i 171\n",
      "171\n",
      "['loss', '0.3418']\n",
      "['accuracy', '0.9286']\n",
      "['val_loss', '0.7535']\n",
      "['val_accuracy', '0.8222']\n",
      "===== i 172\n",
      "172\n",
      "['loss', '0.3368']\n",
      "['accuracy', '0.9298']\n",
      "['val_loss', '0.6665']\n",
      "['val_accuracy', '0.8473']\n",
      "===== i 173\n",
      "173\n",
      "['loss', '0.3376']\n",
      "['accuracy', '0.9288']\n",
      "['val_loss', '0.7368']\n",
      "['val_accuracy', '0.8275']\n",
      "===== i 174\n",
      "174\n",
      "['loss', '0.3312']\n",
      "['accuracy', '0.9310']\n",
      "['val_loss', '0.6454']\n",
      "['val_accuracy', '0.8510']\n",
      "===== i 175\n",
      "175\n",
      "['loss', '0.3346']\n",
      "['accuracy', '0.9298']\n",
      "['val_loss', '0.7085']\n",
      "['val_accuracy', '0.8391']\n",
      "===== i 176\n",
      "176\n",
      "['loss', '0.3343']\n",
      "['accuracy', '0.9304']\n",
      "['val_loss', '0.7461']\n",
      "['val_accuracy', '0.8379']\n",
      "===== i 177\n",
      "177\n",
      "['loss', '0.3363']\n",
      "['accuracy', '0.9302']\n",
      "['val_loss', '0.8247']\n",
      "['val_accuracy', '0.8162']\n",
      "===== i 178\n",
      "178\n",
      "['loss', '0.3359']\n",
      "['accuracy', '0.9303']\n",
      "['val_loss', '0.6700']\n",
      "['val_accuracy', '0.8463']\n",
      "===== i 179\n",
      "179\n",
      "['loss', '0.3332']\n",
      "['accuracy', '0.9315']\n",
      "['val_loss', '0.7507']\n",
      "['val_accuracy', '0.8346']\n",
      "===== i 180\n",
      "180\n",
      "['loss', '0.3345']\n",
      "['accuracy', '0.9317']\n",
      "['val_loss', '0.6369']\n",
      "['val_accuracy', '0.8548']\n",
      "===== i 181\n",
      "181\n",
      "['loss', '0.3288']\n",
      "['accuracy', '0.9323']\n",
      "['val_loss', '0.6668']\n",
      "['val_accuracy', '0.8444']\n",
      "===== i 182\n",
      "182\n",
      "['loss', '0.3256']\n",
      "['accuracy', '0.9342']\n",
      "['val_loss', '0.7236']\n",
      "['val_accuracy', '0.8449']\n",
      "===== i 183\n",
      "183\n",
      "['loss', '0.3316']\n",
      "['accuracy', '0.9312']\n",
      "['val_loss', '0.7541']\n",
      "['val_accuracy', '0.8382']\n",
      "===== i 184\n",
      "184\n",
      "['loss', '0.3286']\n",
      "['accuracy', '0.9326']\n",
      "['val_loss', '0.6289']\n",
      "['val_accuracy', '0.8535']\n",
      "===== i 185\n",
      "185\n",
      "['loss', '0.3266']\n",
      "['accuracy', '0.9327']\n",
      "['val_loss', '0.6611']\n",
      "['val_accuracy', '0.8476']\n",
      "===== i 186\n",
      "186\n",
      "['loss', '0.3289']\n",
      "['accuracy', '0.9318']\n",
      "['val_loss', '0.7026']\n",
      "['val_accuracy', '0.8415']\n",
      "===== i 187\n",
      "187\n",
      "['loss', '0.3318']\n",
      "['accuracy', '0.9321']\n",
      "['val_loss', '0.7372']\n",
      "['val_accuracy', '0.8318']\n",
      "===== i 188\n",
      "188\n",
      "['loss', '0.3292']\n",
      "['accuracy', '0.9323']\n",
      "['val_loss', '0.6257']\n",
      "['val_accuracy', '0.8538']\n",
      "===== i 189\n",
      "189\n",
      "['loss', '0.3286']\n",
      "['accuracy', '0.9333']\n",
      "['val_loss', '0.6941']\n",
      "['val_accuracy', '0.8452']\n",
      "===== i 190\n",
      "190\n",
      "['loss', '0.3272']\n",
      "['accuracy', '0.9327']\n",
      "['val_loss', '0.7283']\n",
      "['val_accuracy', '0.8353']\n",
      "===== i 191\n",
      "191\n",
      "['loss', '0.3183']\n",
      "['accuracy', '0.9364']\n",
      "['val_loss', '0.7015']\n",
      "['val_accuracy', '0.8436']\n",
      "===== i 192\n",
      "192\n",
      "['loss', '0.3251']\n",
      "['accuracy', '0.9340']\n",
      "['val_loss', '0.7640']\n",
      "['val_accuracy', '0.8329']\n",
      "===== i 193\n",
      "193\n",
      "['loss', '0.3232']\n",
      "['accuracy', '0.9339']\n",
      "['val_loss', '0.6122']\n",
      "['val_accuracy', '0.8564']\n",
      "===== i 194\n",
      "194\n",
      "['loss', '0.3223']\n",
      "['accuracy', '0.9345']\n",
      "['val_loss', '0.6764']\n",
      "['val_accuracy', '0.8485']\n",
      "===== i 195\n",
      "195\n",
      "['loss', '0.3215']\n",
      "['accuracy', '0.9354']\n",
      "['val_loss', '0.6869']\n",
      "['val_accuracy', '0.8418']\n",
      "===== i 196\n",
      "196\n",
      "['loss', '0.3213']\n",
      "['accuracy', '0.9353']\n",
      "['val_loss', '0.6983']\n",
      "['val_accuracy', '0.8443']\n",
      "===== i 197\n",
      "197\n",
      "['loss', '0.3198']\n",
      "['accuracy', '0.9345']\n",
      "['val_loss', '0.7679']\n",
      "['val_accuracy', '0.8276']\n",
      "===== i 198\n",
      "198\n",
      "['loss', '0.3177']\n",
      "['accuracy', '0.9353']\n",
      "['val_loss', '0.6658']\n",
      "['val_accuracy', '0.8462']\n",
      "===== i 199\n",
      "199\n",
      "['loss', '0.3215']\n",
      "['accuracy', '0.9344']\n",
      "['val_loss', '0.8749']\n",
      "['val_accuracy', '0.8120']\n",
      "===== i 200\n",
      "200\n",
      "['loss', '0.3194']\n",
      "['accuracy', '0.9358']\n",
      "['val_loss', '0.7133']\n",
      "['val_accuracy', '0.8388']\n",
      "===== i 201\n",
      "201\n",
      "['loss', '0.3197']\n",
      "['accuracy', '0.9349']\n",
      "['val_loss', '0.7902']\n",
      "['val_accuracy', '0.8310']\n",
      "===== i 202\n",
      "202\n",
      "['loss', '0.3195']\n",
      "['accuracy', '0.9365']\n",
      "['val_loss', '0.7068']\n",
      "['val_accuracy', '0.8398']\n",
      "===== i 203\n",
      "203\n",
      "['loss', '0.3141']\n",
      "['accuracy', '0.9374']\n",
      "['val_loss', '0.7026']\n",
      "['val_accuracy', '0.8394']\n",
      "===== i 204\n",
      "204\n",
      "['loss', '0.3202']\n",
      "['accuracy', '0.9355']\n",
      "['val_loss', '0.6624']\n",
      "['val_accuracy', '0.8476']\n",
      "===== i 205\n",
      "205\n",
      "['loss', '0.3191']\n",
      "['accuracy', '0.9349']\n",
      "['val_loss', '0.7917']\n",
      "['val_accuracy', '0.8253']\n",
      "===== i 206\n",
      "206\n",
      "['loss', '0.3161']\n",
      "['accuracy', '0.9364']\n",
      "['val_loss', '0.8080']\n",
      "['val_accuracy', '0.8276']\n",
      "===== i 207\n",
      "207\n",
      "['loss', '0.3089']\n",
      "['accuracy', '0.9391']\n",
      "['val_loss', '0.6986']\n",
      "['val_accuracy', '0.8434']\n",
      "===== i 208\n",
      "208\n",
      "['loss', '0.3109']\n",
      "['accuracy', '0.9383']\n",
      "['val_loss', '0.6794']\n",
      "['val_accuracy', '0.8427']\n",
      "===== i 209\n",
      "209\n",
      "['loss', '0.3116']\n",
      "['accuracy', '0.9369']\n",
      "['val_loss', '0.6797']\n",
      "['val_accuracy', '0.8463']\n",
      "===== i 210\n",
      "210\n",
      "['loss', '0.3161']\n",
      "['accuracy', '0.9360']\n",
      "['val_loss', '0.7264']\n",
      "['val_accuracy', '0.8365']\n",
      "===== i 211\n",
      "211\n",
      "['loss', '0.3099']\n",
      "['accuracy', '0.9386']\n",
      "['val_loss', '0.6726']\n",
      "['val_accuracy', '0.8505']\n",
      "===== i 212\n",
      "212\n",
      "['loss', '0.3094']\n",
      "['accuracy', '0.9391']\n",
      "['val_loss', '0.7146']\n",
      "['val_accuracy', '0.8398']\n",
      "===== i 213\n",
      "213\n",
      "['loss', '0.3088']\n",
      "['accuracy', '0.9388']\n",
      "['val_loss', '0.7955']\n",
      "['val_accuracy', '0.8320']\n",
      "===== i 214\n",
      "214\n",
      "['loss', '0.3119']\n",
      "['accuracy', '0.9386']\n",
      "['val_loss', '0.7168']\n",
      "['val_accuracy', '0.8363']\n",
      "===== i 215\n",
      "215\n",
      "['loss', '0.3089']\n",
      "['accuracy', '0.9389']\n",
      "['val_loss', '0.6878']\n",
      "['val_accuracy', '0.8492']\n",
      "===== i 216\n",
      "216\n",
      "['loss', '0.3151']\n",
      "['accuracy', '0.9362']\n",
      "['val_loss', '0.7203']\n",
      "['val_accuracy', '0.8379']\n",
      "===== i 217\n",
      "217\n",
      "['loss', '0.3067']\n",
      "['accuracy', '0.9397']\n",
      "['val_loss', '0.7213']\n",
      "['val_accuracy', '0.8420']\n",
      "===== i 218\n",
      "218\n",
      "['loss', '0.3131']\n",
      "['accuracy', '0.9376']\n",
      "['val_loss', '0.6650']\n",
      "['val_accuracy', '0.8522']\n",
      "===== i 219\n",
      "219\n",
      "['loss', '0.3060']\n",
      "['accuracy', '0.9396']\n",
      "['val_loss', '0.7011']\n",
      "['val_accuracy', '0.8440']\n",
      "===== i 220\n",
      "220\n",
      "['loss', '0.3075']\n",
      "['accuracy', '0.9400']\n",
      "['val_loss', '0.6790']\n",
      "['val_accuracy', '0.8543']\n",
      "===== i 221\n",
      "221\n",
      "['loss', '0.3046']\n",
      "['accuracy', '0.9413']\n",
      "['val_loss', '0.6216']\n",
      "['val_accuracy', '0.8585']\n",
      "===== i 222\n",
      "222\n",
      "['loss', '0.3099']\n",
      "['accuracy', '0.9373']\n",
      "['val_loss', '0.6922']\n",
      "['val_accuracy', '0.8502']\n",
      "===== i 223\n",
      "223\n",
      "['loss', '0.3038']\n",
      "['accuracy', '0.9404']\n",
      "['val_loss', '0.6552']\n",
      "['val_accuracy', '0.8478']\n",
      "===== i 224\n",
      "224\n",
      "['loss', '0.3005']\n",
      "['accuracy', '0.9418']\n",
      "['val_loss', '0.6608']\n",
      "['val_accuracy', '0.8510']\n",
      "===== i 225\n",
      "225\n",
      "['loss', '0.3073']\n",
      "['accuracy', '0.9390']\n",
      "['val_loss', '0.6958']\n",
      "['val_accuracy', '0.8508']\n",
      "===== i 226\n",
      "226\n",
      "['loss', '0.3046']\n",
      "['accuracy', '0.9410']\n",
      "['val_loss', '0.6881']\n",
      "['val_accuracy', '0.8473']\n",
      "===== i 227\n",
      "227\n",
      "['loss', '0.3084']\n",
      "['accuracy', '0.9383']\n",
      "['val_loss', '0.8249']\n",
      "['val_accuracy', '0.8274']\n",
      "===== i 228\n",
      "228\n",
      "['loss', '0.3040']\n",
      "['accuracy', '0.9410']\n",
      "['val_loss', '0.6705']\n",
      "['val_accuracy', '0.8480']\n",
      "===== i 229\n",
      "229\n",
      "['loss', '0.3043']\n",
      "['accuracy', '0.9394']\n",
      "['val_loss', '0.6781']\n",
      "['val_accuracy', '0.8474']\n",
      "===== i 230\n",
      "230\n",
      "['loss', '0.3042']\n",
      "['accuracy', '0.9412']\n",
      "['val_loss', '0.7273']\n",
      "['val_accuracy', '0.8329']\n",
      "===== i 231\n",
      "231\n",
      "['loss', '0.3017']\n",
      "['accuracy', '0.9417']\n",
      "['val_loss', '0.6684']\n",
      "['val_accuracy', '0.8465']\n",
      "===== i 232\n",
      "232\n",
      "['loss', '0.3011']\n",
      "['accuracy', '0.9410']\n",
      "['val_loss', '0.6391']\n",
      "['val_accuracy', '0.8602']\n",
      "===== i 233\n",
      "233\n",
      "['loss', '0.2978']\n",
      "['accuracy', '0.9421']\n",
      "['val_loss', '0.6991']\n",
      "['val_accuracy', '0.8495']\n",
      "===== i 234\n",
      "234\n",
      "['loss', '0.3034']\n",
      "['accuracy', '0.9408']\n",
      "['val_loss', '0.6925']\n",
      "['val_accuracy', '0.8489']\n",
      "===== i 235\n",
      "235\n",
      "['loss', '0.2976']\n",
      "['accuracy', '0.9433']\n",
      "['val_loss', '0.6635']\n",
      "['val_accuracy', '0.8527']\n",
      "===== i 236\n",
      "236\n",
      "['loss', '0.3014']\n",
      "['accuracy', '0.9418']\n",
      "['val_loss', '0.7973']\n",
      "['val_accuracy', '0.8294']\n",
      "===== i 237\n",
      "237\n",
      "['loss', '0.2985']\n",
      "['accuracy', '0.9419']\n",
      "['val_loss', '0.6742']\n",
      "['val_accuracy', '0.8506']\n",
      "===== i 238\n",
      "238\n",
      "['loss', '0.3011']\n",
      "['accuracy', '0.9413']\n",
      "['val_loss', '0.7191']\n",
      "['val_accuracy', '0.8471']\n",
      "===== i 239\n",
      "239\n",
      "['loss', '0.3012']\n",
      "['accuracy', '0.9401']\n",
      "['val_loss', '0.6431']\n",
      "['val_accuracy', '0.8521']\n",
      "===== i 240\n",
      "240\n",
      "['loss', '0.2997']\n",
      "['accuracy', '0.9419']\n",
      "['val_loss', '0.7556']\n",
      "['val_accuracy', '0.8458']\n",
      "===== i 241\n",
      "241\n",
      "['loss', '0.3001']\n",
      "['accuracy', '0.9402']\n",
      "['val_loss', '0.6356']\n",
      "['val_accuracy', '0.8536']\n",
      "===== i 242\n",
      "242\n",
      "['loss', '0.2992']\n",
      "['accuracy', '0.9418']\n",
      "['val_loss', '0.6312']\n",
      "['val_accuracy', '0.8588']\n",
      "===== i 243\n",
      "243\n",
      "['loss', '0.3016']\n",
      "['accuracy', '0.9401']\n",
      "['val_loss', '0.7272']\n",
      "['val_accuracy', '0.8391']\n",
      "===== i 244\n",
      "244\n",
      "['loss', '0.2998']\n",
      "['accuracy', '0.9414']\n",
      "['val_loss', '0.7180']\n",
      "['val_accuracy', '0.8344']\n",
      "===== i 245\n",
      "245\n",
      "['loss', '0.2952']\n",
      "['accuracy', '0.9445']\n",
      "['val_loss', '0.7679']\n",
      "['val_accuracy', '0.8362']\n",
      "===== i 246\n",
      "246\n",
      "['loss', '0.3008']\n",
      "['accuracy', '0.9416']\n",
      "['val_loss', '0.6788']\n",
      "['val_accuracy', '0.8516']\n",
      "===== i 247\n",
      "247\n",
      "['loss', '0.2944']\n",
      "['accuracy', '0.9441']\n",
      "['val_loss', '0.6949']\n",
      "['val_accuracy', '0.8504']\n",
      "===== i 248\n",
      "248\n",
      "['loss', '0.2988']\n",
      "['accuracy', '0.9417']\n",
      "['val_loss', '0.6695']\n",
      "['val_accuracy', '0.8514']\n",
      "===== i 249\n",
      "249\n",
      "['loss', '0.2939']\n",
      "['accuracy', '0.9447']\n",
      "['val_loss', '0.8013']\n",
      "['val_accuracy', '0.8193']\n",
      "===== i 250\n",
      "250\n",
      "['loss', '0.2916']\n",
      "['accuracy', '0.9452']\n",
      "['val_loss', '0.6845']\n",
      "['val_accuracy', '0.8430']\n",
      "===== i 251\n",
      "251\n",
      "['loss', '0.2937']\n",
      "['accuracy', '0.9430']\n",
      "['val_loss', '0.7472']\n",
      "['val_accuracy', '0.8389']\n",
      "===== i 252\n",
      "252\n",
      "['loss', '0.2934']\n",
      "['accuracy', '0.9437']\n",
      "['val_loss', '0.6337']\n",
      "['val_accuracy', '0.8567']\n",
      "===== i 253\n",
      "253\n",
      "['loss', '0.2920']\n",
      "['accuracy', '0.9455']\n",
      "['val_loss', '0.6658']\n",
      "['val_accuracy', '0.8507']\n",
      "===== i 254\n",
      "254\n",
      "['loss', '0.2876']\n",
      "['accuracy', '0.9450']\n",
      "['val_loss', '0.6713']\n",
      "['val_accuracy', '0.8532']\n",
      "===== i 255\n",
      "255\n",
      "['loss', '0.2917']\n",
      "['accuracy', '0.9438']\n",
      "['val_loss', '0.7080']\n",
      "['val_accuracy', '0.8413']\n",
      "===== i 256\n",
      "256\n",
      "['loss', '0.2980']\n",
      "['accuracy', '0.9416']\n",
      "['val_loss', '0.7020']\n",
      "['val_accuracy', '0.8435']\n",
      "===== i 257\n",
      "257\n",
      "['loss', '0.2899']\n",
      "['accuracy', '0.9449']\n",
      "['val_loss', '0.6924']\n",
      "['val_accuracy', '0.8512']\n",
      "===== i 258\n",
      "258\n",
      "['loss', '0.2943']\n",
      "['accuracy', '0.9447']\n",
      "['val_loss', '0.6810']\n",
      "['val_accuracy', '0.8489']\n",
      "===== i 259\n",
      "259\n",
      "['loss', '0.2940']\n",
      "['accuracy', '0.9434']\n",
      "['val_loss', '0.8251']\n",
      "['val_accuracy', '0.8239']\n",
      "===== i 260\n",
      "260\n",
      "['loss', '0.2934']\n",
      "['accuracy', '0.9432']\n",
      "['val_loss', '0.7448']\n",
      "['val_accuracy', '0.8392']\n",
      "===== i 261\n",
      "261\n",
      "['loss', '0.2884']\n",
      "['accuracy', '0.9458']\n",
      "['val_loss', '0.6474']\n",
      "['val_accuracy', '0.8575']\n",
      "===== i 262\n",
      "262\n",
      "['loss', '0.2962']\n",
      "['accuracy', '0.9420']\n",
      "['val_loss', '0.7087']\n",
      "['val_accuracy', '0.8501']\n",
      "===== i 263\n",
      "263\n",
      "['loss', '0.2887']\n",
      "['accuracy', '0.9453']\n",
      "['val_loss', '0.6648']\n",
      "['val_accuracy', '0.8578']\n",
      "===== i 264\n",
      "264\n",
      "['loss', '0.2879']\n",
      "['accuracy', '0.9457']\n",
      "['val_loss', '0.8294']\n",
      "['val_accuracy', '0.8290']\n",
      "===== i 265\n",
      "265\n",
      "['loss', '0.2920']\n",
      "['accuracy', '0.9450']\n",
      "['val_loss', '0.6918']\n",
      "['val_accuracy', '0.8468']\n",
      "===== i 266\n",
      "266\n",
      "['loss', '0.2938']\n",
      "['accuracy', '0.9432']\n",
      "['val_loss', '0.6478']\n",
      "['val_accuracy', '0.8582']\n",
      "===== i 267\n",
      "267\n",
      "['loss', '0.2898']\n",
      "['accuracy', '0.9453']\n",
      "['val_loss', '0.6158']\n",
      "['val_accuracy', '0.8626']\n",
      "===== i 268\n",
      "268\n",
      "['loss', '0.2877']\n",
      "['accuracy', '0.9446']\n",
      "['val_loss', '0.8230']\n",
      "['val_accuracy', '0.8223']\n",
      "===== i 269\n",
      "269\n",
      "['loss', '0.2908']\n",
      "['accuracy', '0.9447']\n",
      "['val_loss', '0.6714']\n",
      "['val_accuracy', '0.8470']\n",
      "===== i 270\n",
      "270\n",
      "['loss', '0.2868']\n",
      "['accuracy', '0.9467']\n",
      "['val_loss', '0.6512']\n",
      "['val_accuracy', '0.8538']\n",
      "===== i 271\n",
      "271\n",
      "['loss', '0.2885']\n",
      "['accuracy', '0.9455']\n",
      "['val_loss', '0.6484']\n",
      "['val_accuracy', '0.8568']\n",
      "===== i 272\n",
      "272\n",
      "['loss', '0.2928']\n",
      "['accuracy', '0.9437']\n",
      "['val_loss', '0.6663']\n",
      "['val_accuracy', '0.8477']\n",
      "===== i 273\n",
      "273\n",
      "['loss', '0.2873']\n",
      "['accuracy', '0.9464']\n",
      "['val_loss', '0.7923']\n",
      "['val_accuracy', '0.8270']\n",
      "===== i 274\n",
      "274\n",
      "['loss', '0.2907']\n",
      "['accuracy', '0.9440']\n",
      "['val_loss', '0.7000']\n",
      "['val_accuracy', '0.8391']\n",
      "===== i 275\n",
      "275\n",
      "['loss', '0.2882']\n",
      "['accuracy', '0.9450']\n",
      "['val_loss', '0.6631']\n",
      "['val_accuracy', '0.8568']\n",
      "===== i 276\n",
      "276\n",
      "['loss', '0.2861']\n",
      "['accuracy', '0.9453']\n",
      "['val_loss', '0.5883']\n",
      "['val_accuracy', '0.8659']\n",
      "===== i 277\n",
      "277\n",
      "['loss', '0.2842']\n",
      "['accuracy', '0.9467']\n",
      "['val_loss', '0.7048']\n",
      "['val_accuracy', '0.8468']\n",
      "===== i 278\n",
      "278\n",
      "['loss', '0.2877']\n",
      "['accuracy', '0.9462']\n",
      "['val_loss', '0.6291']\n",
      "['val_accuracy', '0.8538']\n",
      "===== i 279\n",
      "279\n",
      "['loss', '0.2888']\n",
      "['accuracy', '0.9445']\n",
      "['val_loss', '0.7404']\n",
      "['val_accuracy', '0.8354']\n",
      "===== i 280\n",
      "280\n",
      "['loss', '0.2836']\n",
      "['accuracy', '0.9466']\n",
      "['val_loss', '0.7674']\n",
      "['val_accuracy', '0.8370']\n",
      "===== i 281\n",
      "281\n",
      "['loss', '0.2892']\n",
      "['accuracy', '0.9446']\n",
      "['val_loss', '0.7080']\n",
      "['val_accuracy', '0.8475']\n",
      "===== i 282\n",
      "282\n",
      "['loss', '0.2880']\n",
      "['accuracy', '0.9452']\n",
      "['val_loss', '0.7282']\n",
      "['val_accuracy', '0.8448']\n",
      "===== i 283\n",
      "283\n",
      "['loss', '0.2869']\n",
      "['accuracy', '0.9450']\n",
      "['val_loss', '0.6440']\n",
      "['val_accuracy', '0.8607']\n",
      "===== i 284\n",
      "284\n",
      "['loss', '0.2859']\n",
      "['accuracy', '0.9458']\n",
      "['val_loss', '0.6764']\n",
      "['val_accuracy', '0.8526']\n",
      "===== i 285\n",
      "285\n",
      "['loss', '0.2879']\n",
      "['accuracy', '0.9450']\n",
      "['val_loss', '0.7023']\n",
      "['val_accuracy', '0.8520']\n",
      "===== i 286\n",
      "286\n",
      "['loss', '0.2799']\n",
      "['accuracy', '0.9495']\n",
      "['val_loss', '0.6175']\n",
      "['val_accuracy', '0.8683']\n",
      "===== i 287\n",
      "287\n",
      "['loss', '0.2827']\n",
      "['accuracy', '0.9475']\n",
      "['val_loss', '0.8263']\n",
      "['val_accuracy', '0.8273']\n",
      "===== i 288\n",
      "288\n",
      "['loss', '0.2795']\n",
      "['accuracy', '0.9479']\n",
      "['val_loss', '0.6924']\n",
      "['val_accuracy', '0.8450']\n",
      "===== i 289\n",
      "289\n",
      "['loss', '0.2856']\n",
      "['accuracy', '0.9450']\n",
      "['val_loss', '0.7191']\n",
      "['val_accuracy', '0.8407']\n",
      "===== i 290\n",
      "290\n",
      "['loss', '0.2855']\n",
      "['accuracy', '0.9466']\n",
      "['val_loss', '0.6592']\n",
      "['val_accuracy', '0.8526']\n",
      "===== i 291\n",
      "291\n",
      "['loss', '0.2824']\n",
      "['accuracy', '0.9471']\n",
      "['val_loss', '0.7608']\n",
      "['val_accuracy', '0.8409']\n",
      "===== i 292\n",
      "292\n",
      "['loss', '0.2832']\n",
      "['accuracy', '0.9471']\n",
      "['val_loss', '0.6451']\n",
      "['val_accuracy', '0.8550']\n",
      "===== i 293\n",
      "293\n",
      "['loss', '0.2814']\n",
      "['accuracy', '0.9486']\n",
      "['val_loss', '0.6678']\n",
      "['val_accuracy', '0.8492']\n",
      "===== i 294\n",
      "294\n",
      "['loss', '0.2799']\n",
      "['accuracy', '0.9482']\n",
      "['val_loss', '0.6797']\n",
      "['val_accuracy', '0.8521']\n",
      "===== i 295\n",
      "295\n",
      "['loss', '0.2859']\n",
      "['accuracy', '0.9457']\n",
      "['val_loss', '0.6798']\n",
      "['val_accuracy', '0.8507']\n",
      "===== i 296\n",
      "296\n",
      "['loss', '0.2834']\n",
      "['accuracy', '0.9474']\n",
      "['val_loss', '0.6828']\n",
      "['val_accuracy', '0.8566']\n",
      "===== i 297\n",
      "297\n",
      "['loss', '0.2803']\n",
      "['accuracy', '0.9488']\n",
      "['val_loss', '0.6909']\n",
      "['val_accuracy', '0.8460']\n",
      "===== i 298\n",
      "298\n",
      "['loss', '0.2798']\n",
      "['accuracy', '0.9485']\n",
      "['val_loss', '0.6899']\n",
      "['val_accuracy', '0.8437']\n",
      "===== i 299\n",
      "299\n",
      "['loss', '0.2770']\n",
      "['accuracy', '0.9484']\n",
      "['val_loss', '0.6863']\n",
      "['val_accuracy', '0.8503']\n",
      "===== i 300\n",
      "300\n",
      "['loss', '0.2809']\n",
      "['accuracy', '0.9467']\n",
      "['val_loss', '0.6927']\n",
      "['val_accuracy', '0.8499']\n",
      "===== i 301\n",
      "301\n",
      "['loss', '0.2792']\n",
      "['accuracy', '0.9484']\n",
      "['val_loss', '0.6560']\n",
      "['val_accuracy', '0.8580']\n",
      "===== i 302\n",
      "302\n",
      "['loss', '0.2802']\n",
      "['accuracy', '0.9472']\n",
      "['val_loss', '0.6405']\n",
      "['val_accuracy', '0.8626']\n",
      "===== i 303\n",
      "303\n",
      "['loss', '0.2779']\n",
      "['accuracy', '0.9488']\n",
      "['val_loss', '0.6713']\n",
      "['val_accuracy', '0.8536']\n",
      "===== i 304\n",
      "304\n",
      "['loss', '0.2779']\n",
      "['accuracy', '0.9496']\n",
      "['val_loss', '0.6530']\n",
      "['val_accuracy', '0.8614']\n",
      "===== i 305\n",
      "305\n",
      "['loss', '0.2770']\n",
      "['accuracy', '0.9488']\n",
      "['val_loss', '0.7120']\n",
      "['val_accuracy', '0.8528']\n",
      "===== i 306\n",
      "306\n",
      "['loss', '0.2791']\n",
      "['accuracy', '0.9481']\n",
      "['val_loss', '0.6720']\n",
      "['val_accuracy', '0.8495']\n",
      "===== i 307\n",
      "307\n",
      "['loss', '0.2819']\n",
      "['accuracy', '0.9472']\n",
      "['val_loss', '0.7144']\n",
      "['val_accuracy', '0.8472']\n",
      "===== i 308\n",
      "308\n",
      "['loss', '0.2753']\n",
      "['accuracy', '0.9498']\n",
      "['val_loss', '0.7666']\n",
      "['val_accuracy', '0.8306']\n",
      "===== i 309\n",
      "309\n",
      "['loss', '0.2816']\n",
      "['accuracy', '0.9475']\n",
      "['val_loss', '0.6860']\n",
      "['val_accuracy', '0.8523']\n",
      "===== i 310\n",
      "310\n",
      "['loss', '0.2776']\n",
      "['accuracy', '0.9483']\n",
      "['val_loss', '0.6804']\n",
      "['val_accuracy', '0.8555']\n",
      "===== i 311\n",
      "311\n",
      "['loss', '0.2786']\n",
      "['accuracy', '0.9486']\n",
      "['val_loss', '0.7367']\n",
      "['val_accuracy', '0.8473']\n",
      "===== i 312\n",
      "312\n",
      "['loss', '0.2726']\n",
      "['accuracy', '0.9506']\n",
      "['val_loss', '0.7451']\n",
      "['val_accuracy', '0.8436']\n",
      "===== i 313\n",
      "313\n",
      "['loss', '0.2743']\n",
      "['accuracy', '0.9501']\n",
      "['val_loss', '0.6761']\n",
      "['val_accuracy', '0.8491']\n",
      "===== i 314\n",
      "314\n",
      "['loss', '0.2786']\n",
      "['accuracy', '0.9481']\n",
      "['val_loss', '0.7307']\n",
      "['val_accuracy', '0.8401']\n",
      "===== i 315\n",
      "315\n",
      "['loss', '0.2759']\n",
      "['accuracy', '0.9497']\n",
      "['val_loss', '0.6713']\n",
      "['val_accuracy', '0.8542']\n",
      "===== i 316\n",
      "316\n",
      "['loss', '0.2738']\n",
      "['accuracy', '0.9512']\n",
      "['val_loss', '0.6667']\n",
      "['val_accuracy', '0.8529']\n",
      "===== i 317\n",
      "317\n",
      "['loss', '0.2760']\n",
      "['accuracy', '0.9498']\n",
      "['val_loss', '0.7754']\n",
      "['val_accuracy', '0.8369']\n",
      "===== i 318\n",
      "318\n",
      "['loss', '0.2765']\n",
      "['accuracy', '0.9477']\n",
      "['val_loss', '0.6874']\n",
      "['val_accuracy', '0.8531']\n",
      "===== i 319\n",
      "319\n",
      "['loss', '0.2715']\n",
      "['accuracy', '0.9517']\n",
      "['val_loss', '0.6533']\n",
      "['val_accuracy', '0.8537']\n",
      "===== i 320\n",
      "320\n",
      "['loss', '0.2762']\n",
      "['accuracy', '0.9483']\n",
      "['val_loss', '0.7438']\n",
      "['val_accuracy', '0.8434']\n",
      "===== i 321\n",
      "321\n",
      "['loss', '0.2733']\n",
      "['accuracy', '0.9509']\n",
      "['val_loss', '0.7636']\n",
      "['val_accuracy', '0.8368']\n",
      "===== i 322\n",
      "322\n",
      "['loss', '0.2731']\n",
      "['accuracy', '0.9500']\n",
      "['val_loss', '0.7383']\n",
      "['val_accuracy', '0.8384']\n",
      "===== i 323\n",
      "323\n",
      "['loss', '0.2705']\n",
      "['accuracy', '0.9519']\n",
      "['val_loss', '0.6764']\n",
      "['val_accuracy', '0.8581']\n",
      "===== i 324\n",
      "324\n",
      "['loss', '0.2768']\n",
      "['accuracy', '0.9494']\n",
      "['val_loss', '0.6772']\n",
      "['val_accuracy', '0.8575']\n",
      "===== i 325\n",
      "325\n",
      "['loss', '0.2719']\n",
      "['accuracy', '0.9510']\n",
      "['val_loss', '0.6400']\n",
      "['val_accuracy', '0.8595']\n",
      "===== i 326\n",
      "326\n",
      "['loss', '0.2663']\n",
      "['accuracy', '0.9526']\n",
      "['val_loss', '0.6620']\n",
      "['val_accuracy', '0.8509']\n",
      "===== i 327\n",
      "327\n",
      "['loss', '0.2744']\n",
      "['accuracy', '0.9492']\n",
      "['val_loss', '0.6701']\n",
      "['val_accuracy', '0.8544']\n",
      "===== i 328\n",
      "328\n",
      "['loss', '0.2695']\n",
      "['accuracy', '0.9514']\n",
      "['val_loss', '0.6916']\n",
      "['val_accuracy', '0.8550']\n",
      "===== i 329\n",
      "329\n",
      "['loss', '0.2722']\n",
      "['accuracy', '0.9512']\n",
      "['val_loss', '0.7454']\n",
      "['val_accuracy', '0.8447']\n",
      "===== i 330\n",
      "330\n",
      "['loss', '0.2795']\n",
      "['accuracy', '0.9474']\n",
      "['val_loss', '0.7416']\n",
      "['val_accuracy', '0.8388']\n",
      "===== i 331\n",
      "331\n",
      "['loss', '0.2745']\n",
      "['accuracy', '0.9499']\n",
      "['val_loss', '0.7185']\n",
      "['val_accuracy', '0.8433']\n",
      "===== i 332\n",
      "332\n",
      "['loss', '0.2728']\n",
      "['accuracy', '0.9506']\n",
      "['val_loss', '0.6861']\n",
      "['val_accuracy', '0.8568']\n",
      "===== i 333\n",
      "333\n",
      "['loss', '0.2720']\n",
      "['accuracy', '0.9499']\n",
      "['val_loss', '0.7373']\n",
      "['val_accuracy', '0.8420']\n",
      "===== i 334\n",
      "334\n",
      "['loss', '0.2694']\n",
      "['accuracy', '0.9522']\n",
      "['val_loss', '0.6462']\n",
      "['val_accuracy', '0.8587']\n",
      "===== i 335\n",
      "335\n",
      "['loss', '0.2732']\n",
      "['accuracy', '0.9501']\n",
      "['val_loss', '0.7015']\n",
      "['val_accuracy', '0.8469']\n",
      "===== i 336\n",
      "336\n",
      "['loss', '0.2731']\n",
      "['accuracy', '0.9498']\n",
      "['val_loss', '0.6470']\n",
      "['val_accuracy', '0.8630']\n",
      "===== i 337\n",
      "337\n",
      "['loss', '0.2729']\n",
      "['accuracy', '0.9503']\n",
      "['val_loss', '0.8527']\n",
      "['val_accuracy', '0.8240']\n",
      "===== i 338\n",
      "338\n",
      "['loss', '0.2708']\n",
      "['accuracy', '0.9513']\n",
      "['val_loss', '0.6755']\n",
      "['val_accuracy', '0.8525']\n",
      "===== i 339\n",
      "339\n",
      "['loss', '0.2735']\n",
      "['accuracy', '0.9506']\n",
      "['val_loss', '0.7327']\n",
      "['val_accuracy', '0.8424']\n",
      "===== i 340\n",
      "340\n",
      "['loss', '0.2710']\n",
      "['accuracy', '0.9513']\n",
      "['val_loss', '0.6720']\n",
      "['val_accuracy', '0.8564']\n",
      "===== i 341\n",
      "341\n",
      "['loss', '0.2726']\n",
      "['accuracy', '0.9515']\n",
      "['val_loss', '0.6834']\n",
      "['val_accuracy', '0.8543']\n",
      "===== i 342\n",
      "342\n",
      "['loss', '0.2674']\n",
      "['accuracy', '0.9522']\n",
      "['val_loss', '0.6595']\n",
      "['val_accuracy', '0.8561']\n",
      "===== i 343\n",
      "343\n",
      "['loss', '0.2674']\n",
      "['accuracy', '0.9519']\n",
      "['val_loss', '0.6965']\n",
      "['val_accuracy', '0.8480']\n",
      "===== i 344\n",
      "344\n",
      "['loss', '0.2742']\n",
      "['accuracy', '0.9498']\n",
      "['val_loss', '0.8320']\n",
      "['val_accuracy', '0.8341']\n",
      "===== i 345\n",
      "345\n",
      "['loss', '0.2688']\n",
      "['accuracy', '0.9515']\n",
      "['val_loss', '0.7245']\n",
      "['val_accuracy', '0.8485']\n",
      "===== i 346\n",
      "346\n",
      "['loss', '0.2741']\n",
      "['accuracy', '0.9487']\n",
      "['val_loss', '0.8742']\n",
      "['val_accuracy', '0.8256']\n",
      "===== i 347\n",
      "347\n",
      "['loss', '0.2724']\n",
      "['accuracy', '0.9503']\n",
      "['val_loss', '0.7522']\n",
      "['val_accuracy', '0.8332']\n",
      "===== i 348\n",
      "348\n",
      "['loss', '0.2677']\n",
      "['accuracy', '0.9521']\n",
      "['val_loss', '0.6746']\n",
      "['val_accuracy', '0.8563']\n",
      "===== i 349\n",
      "349\n",
      "['loss', '0.2681']\n",
      "['accuracy', '0.9515']\n",
      "['val_loss', '0.7856']\n",
      "['val_accuracy', '0.8296']\n",
      "===== i 350\n",
      "350\n",
      "['loss', '0.2669']\n",
      "['accuracy', '0.9532']\n",
      "['val_loss', '0.6581']\n",
      "['val_accuracy', '0.8571']\n",
      "===== i 351\n",
      "351\n",
      "['loss', '0.2676']\n",
      "['accuracy', '0.9518']\n",
      "['val_loss', '0.6211']\n",
      "['val_accuracy', '0.8610']\n",
      "===== i 352\n",
      "352\n",
      "['loss', '0.2686']\n",
      "['accuracy', '0.9524']\n",
      "['val_loss', '0.6593']\n",
      "['val_accuracy', '0.8573']\n",
      "===== i 353\n",
      "353\n",
      "['loss', '0.2682']\n",
      "['accuracy', '0.9525']\n",
      "['val_loss', '0.7021']\n",
      "['val_accuracy', '0.8523']\n",
      "===== i 354\n",
      "354\n",
      "['loss', '0.2672']\n",
      "['accuracy', '0.9532']\n",
      "['val_loss', '0.6965']\n",
      "['val_accuracy', '0.8492']\n",
      "===== i 355\n",
      "355\n",
      "['loss', '0.2666']\n",
      "['accuracy', '0.9525']\n",
      "['val_loss', '0.7969']\n",
      "['val_accuracy', '0.8292']\n",
      "===== i 356\n",
      "356\n",
      "['loss', '0.2659']\n",
      "['accuracy', '0.9533']\n",
      "['val_loss', '0.7062']\n",
      "['val_accuracy', '0.8461']\n",
      "===== i 357\n",
      "357\n",
      "['loss', '0.2701']\n",
      "['accuracy', '0.9506']\n",
      "['val_loss', '0.7249']\n",
      "['val_accuracy', '0.8499']\n",
      "===== i 358\n",
      "358\n",
      "['loss', '0.2630']\n",
      "['accuracy', '0.9538']\n",
      "['val_loss', '0.7024']\n",
      "['val_accuracy', '0.8479']\n",
      "===== i 359\n",
      "359\n",
      "['loss', '0.2685']\n",
      "['accuracy', '0.9502']\n",
      "['val_loss', '0.6537']\n",
      "['val_accuracy', '0.8627']\n",
      "===== i 360\n",
      "360\n",
      "['loss', '0.2691']\n",
      "['accuracy', '0.9515']\n",
      "['val_loss', '0.6930']\n",
      "['val_accuracy', '0.8517']\n",
      "===== i 361\n",
      "361\n",
      "['loss', '0.2640']\n",
      "['accuracy', '0.9536']\n",
      "['val_loss', '0.6640']\n",
      "['val_accuracy', '0.8533']\n",
      "===== i 362\n",
      "362\n",
      "['loss', '0.2663']\n",
      "['accuracy', '0.9527']\n",
      "['val_loss', '0.6400']\n",
      "['val_accuracy', '0.8611']\n",
      "===== i 363\n",
      "363\n",
      "['loss', '0.2690']\n",
      "['accuracy', '0.9512']\n",
      "['val_loss', '0.7377']\n",
      "['val_accuracy', '0.8530']\n",
      "===== i 364\n",
      "364\n",
      "['loss', '0.2642']\n",
      "['accuracy', '0.9536']\n",
      "['val_loss', '0.6716']\n",
      "['val_accuracy', '0.8618']\n",
      "===== i 365\n",
      "365\n",
      "['loss', '0.2653']\n",
      "['accuracy', '0.9526']\n",
      "['val_loss', '0.7125']\n",
      "['val_accuracy', '0.8529']\n",
      "===== i 366\n",
      "366\n",
      "['loss', '0.2677']\n",
      "['accuracy', '0.9509']\n",
      "['val_loss', '0.6676']\n",
      "['val_accuracy', '0.8515']\n",
      "===== i 367\n",
      "367\n",
      "['loss', '0.2668']\n",
      "['accuracy', '0.9531']\n",
      "['val_loss', '0.7023']\n",
      "['val_accuracy', '0.8529']\n",
      "===== i 368\n",
      "368\n",
      "['loss', '0.2694']\n",
      "['accuracy', '0.9504']\n",
      "['val_loss', '0.7458']\n",
      "['val_accuracy', '0.8407']\n",
      "===== i 369\n",
      "369\n",
      "['loss', '0.2675']\n",
      "['accuracy', '0.9522']\n",
      "['val_loss', '0.6850']\n",
      "['val_accuracy', '0.8518']\n",
      "===== i 370\n",
      "370\n",
      "['loss', '0.2644']\n",
      "['accuracy', '0.9527']\n",
      "['val_loss', '0.7056']\n",
      "['val_accuracy', '0.8494']\n",
      "===== i 371\n",
      "371\n",
      "['loss', '0.2637']\n",
      "['accuracy', '0.9522']\n",
      "['val_loss', '0.6489']\n",
      "['val_accuracy', '0.8566']\n",
      "===== i 372\n",
      "372\n",
      "['loss', '0.2659']\n",
      "['accuracy', '0.9526']\n",
      "['val_loss', '0.6922']\n",
      "['val_accuracy', '0.8555']\n",
      "===== i 373\n",
      "373\n",
      "['loss', '0.2608']\n",
      "['accuracy', '0.9551']\n",
      "['val_loss', '0.6417']\n",
      "['val_accuracy', '0.8606']\n",
      "===== i 374\n",
      "374\n",
      "['loss', '0.2644']\n",
      "['accuracy', '0.9535']\n",
      "['val_loss', '0.6931']\n",
      "['val_accuracy', '0.8561']\n",
      "===== i 375\n",
      "375\n",
      "['loss', '0.2617']\n",
      "['accuracy', '0.9531']\n",
      "['val_loss', '0.7804']\n",
      "['val_accuracy', '0.8321']\n",
      "===== i 376\n",
      "376\n",
      "['loss', '0.2647']\n",
      "['accuracy', '0.9525']\n",
      "['val_loss', '0.7794']\n",
      "['val_accuracy', '0.8333']\n",
      "===== i 377\n",
      "377\n",
      "['loss', '0.2641']\n",
      "['accuracy', '0.9532']\n",
      "['val_loss', '0.7805']\n",
      "['val_accuracy', '0.8368']\n",
      "===== i 378\n",
      "378\n",
      "['loss', '0.2666']\n",
      "['accuracy', '0.9517']\n",
      "['val_loss', '0.6105']\n",
      "['val_accuracy', '0.8671']\n",
      "===== i 379\n",
      "379\n",
      "['loss', '0.2642']\n",
      "['accuracy', '0.9526']\n",
      "['val_loss', '0.6633']\n",
      "['val_accuracy', '0.8573']\n",
      "===== i 380\n",
      "380\n",
      "['loss', '0.2619']\n",
      "['accuracy', '0.9539']\n",
      "['val_loss', '0.6349']\n",
      "['val_accuracy', '0.8556']\n",
      "===== i 381\n",
      "381\n",
      "['loss', '0.2654']\n",
      "['accuracy', '0.9533']\n",
      "['val_loss', '0.6601']\n",
      "['val_accuracy', '0.8625']\n",
      "===== i 382\n",
      "382\n",
      "['loss', '0.2633']\n",
      "['accuracy', '0.9530']\n",
      "['val_loss', '0.6633']\n",
      "['val_accuracy', '0.8596']\n",
      "===== i 383\n",
      "383\n",
      "['loss', '0.2595']\n",
      "['accuracy', '0.9548']\n",
      "['val_loss', '0.7185']\n",
      "['val_accuracy', '0.8444']\n",
      "===== i 384\n",
      "384\n",
      "['loss', '0.2650']\n",
      "['accuracy', '0.9528']\n",
      "['val_loss', '0.6608']\n",
      "['val_accuracy', '0.8551']\n",
      "===== i 385\n",
      "385\n",
      "['loss', '0.2602']\n",
      "['accuracy', '0.9544']\n",
      "['val_loss', '0.6564']\n",
      "['val_accuracy', '0.8623']\n",
      "===== i 386\n",
      "386\n",
      "['loss', '0.2605']\n",
      "['accuracy', '0.9536']\n",
      "['val_loss', '0.7244']\n",
      "['val_accuracy', '0.8448']\n",
      "===== i 387\n",
      "387\n",
      "['loss', '0.2627']\n",
      "['accuracy', '0.9525']\n",
      "['val_loss', '0.7320']\n",
      "['val_accuracy', '0.8400']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== i 388\n",
      "388\n",
      "['loss', '0.2590']\n",
      "['accuracy', '0.9551']\n",
      "['val_loss', '0.7197']\n",
      "['val_accuracy', '0.8470']\n",
      "===== i 389\n",
      "389\n",
      "['loss', '0.2637']\n",
      "['accuracy', '0.9530']\n",
      "['val_loss', '0.6643']\n",
      "['val_accuracy', '0.8647']\n",
      "===== i 390\n",
      "390\n",
      "['loss', '0.2636']\n",
      "['accuracy', '0.9516']\n",
      "['val_loss', '0.7211']\n",
      "['val_accuracy', '0.8525']\n",
      "===== i 391\n",
      "391\n",
      "['loss', '0.2630']\n",
      "['accuracy', '0.9542']\n",
      "['val_loss', '0.7936']\n",
      "['val_accuracy', '0.8417']\n",
      "===== i 392\n",
      "392\n",
      "['loss', '0.2643']\n",
      "['accuracy', '0.9529']\n",
      "['val_loss', '0.6415']\n",
      "['val_accuracy', '0.8582']\n",
      "===== i 393\n",
      "393\n",
      "['loss', '0.2624']\n",
      "['accuracy', '0.9523']\n",
      "['val_loss', '0.6906']\n",
      "['val_accuracy', '0.8505']\n",
      "===== i 394\n",
      "394\n",
      "['loss', '0.2641']\n",
      "['accuracy', '0.9533']\n",
      "['val_loss', '0.7900']\n",
      "['val_accuracy', '0.8337']\n",
      "===== i 395\n",
      "395\n",
      "['loss', '0.2596']\n",
      "['accuracy', '0.9550']\n",
      "['val_loss', '0.7332']\n",
      "['val_accuracy', '0.8525']\n",
      "===== i 396\n",
      "396\n",
      "['loss', '0.2592']\n",
      "['accuracy', '0.9551']\n",
      "['val_loss', '0.7620']\n",
      "['val_accuracy', '0.8421']\n",
      "===== i 397\n",
      "397\n",
      "['loss', '0.2639']\n",
      "['accuracy', '0.9529']\n",
      "['val_loss', '0.7878']\n",
      "['val_accuracy', '0.8388']\n",
      "===== i 398\n",
      "398\n",
      "['loss', '0.2582']\n",
      "['accuracy', '0.9538']\n",
      "['val_loss', '0.7343']\n",
      "['val_accuracy', '0.8463']\n",
      "===== i 399\n",
      "399\n",
      "['loss', '0.2623']\n",
      "['accuracy', '0.9541']\n",
      "['val_loss', '0.6424']\n",
      "['val_accuracy', '0.8570']\n",
      "===== i 400\n",
      "400\n",
      "['loss', '0.2579']\n",
      "['accuracy', '0.9536']\n",
      "['val_loss', '0.7216']\n",
      "['val_accuracy', '0.8420']\n",
      "===== i 401\n",
      "401\n",
      "['loss', '0.2621']\n",
      "['accuracy', '0.9533']\n",
      "['val_loss', '0.6775']\n",
      "['val_accuracy', '0.8556']\n",
      "===== i 402\n",
      "402\n",
      "['loss', '0.2603']\n",
      "['accuracy', '0.9547']\n",
      "['val_loss', '0.7284']\n",
      "['val_accuracy', '0.8466']\n",
      "===== i 403\n",
      "403\n",
      "['loss', '0.2548']\n",
      "['accuracy', '0.9544']\n",
      "['val_loss', '0.7301']\n",
      "['val_accuracy', '0.8443']\n",
      "===== i 404\n",
      "404\n",
      "['loss', '0.2612']\n",
      "['accuracy', '0.9543']\n",
      "['val_loss', '0.7883']\n",
      "['val_accuracy', '0.8323']\n",
      "===== i 405\n",
      "405\n",
      "['loss', '0.2622']\n",
      "['accuracy', '0.9542']\n",
      "['val_loss', '0.7217']\n",
      "['val_accuracy', '0.8503']\n",
      "===== i 406\n",
      "406\n",
      "['loss', '0.2604']\n",
      "['accuracy', '0.9539']\n",
      "['val_loss', '0.6567']\n",
      "['val_accuracy', '0.8566']\n"
     ]
    }
   ],
   "source": [
    "history_dict = {\n",
    "    'loss': [],\n",
    "    'accuracy': [],\n",
    "    'val_loss': [],\n",
    "    'val_accuracy': [],\n",
    "    'epochs': []\n",
    "}\n",
    "\n",
    "for i in range(len(splitted)//2):\n",
    "    print('===== i', i)\n",
    "#     print('epoch', splitted[2*i-1][5:][:-3])\n",
    "    tmp = splitted[2*i].split(' - ')\n",
    "    if len(tmp) > 1:\n",
    "        print(splitted[2*i-1].split(' ')[1][:-4])\n",
    "        print(tmp[2].split(': '))\n",
    "        print(tmp[3].split(': '))\n",
    "        print(tmp[4].split(': '))\n",
    "        print(tmp[5].split(': '))\n",
    "        \n",
    "        history_dict['epochs'].append(int(splitted[2*i-1].split(' ')[1][:-4]))\n",
    "        \n",
    "        for t in tmp[2:6]:\n",
    "            key, value = t.split(': ')\n",
    "            history_dict[key].append(float(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [2.0599,\n",
       "  1.7205,\n",
       "  1.5905,\n",
       "  1.4974,\n",
       "  1.4271,\n",
       "  1.37,\n",
       "  1.322,\n",
       "  1.2739,\n",
       "  1.2277,\n",
       "  1.1872,\n",
       "  1.1571,\n",
       "  1.1277,\n",
       "  1.1028,\n",
       "  1.0755,\n",
       "  1.0511,\n",
       "  1.0278,\n",
       "  1.014,\n",
       "  0.982,\n",
       "  0.9678,\n",
       "  0.9565,\n",
       "  0.9401,\n",
       "  0.9174,\n",
       "  0.9102,\n",
       "  0.8935,\n",
       "  0.8751,\n",
       "  0.8635,\n",
       "  0.8496,\n",
       "  0.8395,\n",
       "  0.8291,\n",
       "  0.8171,\n",
       "  0.8074,\n",
       "  0.7953,\n",
       "  0.7836,\n",
       "  0.7703,\n",
       "  0.7665,\n",
       "  0.7571,\n",
       "  0.7461,\n",
       "  0.736,\n",
       "  0.7283,\n",
       "  0.7202,\n",
       "  0.7188,\n",
       "  0.7046,\n",
       "  0.6946,\n",
       "  0.6887,\n",
       "  0.6783,\n",
       "  0.6786,\n",
       "  0.6651,\n",
       "  0.6626,\n",
       "  0.6481,\n",
       "  0.6409,\n",
       "  0.6448,\n",
       "  0.638,\n",
       "  0.6299,\n",
       "  0.6212,\n",
       "  0.6146,\n",
       "  0.6104,\n",
       "  0.6028,\n",
       "  0.6024,\n",
       "  0.5957,\n",
       "  0.5872,\n",
       "  0.5825,\n",
       "  0.5796,\n",
       "  0.5733,\n",
       "  0.5711,\n",
       "  0.5611,\n",
       "  0.5616,\n",
       "  0.557,\n",
       "  0.554,\n",
       "  0.549,\n",
       "  0.5395,\n",
       "  0.5393,\n",
       "  0.5325,\n",
       "  0.5226,\n",
       "  0.5194,\n",
       "  0.5207,\n",
       "  0.5116,\n",
       "  0.5109,\n",
       "  0.5116,\n",
       "  0.508,\n",
       "  0.5034,\n",
       "  0.5016,\n",
       "  0.4918,\n",
       "  0.4968,\n",
       "  0.4822,\n",
       "  0.486,\n",
       "  0.484,\n",
       "  0.4801,\n",
       "  0.474,\n",
       "  0.4719,\n",
       "  0.4704,\n",
       "  0.4657,\n",
       "  0.4678,\n",
       "  0.4588,\n",
       "  0.4602,\n",
       "  0.4539,\n",
       "  0.4526,\n",
       "  0.457,\n",
       "  0.4524,\n",
       "  0.4493,\n",
       "  0.4414,\n",
       "  0.4423,\n",
       "  0.4368,\n",
       "  0.4348,\n",
       "  0.4333,\n",
       "  0.4319,\n",
       "  0.4257,\n",
       "  0.4251,\n",
       "  0.4276,\n",
       "  0.4259,\n",
       "  0.413,\n",
       "  0.4205,\n",
       "  0.4246,\n",
       "  0.4124,\n",
       "  0.4117,\n",
       "  0.4105,\n",
       "  0.4098,\n",
       "  0.4041,\n",
       "  0.4013,\n",
       "  0.4081,\n",
       "  0.4034,\n",
       "  0.4027,\n",
       "  0.3946,\n",
       "  0.3935,\n",
       "  0.3941,\n",
       "  0.3899,\n",
       "  0.3896,\n",
       "  0.3888,\n",
       "  0.3904,\n",
       "  0.3933,\n",
       "  0.386,\n",
       "  0.385,\n",
       "  0.3825,\n",
       "  0.3788,\n",
       "  0.3798,\n",
       "  0.3791,\n",
       "  0.3745,\n",
       "  0.3781,\n",
       "  0.3738,\n",
       "  0.3719,\n",
       "  0.369,\n",
       "  0.3767,\n",
       "  0.3657,\n",
       "  0.3657,\n",
       "  0.3686,\n",
       "  0.3676,\n",
       "  0.3641,\n",
       "  0.3655,\n",
       "  0.3623,\n",
       "  0.3616,\n",
       "  0.3611,\n",
       "  0.3562,\n",
       "  0.3582,\n",
       "  0.3555,\n",
       "  0.3557,\n",
       "  0.3568,\n",
       "  0.3535,\n",
       "  0.3492,\n",
       "  0.3497,\n",
       "  0.3507,\n",
       "  0.3456,\n",
       "  0.3515,\n",
       "  0.3485,\n",
       "  0.3431,\n",
       "  0.3473,\n",
       "  0.3493,\n",
       "  0.3417,\n",
       "  0.3437,\n",
       "  0.3427,\n",
       "  0.3345,\n",
       "  0.3428,\n",
       "  0.3418,\n",
       "  0.3368,\n",
       "  0.3376,\n",
       "  0.3312,\n",
       "  0.3346,\n",
       "  0.3343,\n",
       "  0.3363,\n",
       "  0.3359,\n",
       "  0.3332,\n",
       "  0.3345,\n",
       "  0.3288,\n",
       "  0.3256,\n",
       "  0.3316,\n",
       "  0.3286,\n",
       "  0.3266,\n",
       "  0.3289,\n",
       "  0.3318,\n",
       "  0.3292,\n",
       "  0.3286,\n",
       "  0.3272,\n",
       "  0.3183,\n",
       "  0.3251,\n",
       "  0.3232,\n",
       "  0.3223,\n",
       "  0.3215,\n",
       "  0.3213,\n",
       "  0.3198,\n",
       "  0.3177,\n",
       "  0.3215,\n",
       "  0.3194,\n",
       "  0.3197,\n",
       "  0.3195,\n",
       "  0.3141,\n",
       "  0.3202,\n",
       "  0.3191,\n",
       "  0.3161,\n",
       "  0.3089,\n",
       "  0.3109,\n",
       "  0.3116,\n",
       "  0.3161,\n",
       "  0.3099,\n",
       "  0.3094,\n",
       "  0.3088,\n",
       "  0.3119,\n",
       "  0.3089,\n",
       "  0.3151,\n",
       "  0.3067,\n",
       "  0.3131,\n",
       "  0.306,\n",
       "  0.3075,\n",
       "  0.3046,\n",
       "  0.3099,\n",
       "  0.3038,\n",
       "  0.3005,\n",
       "  0.3073,\n",
       "  0.3046,\n",
       "  0.3084,\n",
       "  0.304,\n",
       "  0.3043,\n",
       "  0.3042,\n",
       "  0.3017,\n",
       "  0.3011,\n",
       "  0.2978,\n",
       "  0.3034,\n",
       "  0.2976,\n",
       "  0.3014,\n",
       "  0.2985,\n",
       "  0.3011,\n",
       "  0.3012,\n",
       "  0.2997,\n",
       "  0.3001,\n",
       "  0.2992,\n",
       "  0.3016,\n",
       "  0.2998,\n",
       "  0.2952,\n",
       "  0.3008,\n",
       "  0.2944,\n",
       "  0.2988,\n",
       "  0.2939,\n",
       "  0.2916,\n",
       "  0.2937,\n",
       "  0.2934,\n",
       "  0.292,\n",
       "  0.2876,\n",
       "  0.2917,\n",
       "  0.298,\n",
       "  0.2899,\n",
       "  0.2943,\n",
       "  0.294,\n",
       "  0.2934,\n",
       "  0.2884,\n",
       "  0.2962,\n",
       "  0.2887,\n",
       "  0.2879,\n",
       "  0.292,\n",
       "  0.2938,\n",
       "  0.2898,\n",
       "  0.2877,\n",
       "  0.2908,\n",
       "  0.2868,\n",
       "  0.2885,\n",
       "  0.2928,\n",
       "  0.2873,\n",
       "  0.2907,\n",
       "  0.2882,\n",
       "  0.2861,\n",
       "  0.2842,\n",
       "  0.2877,\n",
       "  0.2888,\n",
       "  0.2836,\n",
       "  0.2892,\n",
       "  0.288,\n",
       "  0.2869,\n",
       "  0.2859,\n",
       "  0.2879,\n",
       "  0.2799,\n",
       "  0.2827,\n",
       "  0.2795,\n",
       "  0.2856,\n",
       "  0.2855,\n",
       "  0.2824,\n",
       "  0.2832,\n",
       "  0.2814,\n",
       "  0.2799,\n",
       "  0.2859,\n",
       "  0.2834,\n",
       "  0.2803,\n",
       "  0.2798,\n",
       "  0.277,\n",
       "  0.2809,\n",
       "  0.2792,\n",
       "  0.2802,\n",
       "  0.2779,\n",
       "  0.2779,\n",
       "  0.277,\n",
       "  0.2791,\n",
       "  0.2819,\n",
       "  0.2753,\n",
       "  0.2816,\n",
       "  0.2776,\n",
       "  0.2786,\n",
       "  0.2726,\n",
       "  0.2743,\n",
       "  0.2786,\n",
       "  0.2759,\n",
       "  0.2738,\n",
       "  0.276,\n",
       "  0.2765,\n",
       "  0.2715,\n",
       "  0.2762,\n",
       "  0.2733,\n",
       "  0.2731,\n",
       "  0.2705,\n",
       "  0.2768,\n",
       "  0.2719,\n",
       "  0.2663,\n",
       "  0.2744,\n",
       "  0.2695,\n",
       "  0.2722,\n",
       "  0.2795,\n",
       "  0.2745,\n",
       "  0.2728,\n",
       "  0.272,\n",
       "  0.2694,\n",
       "  0.2732,\n",
       "  0.2731,\n",
       "  0.2729,\n",
       "  0.2708,\n",
       "  0.2735,\n",
       "  0.271,\n",
       "  0.2726,\n",
       "  0.2674,\n",
       "  0.2674,\n",
       "  0.2742,\n",
       "  0.2688,\n",
       "  0.2741,\n",
       "  0.2724,\n",
       "  0.2677,\n",
       "  0.2681,\n",
       "  0.2669,\n",
       "  0.2676,\n",
       "  0.2686,\n",
       "  0.2682,\n",
       "  0.2672,\n",
       "  0.2666,\n",
       "  0.2659,\n",
       "  0.2701,\n",
       "  0.263,\n",
       "  0.2685,\n",
       "  0.2691,\n",
       "  0.264,\n",
       "  0.2663,\n",
       "  0.269,\n",
       "  0.2642,\n",
       "  0.2653,\n",
       "  0.2677,\n",
       "  0.2668,\n",
       "  0.2694,\n",
       "  0.2675,\n",
       "  0.2644,\n",
       "  0.2637,\n",
       "  0.2659,\n",
       "  0.2608,\n",
       "  0.2644,\n",
       "  0.2617,\n",
       "  0.2647,\n",
       "  0.2641,\n",
       "  0.2666,\n",
       "  0.2642,\n",
       "  0.2619,\n",
       "  0.2654,\n",
       "  0.2633,\n",
       "  0.2595,\n",
       "  0.265,\n",
       "  0.2602,\n",
       "  0.2605,\n",
       "  0.2627,\n",
       "  0.259,\n",
       "  0.2637,\n",
       "  0.2636,\n",
       "  0.263,\n",
       "  0.2643,\n",
       "  0.2624,\n",
       "  0.2641,\n",
       "  0.2596,\n",
       "  0.2592,\n",
       "  0.2639,\n",
       "  0.2582,\n",
       "  0.2623,\n",
       "  0.2579,\n",
       "  0.2621,\n",
       "  0.2603,\n",
       "  0.2548,\n",
       "  0.2612,\n",
       "  0.2622,\n",
       "  0.2604],\n",
       " 'accuracy': [0.4107,\n",
       "  0.5219,\n",
       "  0.5688,\n",
       "  0.6016,\n",
       "  0.625,\n",
       "  0.6446,\n",
       "  0.6601,\n",
       "  0.6759,\n",
       "  0.6915,\n",
       "  0.7038,\n",
       "  0.7128,\n",
       "  0.7219,\n",
       "  0.728,\n",
       "  0.7381,\n",
       "  0.7459,\n",
       "  0.7506,\n",
       "  0.7562,\n",
       "  0.7662,\n",
       "  0.7707,\n",
       "  0.7727,\n",
       "  0.7755,\n",
       "  0.7846,\n",
       "  0.7841,\n",
       "  0.787,\n",
       "  0.7944,\n",
       "  0.7977,\n",
       "  0.8022,\n",
       "  0.8027,\n",
       "  0.8066,\n",
       "  0.81,\n",
       "  0.8119,\n",
       "  0.8157,\n",
       "  0.8187,\n",
       "  0.8216,\n",
       "  0.8241,\n",
       "  0.8253,\n",
       "  0.8266,\n",
       "  0.8314,\n",
       "  0.8309,\n",
       "  0.8347,\n",
       "  0.833,\n",
       "  0.8397,\n",
       "  0.8395,\n",
       "  0.8418,\n",
       "  0.8446,\n",
       "  0.8439,\n",
       "  0.8478,\n",
       "  0.8482,\n",
       "  0.851,\n",
       "  0.8544,\n",
       "  0.8517,\n",
       "  0.8545,\n",
       "  0.8556,\n",
       "  0.8579,\n",
       "  0.8589,\n",
       "  0.8621,\n",
       "  0.8638,\n",
       "  0.8619,\n",
       "  0.8625,\n",
       "  0.8674,\n",
       "  0.8671,\n",
       "  0.8667,\n",
       "  0.8684,\n",
       "  0.8687,\n",
       "  0.8732,\n",
       "  0.8715,\n",
       "  0.8726,\n",
       "  0.8728,\n",
       "  0.8751,\n",
       "  0.8779,\n",
       "  0.8781,\n",
       "  0.8798,\n",
       "  0.8812,\n",
       "  0.8835,\n",
       "  0.8827,\n",
       "  0.8845,\n",
       "  0.8835,\n",
       "  0.8841,\n",
       "  0.8839,\n",
       "  0.8851,\n",
       "  0.8879,\n",
       "  0.8876,\n",
       "  0.8874,\n",
       "  0.8937,\n",
       "  0.891,\n",
       "  0.8903,\n",
       "  0.8912,\n",
       "  0.8934,\n",
       "  0.8948,\n",
       "  0.8945,\n",
       "  0.8954,\n",
       "  0.894,\n",
       "  0.8968,\n",
       "  0.8974,\n",
       "  0.8973,\n",
       "  0.8981,\n",
       "  0.8967,\n",
       "  0.8983,\n",
       "  0.899,\n",
       "  0.9012,\n",
       "  0.9009,\n",
       "  0.9036,\n",
       "  0.9043,\n",
       "  0.9055,\n",
       "  0.9046,\n",
       "  0.9059,\n",
       "  0.9052,\n",
       "  0.9051,\n",
       "  0.9058,\n",
       "  0.9092,\n",
       "  0.906,\n",
       "  0.9067,\n",
       "  0.9097,\n",
       "  0.9093,\n",
       "  0.9108,\n",
       "  0.9098,\n",
       "  0.9119,\n",
       "  0.9117,\n",
       "  0.9091,\n",
       "  0.9101,\n",
       "  0.9112,\n",
       "  0.9141,\n",
       "  0.9137,\n",
       "  0.9137,\n",
       "  0.9143,\n",
       "  0.9152,\n",
       "  0.9163,\n",
       "  0.9142,\n",
       "  0.915,\n",
       "  0.9166,\n",
       "  0.9156,\n",
       "  0.9178,\n",
       "  0.9196,\n",
       "  0.9185,\n",
       "  0.9178,\n",
       "  0.9192,\n",
       "  0.9176,\n",
       "  0.9198,\n",
       "  0.9196,\n",
       "  0.9213,\n",
       "  0.9187,\n",
       "  0.9209,\n",
       "  0.9228,\n",
       "  0.9208,\n",
       "  0.9205,\n",
       "  0.9215,\n",
       "  0.9216,\n",
       "  0.9226,\n",
       "  0.9224,\n",
       "  0.9227,\n",
       "  0.9257,\n",
       "  0.9235,\n",
       "  0.9254,\n",
       "  0.9238,\n",
       "  0.9242,\n",
       "  0.9251,\n",
       "  0.9276,\n",
       "  0.9259,\n",
       "  0.9258,\n",
       "  0.9278,\n",
       "  0.9255,\n",
       "  0.9273,\n",
       "  0.9284,\n",
       "  0.9263,\n",
       "  0.9256,\n",
       "  0.9282,\n",
       "  0.9283,\n",
       "  0.929,\n",
       "  0.9321,\n",
       "  0.928,\n",
       "  0.9286,\n",
       "  0.9298,\n",
       "  0.9288,\n",
       "  0.931,\n",
       "  0.9298,\n",
       "  0.9304,\n",
       "  0.9302,\n",
       "  0.9303,\n",
       "  0.9315,\n",
       "  0.9317,\n",
       "  0.9323,\n",
       "  0.9342,\n",
       "  0.9312,\n",
       "  0.9326,\n",
       "  0.9327,\n",
       "  0.9318,\n",
       "  0.9321,\n",
       "  0.9323,\n",
       "  0.9333,\n",
       "  0.9327,\n",
       "  0.9364,\n",
       "  0.934,\n",
       "  0.9339,\n",
       "  0.9345,\n",
       "  0.9354,\n",
       "  0.9353,\n",
       "  0.9345,\n",
       "  0.9353,\n",
       "  0.9344,\n",
       "  0.9358,\n",
       "  0.9349,\n",
       "  0.9365,\n",
       "  0.9374,\n",
       "  0.9355,\n",
       "  0.9349,\n",
       "  0.9364,\n",
       "  0.9391,\n",
       "  0.9383,\n",
       "  0.9369,\n",
       "  0.936,\n",
       "  0.9386,\n",
       "  0.9391,\n",
       "  0.9388,\n",
       "  0.9386,\n",
       "  0.9389,\n",
       "  0.9362,\n",
       "  0.9397,\n",
       "  0.9376,\n",
       "  0.9396,\n",
       "  0.94,\n",
       "  0.9413,\n",
       "  0.9373,\n",
       "  0.9404,\n",
       "  0.9418,\n",
       "  0.939,\n",
       "  0.941,\n",
       "  0.9383,\n",
       "  0.941,\n",
       "  0.9394,\n",
       "  0.9412,\n",
       "  0.9417,\n",
       "  0.941,\n",
       "  0.9421,\n",
       "  0.9408,\n",
       "  0.9433,\n",
       "  0.9418,\n",
       "  0.9419,\n",
       "  0.9413,\n",
       "  0.9401,\n",
       "  0.9419,\n",
       "  0.9402,\n",
       "  0.9418,\n",
       "  0.9401,\n",
       "  0.9414,\n",
       "  0.9445,\n",
       "  0.9416,\n",
       "  0.9441,\n",
       "  0.9417,\n",
       "  0.9447,\n",
       "  0.9452,\n",
       "  0.943,\n",
       "  0.9437,\n",
       "  0.9455,\n",
       "  0.945,\n",
       "  0.9438,\n",
       "  0.9416,\n",
       "  0.9449,\n",
       "  0.9447,\n",
       "  0.9434,\n",
       "  0.9432,\n",
       "  0.9458,\n",
       "  0.942,\n",
       "  0.9453,\n",
       "  0.9457,\n",
       "  0.945,\n",
       "  0.9432,\n",
       "  0.9453,\n",
       "  0.9446,\n",
       "  0.9447,\n",
       "  0.9467,\n",
       "  0.9455,\n",
       "  0.9437,\n",
       "  0.9464,\n",
       "  0.944,\n",
       "  0.945,\n",
       "  0.9453,\n",
       "  0.9467,\n",
       "  0.9462,\n",
       "  0.9445,\n",
       "  0.9466,\n",
       "  0.9446,\n",
       "  0.9452,\n",
       "  0.945,\n",
       "  0.9458,\n",
       "  0.945,\n",
       "  0.9495,\n",
       "  0.9475,\n",
       "  0.9479,\n",
       "  0.945,\n",
       "  0.9466,\n",
       "  0.9471,\n",
       "  0.9471,\n",
       "  0.9486,\n",
       "  0.9482,\n",
       "  0.9457,\n",
       "  0.9474,\n",
       "  0.9488,\n",
       "  0.9485,\n",
       "  0.9484,\n",
       "  0.9467,\n",
       "  0.9484,\n",
       "  0.9472,\n",
       "  0.9488,\n",
       "  0.9496,\n",
       "  0.9488,\n",
       "  0.9481,\n",
       "  0.9472,\n",
       "  0.9498,\n",
       "  0.9475,\n",
       "  0.9483,\n",
       "  0.9486,\n",
       "  0.9506,\n",
       "  0.9501,\n",
       "  0.9481,\n",
       "  0.9497,\n",
       "  0.9512,\n",
       "  0.9498,\n",
       "  0.9477,\n",
       "  0.9517,\n",
       "  0.9483,\n",
       "  0.9509,\n",
       "  0.95,\n",
       "  0.9519,\n",
       "  0.9494,\n",
       "  0.951,\n",
       "  0.9526,\n",
       "  0.9492,\n",
       "  0.9514,\n",
       "  0.9512,\n",
       "  0.9474,\n",
       "  0.9499,\n",
       "  0.9506,\n",
       "  0.9499,\n",
       "  0.9522,\n",
       "  0.9501,\n",
       "  0.9498,\n",
       "  0.9503,\n",
       "  0.9513,\n",
       "  0.9506,\n",
       "  0.9513,\n",
       "  0.9515,\n",
       "  0.9522,\n",
       "  0.9519,\n",
       "  0.9498,\n",
       "  0.9515,\n",
       "  0.9487,\n",
       "  0.9503,\n",
       "  0.9521,\n",
       "  0.9515,\n",
       "  0.9532,\n",
       "  0.9518,\n",
       "  0.9524,\n",
       "  0.9525,\n",
       "  0.9532,\n",
       "  0.9525,\n",
       "  0.9533,\n",
       "  0.9506,\n",
       "  0.9538,\n",
       "  0.9502,\n",
       "  0.9515,\n",
       "  0.9536,\n",
       "  0.9527,\n",
       "  0.9512,\n",
       "  0.9536,\n",
       "  0.9526,\n",
       "  0.9509,\n",
       "  0.9531,\n",
       "  0.9504,\n",
       "  0.9522,\n",
       "  0.9527,\n",
       "  0.9522,\n",
       "  0.9526,\n",
       "  0.9551,\n",
       "  0.9535,\n",
       "  0.9531,\n",
       "  0.9525,\n",
       "  0.9532,\n",
       "  0.9517,\n",
       "  0.9526,\n",
       "  0.9539,\n",
       "  0.9533,\n",
       "  0.953,\n",
       "  0.9548,\n",
       "  0.9528,\n",
       "  0.9544,\n",
       "  0.9536,\n",
       "  0.9525,\n",
       "  0.9551,\n",
       "  0.953,\n",
       "  0.9516,\n",
       "  0.9542,\n",
       "  0.9529,\n",
       "  0.9523,\n",
       "  0.9533,\n",
       "  0.955,\n",
       "  0.9551,\n",
       "  0.9529,\n",
       "  0.9538,\n",
       "  0.9541,\n",
       "  0.9536,\n",
       "  0.9533,\n",
       "  0.9547,\n",
       "  0.9544,\n",
       "  0.9543,\n",
       "  0.9542,\n",
       "  0.9539],\n",
       " 'val_loss': [1.8859,\n",
       "  1.9937,\n",
       "  1.6765,\n",
       "  1.4793,\n",
       "  1.5261,\n",
       "  1.4851,\n",
       "  1.2994,\n",
       "  1.2912,\n",
       "  1.2616,\n",
       "  1.319,\n",
       "  1.2867,\n",
       "  1.462,\n",
       "  1.159,\n",
       "  1.0992,\n",
       "  1.2855,\n",
       "  1.1468,\n",
       "  1.1902,\n",
       "  1.0532,\n",
       "  1.0227,\n",
       "  1.0175,\n",
       "  1.0776,\n",
       "  1.1113,\n",
       "  1.0366,\n",
       "  1.108,\n",
       "  0.9486,\n",
       "  0.9943,\n",
       "  0.9457,\n",
       "  0.9368,\n",
       "  0.9918,\n",
       "  1.0488,\n",
       "  0.8897,\n",
       "  0.8769,\n",
       "  0.8802,\n",
       "  0.8704,\n",
       "  0.8473,\n",
       "  0.9571,\n",
       "  0.8691,\n",
       "  0.9446,\n",
       "  0.8442,\n",
       "  0.8885,\n",
       "  0.8955,\n",
       "  0.8608,\n",
       "  0.8278,\n",
       "  0.8742,\n",
       "  0.8551,\n",
       "  0.8351,\n",
       "  0.8334,\n",
       "  0.8033,\n",
       "  0.8713,\n",
       "  0.8011,\n",
       "  0.8453,\n",
       "  0.795,\n",
       "  0.7773,\n",
       "  0.7947,\n",
       "  0.9437,\n",
       "  0.879,\n",
       "  0.8848,\n",
       "  0.788,\n",
       "  0.8284,\n",
       "  0.7586,\n",
       "  0.7995,\n",
       "  0.8975,\n",
       "  0.8706,\n",
       "  0.8334,\n",
       "  0.7812,\n",
       "  0.7427,\n",
       "  0.7551,\n",
       "  0.7871,\n",
       "  0.7427,\n",
       "  0.8832,\n",
       "  0.7371,\n",
       "  0.7335,\n",
       "  0.7645,\n",
       "  0.7325,\n",
       "  0.8524,\n",
       "  0.7493,\n",
       "  0.7522,\n",
       "  0.8058,\n",
       "  0.7211,\n",
       "  0.7202,\n",
       "  0.721,\n",
       "  0.7478,\n",
       "  0.7869,\n",
       "  0.7451,\n",
       "  0.7508,\n",
       "  0.7341,\n",
       "  0.6927,\n",
       "  0.8767,\n",
       "  0.7124,\n",
       "  0.7406,\n",
       "  0.7814,\n",
       "  0.6929,\n",
       "  0.7917,\n",
       "  0.8237,\n",
       "  0.811,\n",
       "  0.7317,\n",
       "  0.671,\n",
       "  0.6893,\n",
       "  0.6305,\n",
       "  0.763,\n",
       "  0.7386,\n",
       "  0.7295,\n",
       "  0.6502,\n",
       "  0.6806,\n",
       "  0.749,\n",
       "  0.9395,\n",
       "  0.7368,\n",
       "  0.6543,\n",
       "  0.7818,\n",
       "  0.7225,\n",
       "  0.7117,\n",
       "  0.6748,\n",
       "  0.6957,\n",
       "  0.7909,\n",
       "  0.6461,\n",
       "  0.6621,\n",
       "  0.6754,\n",
       "  0.6281,\n",
       "  0.7457,\n",
       "  0.6785,\n",
       "  0.6523,\n",
       "  0.7062,\n",
       "  0.6977,\n",
       "  0.7185,\n",
       "  0.6906,\n",
       "  0.6042,\n",
       "  0.7511,\n",
       "  0.7261,\n",
       "  0.6887,\n",
       "  0.7198,\n",
       "  0.7012,\n",
       "  0.7076,\n",
       "  0.7418,\n",
       "  0.708,\n",
       "  0.7835,\n",
       "  0.7252,\n",
       "  0.6736,\n",
       "  0.646,\n",
       "  0.6453,\n",
       "  0.721,\n",
       "  0.7102,\n",
       "  0.7309,\n",
       "  0.6755,\n",
       "  0.7396,\n",
       "  0.6342,\n",
       "  0.6575,\n",
       "  0.7022,\n",
       "  0.6499,\n",
       "  0.6991,\n",
       "  0.6561,\n",
       "  0.66,\n",
       "  0.7339,\n",
       "  0.7092,\n",
       "  0.6888,\n",
       "  0.6725,\n",
       "  0.724,\n",
       "  0.6655,\n",
       "  0.6961,\n",
       "  0.7412,\n",
       "  0.7584,\n",
       "  0.7653,\n",
       "  0.8621,\n",
       "  0.6966,\n",
       "  0.6647,\n",
       "  0.7269,\n",
       "  0.6705,\n",
       "  0.6731,\n",
       "  0.6205,\n",
       "  0.6706,\n",
       "  0.6996,\n",
       "  0.7535,\n",
       "  0.6665,\n",
       "  0.7368,\n",
       "  0.6454,\n",
       "  0.7085,\n",
       "  0.7461,\n",
       "  0.8247,\n",
       "  0.67,\n",
       "  0.7507,\n",
       "  0.6369,\n",
       "  0.6668,\n",
       "  0.7236,\n",
       "  0.7541,\n",
       "  0.6289,\n",
       "  0.6611,\n",
       "  0.7026,\n",
       "  0.7372,\n",
       "  0.6257,\n",
       "  0.6941,\n",
       "  0.7283,\n",
       "  0.7015,\n",
       "  0.764,\n",
       "  0.6122,\n",
       "  0.6764,\n",
       "  0.6869,\n",
       "  0.6983,\n",
       "  0.7679,\n",
       "  0.6658,\n",
       "  0.8749,\n",
       "  0.7133,\n",
       "  0.7902,\n",
       "  0.7068,\n",
       "  0.7026,\n",
       "  0.6624,\n",
       "  0.7917,\n",
       "  0.808,\n",
       "  0.6986,\n",
       "  0.6794,\n",
       "  0.6797,\n",
       "  0.7264,\n",
       "  0.6726,\n",
       "  0.7146,\n",
       "  0.7955,\n",
       "  0.7168,\n",
       "  0.6878,\n",
       "  0.7203,\n",
       "  0.7213,\n",
       "  0.665,\n",
       "  0.7011,\n",
       "  0.679,\n",
       "  0.6216,\n",
       "  0.6922,\n",
       "  0.6552,\n",
       "  0.6608,\n",
       "  0.6958,\n",
       "  0.6881,\n",
       "  0.8249,\n",
       "  0.6705,\n",
       "  0.6781,\n",
       "  0.7273,\n",
       "  0.6684,\n",
       "  0.6391,\n",
       "  0.6991,\n",
       "  0.6925,\n",
       "  0.6635,\n",
       "  0.7973,\n",
       "  0.6742,\n",
       "  0.7191,\n",
       "  0.6431,\n",
       "  0.7556,\n",
       "  0.6356,\n",
       "  0.6312,\n",
       "  0.7272,\n",
       "  0.718,\n",
       "  0.7679,\n",
       "  0.6788,\n",
       "  0.6949,\n",
       "  0.6695,\n",
       "  0.8013,\n",
       "  0.6845,\n",
       "  0.7472,\n",
       "  0.6337,\n",
       "  0.6658,\n",
       "  0.6713,\n",
       "  0.708,\n",
       "  0.702,\n",
       "  0.6924,\n",
       "  0.681,\n",
       "  0.8251,\n",
       "  0.7448,\n",
       "  0.6474,\n",
       "  0.7087,\n",
       "  0.6648,\n",
       "  0.8294,\n",
       "  0.6918,\n",
       "  0.6478,\n",
       "  0.6158,\n",
       "  0.823,\n",
       "  0.6714,\n",
       "  0.6512,\n",
       "  0.6484,\n",
       "  0.6663,\n",
       "  0.7923,\n",
       "  0.7,\n",
       "  0.6631,\n",
       "  0.5883,\n",
       "  0.7048,\n",
       "  0.6291,\n",
       "  0.7404,\n",
       "  0.7674,\n",
       "  0.708,\n",
       "  0.7282,\n",
       "  0.644,\n",
       "  0.6764,\n",
       "  0.7023,\n",
       "  0.6175,\n",
       "  0.8263,\n",
       "  0.6924,\n",
       "  0.7191,\n",
       "  0.6592,\n",
       "  0.7608,\n",
       "  0.6451,\n",
       "  0.6678,\n",
       "  0.6797,\n",
       "  0.6798,\n",
       "  0.6828,\n",
       "  0.6909,\n",
       "  0.6899,\n",
       "  0.6863,\n",
       "  0.6927,\n",
       "  0.656,\n",
       "  0.6405,\n",
       "  0.6713,\n",
       "  0.653,\n",
       "  0.712,\n",
       "  0.672,\n",
       "  0.7144,\n",
       "  0.7666,\n",
       "  0.686,\n",
       "  0.6804,\n",
       "  0.7367,\n",
       "  0.7451,\n",
       "  0.6761,\n",
       "  0.7307,\n",
       "  0.6713,\n",
       "  0.6667,\n",
       "  0.7754,\n",
       "  0.6874,\n",
       "  0.6533,\n",
       "  0.7438,\n",
       "  0.7636,\n",
       "  0.7383,\n",
       "  0.6764,\n",
       "  0.6772,\n",
       "  0.64,\n",
       "  0.662,\n",
       "  0.6701,\n",
       "  0.6916,\n",
       "  0.7454,\n",
       "  0.7416,\n",
       "  0.7185,\n",
       "  0.6861,\n",
       "  0.7373,\n",
       "  0.6462,\n",
       "  0.7015,\n",
       "  0.647,\n",
       "  0.8527,\n",
       "  0.6755,\n",
       "  0.7327,\n",
       "  0.672,\n",
       "  0.6834,\n",
       "  0.6595,\n",
       "  0.6965,\n",
       "  0.832,\n",
       "  0.7245,\n",
       "  0.8742,\n",
       "  0.7522,\n",
       "  0.6746,\n",
       "  0.7856,\n",
       "  0.6581,\n",
       "  0.6211,\n",
       "  0.6593,\n",
       "  0.7021,\n",
       "  0.6965,\n",
       "  0.7969,\n",
       "  0.7062,\n",
       "  0.7249,\n",
       "  0.7024,\n",
       "  0.6537,\n",
       "  0.693,\n",
       "  0.664,\n",
       "  0.64,\n",
       "  0.7377,\n",
       "  0.6716,\n",
       "  0.7125,\n",
       "  0.6676,\n",
       "  0.7023,\n",
       "  0.7458,\n",
       "  0.685,\n",
       "  0.7056,\n",
       "  0.6489,\n",
       "  0.6922,\n",
       "  0.6417,\n",
       "  0.6931,\n",
       "  0.7804,\n",
       "  0.7794,\n",
       "  0.7805,\n",
       "  0.6105,\n",
       "  0.6633,\n",
       "  0.6349,\n",
       "  0.6601,\n",
       "  0.6633,\n",
       "  0.7185,\n",
       "  0.6608,\n",
       "  0.6564,\n",
       "  0.7244,\n",
       "  0.732,\n",
       "  0.7197,\n",
       "  0.6643,\n",
       "  0.7211,\n",
       "  0.7936,\n",
       "  0.6415,\n",
       "  0.6906,\n",
       "  0.79,\n",
       "  0.7332,\n",
       "  0.762,\n",
       "  0.7878,\n",
       "  0.7343,\n",
       "  0.6424,\n",
       "  0.7216,\n",
       "  0.6775,\n",
       "  0.7284,\n",
       "  0.7301,\n",
       "  0.7883,\n",
       "  0.7217,\n",
       "  0.6567],\n",
       " 'val_accuracy': [0.4693,\n",
       "  0.4844,\n",
       "  0.5591,\n",
       "  0.6142,\n",
       "  0.5974,\n",
       "  0.6282,\n",
       "  0.6803,\n",
       "  0.6783,\n",
       "  0.69,\n",
       "  0.6726,\n",
       "  0.6792,\n",
       "  0.6396,\n",
       "  0.7258,\n",
       "  0.7424,\n",
       "  0.694,\n",
       "  0.7265,\n",
       "  0.7183,\n",
       "  0.7541,\n",
       "  0.7582,\n",
       "  0.766,\n",
       "  0.7495,\n",
       "  0.7345,\n",
       "  0.7573,\n",
       "  0.7364,\n",
       "  0.7782,\n",
       "  0.7717,\n",
       "  0.7786,\n",
       "  0.7791,\n",
       "  0.7723,\n",
       "  0.7564,\n",
       "  0.7932,\n",
       "  0.8045,\n",
       "  0.8007,\n",
       "  0.8038,\n",
       "  0.8063,\n",
       "  0.7805,\n",
       "  0.7997,\n",
       "  0.7772,\n",
       "  0.8037,\n",
       "  0.7935,\n",
       "  0.7898,\n",
       "  0.8028,\n",
       "  0.8117,\n",
       "  0.7925,\n",
       "  0.8005,\n",
       "  0.8032,\n",
       "  0.8021,\n",
       "  0.8168,\n",
       "  0.8006,\n",
       "  0.8171,\n",
       "  0.8102,\n",
       "  0.8185,\n",
       "  0.8177,\n",
       "  0.8141,\n",
       "  0.7802,\n",
       "  0.7928,\n",
       "  0.7962,\n",
       "  0.8196,\n",
       "  0.8092,\n",
       "  0.8216,\n",
       "  0.8161,\n",
       "  0.7895,\n",
       "  0.7936,\n",
       "  0.8098,\n",
       "  0.8222,\n",
       "  0.8254,\n",
       "  0.8251,\n",
       "  0.8099,\n",
       "  0.8269,\n",
       "  0.7881,\n",
       "  0.827,\n",
       "  0.828,\n",
       "  0.8163,\n",
       "  0.8299,\n",
       "  0.8052,\n",
       "  0.8271,\n",
       "  0.8217,\n",
       "  0.8078,\n",
       "  0.8263,\n",
       "  0.8322,\n",
       "  0.8264,\n",
       "  0.8233,\n",
       "  0.8167,\n",
       "  0.8288,\n",
       "  0.8233,\n",
       "  0.8239,\n",
       "  0.8367,\n",
       "  0.7975,\n",
       "  0.8346,\n",
       "  0.8249,\n",
       "  0.8118,\n",
       "  0.8324,\n",
       "  0.8235,\n",
       "  0.8075,\n",
       "  0.8133,\n",
       "  0.8185,\n",
       "  0.8415,\n",
       "  0.8344,\n",
       "  0.8499,\n",
       "  0.8216,\n",
       "  0.8312,\n",
       "  0.828,\n",
       "  0.8453,\n",
       "  0.8392,\n",
       "  0.8239,\n",
       "  0.7869,\n",
       "  0.8312,\n",
       "  0.8467,\n",
       "  0.8148,\n",
       "  0.8326,\n",
       "  0.8322,\n",
       "  0.8395,\n",
       "  0.839,\n",
       "  0.8077,\n",
       "  0.8505,\n",
       "  0.8461,\n",
       "  0.8404,\n",
       "  0.8512,\n",
       "  0.8332,\n",
       "  0.8379,\n",
       "  0.847,\n",
       "  0.8365,\n",
       "  0.8402,\n",
       "  0.8353,\n",
       "  0.8425,\n",
       "  0.8622,\n",
       "  0.8306,\n",
       "  0.8339,\n",
       "  0.8487,\n",
       "  0.8274,\n",
       "  0.8405,\n",
       "  0.8367,\n",
       "  0.829,\n",
       "  0.8364,\n",
       "  0.8224,\n",
       "  0.8296,\n",
       "  0.8435,\n",
       "  0.8524,\n",
       "  0.8457,\n",
       "  0.8305,\n",
       "  0.8349,\n",
       "  0.8375,\n",
       "  0.8485,\n",
       "  0.8297,\n",
       "  0.8523,\n",
       "  0.8448,\n",
       "  0.8398,\n",
       "  0.8494,\n",
       "  0.8424,\n",
       "  0.8502,\n",
       "  0.8482,\n",
       "  0.8293,\n",
       "  0.8417,\n",
       "  0.846,\n",
       "  0.8451,\n",
       "  0.8294,\n",
       "  0.8537,\n",
       "  0.8421,\n",
       "  0.8317,\n",
       "  0.832,\n",
       "  0.8323,\n",
       "  0.8102,\n",
       "  0.84,\n",
       "  0.8458,\n",
       "  0.8378,\n",
       "  0.8467,\n",
       "  0.8454,\n",
       "  0.8632,\n",
       "  0.8445,\n",
       "  0.8395,\n",
       "  0.8222,\n",
       "  0.8473,\n",
       "  0.8275,\n",
       "  0.851,\n",
       "  0.8391,\n",
       "  0.8379,\n",
       "  0.8162,\n",
       "  0.8463,\n",
       "  0.8346,\n",
       "  0.8548,\n",
       "  0.8444,\n",
       "  0.8449,\n",
       "  0.8382,\n",
       "  0.8535,\n",
       "  0.8476,\n",
       "  0.8415,\n",
       "  0.8318,\n",
       "  0.8538,\n",
       "  0.8452,\n",
       "  0.8353,\n",
       "  0.8436,\n",
       "  0.8329,\n",
       "  0.8564,\n",
       "  0.8485,\n",
       "  0.8418,\n",
       "  0.8443,\n",
       "  0.8276,\n",
       "  0.8462,\n",
       "  0.812,\n",
       "  0.8388,\n",
       "  0.831,\n",
       "  0.8398,\n",
       "  0.8394,\n",
       "  0.8476,\n",
       "  0.8253,\n",
       "  0.8276,\n",
       "  0.8434,\n",
       "  0.8427,\n",
       "  0.8463,\n",
       "  0.8365,\n",
       "  0.8505,\n",
       "  0.8398,\n",
       "  0.832,\n",
       "  0.8363,\n",
       "  0.8492,\n",
       "  0.8379,\n",
       "  0.842,\n",
       "  0.8522,\n",
       "  0.844,\n",
       "  0.8543,\n",
       "  0.8585,\n",
       "  0.8502,\n",
       "  0.8478,\n",
       "  0.851,\n",
       "  0.8508,\n",
       "  0.8473,\n",
       "  0.8274,\n",
       "  0.848,\n",
       "  0.8474,\n",
       "  0.8329,\n",
       "  0.8465,\n",
       "  0.8602,\n",
       "  0.8495,\n",
       "  0.8489,\n",
       "  0.8527,\n",
       "  0.8294,\n",
       "  0.8506,\n",
       "  0.8471,\n",
       "  0.8521,\n",
       "  0.8458,\n",
       "  0.8536,\n",
       "  0.8588,\n",
       "  0.8391,\n",
       "  0.8344,\n",
       "  0.8362,\n",
       "  0.8516,\n",
       "  0.8504,\n",
       "  0.8514,\n",
       "  0.8193,\n",
       "  0.843,\n",
       "  0.8389,\n",
       "  0.8567,\n",
       "  0.8507,\n",
       "  0.8532,\n",
       "  0.8413,\n",
       "  0.8435,\n",
       "  0.8512,\n",
       "  0.8489,\n",
       "  0.8239,\n",
       "  0.8392,\n",
       "  0.8575,\n",
       "  0.8501,\n",
       "  0.8578,\n",
       "  0.829,\n",
       "  0.8468,\n",
       "  0.8582,\n",
       "  0.8626,\n",
       "  0.8223,\n",
       "  0.847,\n",
       "  0.8538,\n",
       "  0.8568,\n",
       "  0.8477,\n",
       "  0.827,\n",
       "  0.8391,\n",
       "  0.8568,\n",
       "  0.8659,\n",
       "  0.8468,\n",
       "  0.8538,\n",
       "  0.8354,\n",
       "  0.837,\n",
       "  0.8475,\n",
       "  0.8448,\n",
       "  0.8607,\n",
       "  0.8526,\n",
       "  0.852,\n",
       "  0.8683,\n",
       "  0.8273,\n",
       "  0.845,\n",
       "  0.8407,\n",
       "  0.8526,\n",
       "  0.8409,\n",
       "  0.855,\n",
       "  0.8492,\n",
       "  0.8521,\n",
       "  0.8507,\n",
       "  0.8566,\n",
       "  0.846,\n",
       "  0.8437,\n",
       "  0.8503,\n",
       "  0.8499,\n",
       "  0.858,\n",
       "  0.8626,\n",
       "  0.8536,\n",
       "  0.8614,\n",
       "  0.8528,\n",
       "  0.8495,\n",
       "  0.8472,\n",
       "  0.8306,\n",
       "  0.8523,\n",
       "  0.8555,\n",
       "  0.8473,\n",
       "  0.8436,\n",
       "  0.8491,\n",
       "  0.8401,\n",
       "  0.8542,\n",
       "  0.8529,\n",
       "  0.8369,\n",
       "  0.8531,\n",
       "  0.8537,\n",
       "  0.8434,\n",
       "  0.8368,\n",
       "  0.8384,\n",
       "  0.8581,\n",
       "  0.8575,\n",
       "  0.8595,\n",
       "  0.8509,\n",
       "  0.8544,\n",
       "  0.855,\n",
       "  0.8447,\n",
       "  0.8388,\n",
       "  0.8433,\n",
       "  0.8568,\n",
       "  0.842,\n",
       "  0.8587,\n",
       "  0.8469,\n",
       "  0.863,\n",
       "  0.824,\n",
       "  0.8525,\n",
       "  0.8424,\n",
       "  0.8564,\n",
       "  0.8543,\n",
       "  0.8561,\n",
       "  0.848,\n",
       "  0.8341,\n",
       "  0.8485,\n",
       "  0.8256,\n",
       "  0.8332,\n",
       "  0.8563,\n",
       "  0.8296,\n",
       "  0.8571,\n",
       "  0.861,\n",
       "  0.8573,\n",
       "  0.8523,\n",
       "  0.8492,\n",
       "  0.8292,\n",
       "  0.8461,\n",
       "  0.8499,\n",
       "  0.8479,\n",
       "  0.8627,\n",
       "  0.8517,\n",
       "  0.8533,\n",
       "  0.8611,\n",
       "  0.853,\n",
       "  0.8618,\n",
       "  0.8529,\n",
       "  0.8515,\n",
       "  0.8529,\n",
       "  0.8407,\n",
       "  0.8518,\n",
       "  0.8494,\n",
       "  0.8566,\n",
       "  0.8555,\n",
       "  0.8606,\n",
       "  0.8561,\n",
       "  0.8321,\n",
       "  0.8333,\n",
       "  0.8368,\n",
       "  0.8671,\n",
       "  0.8573,\n",
       "  0.8556,\n",
       "  0.8625,\n",
       "  0.8596,\n",
       "  0.8444,\n",
       "  0.8551,\n",
       "  0.8623,\n",
       "  0.8448,\n",
       "  0.84,\n",
       "  0.847,\n",
       "  0.8647,\n",
       "  0.8525,\n",
       "  0.8417,\n",
       "  0.8582,\n",
       "  0.8505,\n",
       "  0.8337,\n",
       "  0.8525,\n",
       "  0.8421,\n",
       "  0.8388,\n",
       "  0.8463,\n",
       "  0.857,\n",
       "  0.842,\n",
       "  0.8556,\n",
       "  0.8466,\n",
       "  0.8443,\n",
       "  0.8323,\n",
       "  0.8503,\n",
       "  0.8566],\n",
       " 'epochs': [1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  12,\n",
       "  13,\n",
       "  14,\n",
       "  15,\n",
       "  16,\n",
       "  17,\n",
       "  18,\n",
       "  19,\n",
       "  20,\n",
       "  21,\n",
       "  22,\n",
       "  23,\n",
       "  24,\n",
       "  25,\n",
       "  26,\n",
       "  27,\n",
       "  28,\n",
       "  29,\n",
       "  30,\n",
       "  31,\n",
       "  32,\n",
       "  33,\n",
       "  34,\n",
       "  35,\n",
       "  36,\n",
       "  37,\n",
       "  38,\n",
       "  39,\n",
       "  40,\n",
       "  41,\n",
       "  42,\n",
       "  43,\n",
       "  44,\n",
       "  45,\n",
       "  46,\n",
       "  47,\n",
       "  48,\n",
       "  49,\n",
       "  50,\n",
       "  51,\n",
       "  52,\n",
       "  53,\n",
       "  54,\n",
       "  55,\n",
       "  56,\n",
       "  57,\n",
       "  58,\n",
       "  59,\n",
       "  60,\n",
       "  61,\n",
       "  62,\n",
       "  63,\n",
       "  64,\n",
       "  65,\n",
       "  66,\n",
       "  67,\n",
       "  68,\n",
       "  69,\n",
       "  70,\n",
       "  71,\n",
       "  72,\n",
       "  73,\n",
       "  74,\n",
       "  75,\n",
       "  76,\n",
       "  77,\n",
       "  78,\n",
       "  79,\n",
       "  80,\n",
       "  81,\n",
       "  82,\n",
       "  83,\n",
       "  84,\n",
       "  85,\n",
       "  86,\n",
       "  87,\n",
       "  88,\n",
       "  89,\n",
       "  90,\n",
       "  91,\n",
       "  92,\n",
       "  93,\n",
       "  94,\n",
       "  95,\n",
       "  96,\n",
       "  97,\n",
       "  98,\n",
       "  99,\n",
       "  100,\n",
       "  101,\n",
       "  102,\n",
       "  103,\n",
       "  104,\n",
       "  105,\n",
       "  106,\n",
       "  107,\n",
       "  108,\n",
       "  109,\n",
       "  110,\n",
       "  111,\n",
       "  112,\n",
       "  113,\n",
       "  114,\n",
       "  115,\n",
       "  116,\n",
       "  117,\n",
       "  118,\n",
       "  119,\n",
       "  120,\n",
       "  121,\n",
       "  122,\n",
       "  123,\n",
       "  124,\n",
       "  125,\n",
       "  126,\n",
       "  127,\n",
       "  128,\n",
       "  129,\n",
       "  130,\n",
       "  131,\n",
       "  132,\n",
       "  133,\n",
       "  134,\n",
       "  135,\n",
       "  136,\n",
       "  137,\n",
       "  138,\n",
       "  139,\n",
       "  140,\n",
       "  141,\n",
       "  142,\n",
       "  143,\n",
       "  144,\n",
       "  145,\n",
       "  146,\n",
       "  147,\n",
       "  148,\n",
       "  149,\n",
       "  150,\n",
       "  151,\n",
       "  152,\n",
       "  153,\n",
       "  154,\n",
       "  155,\n",
       "  156,\n",
       "  157,\n",
       "  158,\n",
       "  159,\n",
       "  160,\n",
       "  161,\n",
       "  162,\n",
       "  163,\n",
       "  164,\n",
       "  165,\n",
       "  166,\n",
       "  167,\n",
       "  168,\n",
       "  169,\n",
       "  170,\n",
       "  171,\n",
       "  172,\n",
       "  173,\n",
       "  174,\n",
       "  175,\n",
       "  176,\n",
       "  177,\n",
       "  178,\n",
       "  179,\n",
       "  180,\n",
       "  181,\n",
       "  182,\n",
       "  183,\n",
       "  184,\n",
       "  185,\n",
       "  186,\n",
       "  187,\n",
       "  188,\n",
       "  189,\n",
       "  190,\n",
       "  191,\n",
       "  192,\n",
       "  193,\n",
       "  194,\n",
       "  195,\n",
       "  196,\n",
       "  197,\n",
       "  198,\n",
       "  199,\n",
       "  200,\n",
       "  201,\n",
       "  202,\n",
       "  203,\n",
       "  204,\n",
       "  205,\n",
       "  206,\n",
       "  207,\n",
       "  208,\n",
       "  209,\n",
       "  210,\n",
       "  211,\n",
       "  212,\n",
       "  213,\n",
       "  214,\n",
       "  215,\n",
       "  216,\n",
       "  217,\n",
       "  218,\n",
       "  219,\n",
       "  220,\n",
       "  221,\n",
       "  222,\n",
       "  223,\n",
       "  224,\n",
       "  225,\n",
       "  226,\n",
       "  227,\n",
       "  228,\n",
       "  229,\n",
       "  230,\n",
       "  231,\n",
       "  232,\n",
       "  233,\n",
       "  234,\n",
       "  235,\n",
       "  236,\n",
       "  237,\n",
       "  238,\n",
       "  239,\n",
       "  240,\n",
       "  241,\n",
       "  242,\n",
       "  243,\n",
       "  244,\n",
       "  245,\n",
       "  246,\n",
       "  247,\n",
       "  248,\n",
       "  249,\n",
       "  250,\n",
       "  251,\n",
       "  252,\n",
       "  253,\n",
       "  254,\n",
       "  255,\n",
       "  256,\n",
       "  257,\n",
       "  258,\n",
       "  259,\n",
       "  260,\n",
       "  261,\n",
       "  262,\n",
       "  263,\n",
       "  264,\n",
       "  265,\n",
       "  266,\n",
       "  267,\n",
       "  268,\n",
       "  269,\n",
       "  270,\n",
       "  271,\n",
       "  272,\n",
       "  273,\n",
       "  274,\n",
       "  275,\n",
       "  276,\n",
       "  277,\n",
       "  278,\n",
       "  279,\n",
       "  280,\n",
       "  281,\n",
       "  282,\n",
       "  283,\n",
       "  284,\n",
       "  285,\n",
       "  286,\n",
       "  287,\n",
       "  288,\n",
       "  289,\n",
       "  290,\n",
       "  291,\n",
       "  292,\n",
       "  293,\n",
       "  294,\n",
       "  295,\n",
       "  296,\n",
       "  297,\n",
       "  298,\n",
       "  299,\n",
       "  300,\n",
       "  301,\n",
       "  302,\n",
       "  303,\n",
       "  304,\n",
       "  305,\n",
       "  306,\n",
       "  307,\n",
       "  308,\n",
       "  309,\n",
       "  310,\n",
       "  311,\n",
       "  312,\n",
       "  313,\n",
       "  314,\n",
       "  315,\n",
       "  316,\n",
       "  317,\n",
       "  318,\n",
       "  319,\n",
       "  320,\n",
       "  321,\n",
       "  322,\n",
       "  323,\n",
       "  324,\n",
       "  325,\n",
       "  326,\n",
       "  327,\n",
       "  328,\n",
       "  329,\n",
       "  330,\n",
       "  331,\n",
       "  332,\n",
       "  333,\n",
       "  334,\n",
       "  335,\n",
       "  336,\n",
       "  337,\n",
       "  338,\n",
       "  339,\n",
       "  340,\n",
       "  341,\n",
       "  342,\n",
       "  343,\n",
       "  344,\n",
       "  345,\n",
       "  346,\n",
       "  347,\n",
       "  348,\n",
       "  349,\n",
       "  350,\n",
       "  351,\n",
       "  352,\n",
       "  353,\n",
       "  354,\n",
       "  355,\n",
       "  356,\n",
       "  357,\n",
       "  358,\n",
       "  359,\n",
       "  360,\n",
       "  361,\n",
       "  362,\n",
       "  363,\n",
       "  364,\n",
       "  365,\n",
       "  366,\n",
       "  367,\n",
       "  368,\n",
       "  369,\n",
       "  370,\n",
       "  371,\n",
       "  372,\n",
       "  373,\n",
       "  374,\n",
       "  375,\n",
       "  376,\n",
       "  377,\n",
       "  378,\n",
       "  379,\n",
       "  380,\n",
       "  381,\n",
       "  382,\n",
       "  383,\n",
       "  384,\n",
       "  385,\n",
       "  386,\n",
       "  387,\n",
       "  388,\n",
       "  389,\n",
       "  390,\n",
       "  391,\n",
       "  392,\n",
       "  393,\n",
       "  394,\n",
       "  395,\n",
       "  396,\n",
       "  397,\n",
       "  398,\n",
       "  399,\n",
       "  400,\n",
       "  401,\n",
       "  402,\n",
       "  403,\n",
       "  404,\n",
       "  405,\n",
       "  406]}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.ylim((0,1))\n",
    "plt.plot(history_dict['epochs'], history_dict['accuracy'],'r')\n",
    "plt.plot(history_dict['epochs'], history_dict['val_accuracy'], 'b')\n",
    "plt.legend({'training accuracy':'r', 'validation accuracy': 'b'})\n",
    "plt.show()\n",
    "\n",
    "plt.ylim((0,2.5))\n",
    "plt.plot(history_dict['epochs'], history_dict['loss'],'r')\n",
    "plt.plot(history_dict['epochs'], history_dict['val_loss'], 'b')\n",
    "plt.legend({'training loss':'r', 'validation loss': 'b'})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.ylim((0,1))\n",
    "plt.plot(history_dict['epochs'], history_dict['accuracy'],'r')\n",
    "plt.plot(history_dict['epochs'], history_dict['val_accuracy'], 'b')\n",
    "plt.legend({'training accuracy':'r', 'validation accuracy': 'b'})\n",
    "plt.show()\n",
    "\n",
    "plt.ylim((0,2.5))\n",
    "plt.plot(history_dict['epochs'], history_dict['loss'],'r')\n",
    "plt.plot(history_dict['epochs'], history_dict['val_loss'], 'b')\n",
    "plt.legend({'training loss':'r', 'validation loss': 'b'})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
